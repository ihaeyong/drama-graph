{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MissOh DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnotherMissOh Visual Structure\n",
    "- json_data['file_name'] : 'AnotherMissOh01.mp4'\n",
    "- json_data['visual_results']\n",
    "- json_data['visual_results'][0].keys() : dict_keys(['start_time', 'end_time', 'vid', 'image_info'])\n",
    "- {\n",
    "'start_time': '00:02:51;16', \n",
    "'end_time': '00:02:54;15', \n",
    "'vid': 'AnotherMissOh01_001_0078', \n",
    "'image_info': ...}\n",
    "- json_data['visual_results'][0]['image_info']\n",
    "- [{'frame_id': 'AnotherMissOh01_001_0078_IMAGE_0000004295', \n",
    "'place': 'none', \n",
    "'persons': [\n",
    "{'person_id': 'Haeyoung1', \n",
    "'person_info': {\n",
    "'face_rect': {'min_x': 515, 'min_y': 0, 'max_x': 845, 'max_y': 443}, \n",
    "'full_rect': {'min_x': 278, 'min_y': 2, 'max_x': 1025, 'max_y': 769}, \n",
    "'behavior': 'stand up', \n",
    "'predicate': 'none', \n",
    "'emotion': 'Neutral', \n",
    "'face_rect_score': '0.5', \n",
    "'full_rect_score': '0.9'}, \n",
    "'related_objects': []}], \n",
    "'objects': []}, \n",
    "- {'frame_id': 'AnotherMissOh01_001_0078_IMAGE_0000004311', \n",
    "'place': '', \n",
    "'persons': [{\n",
    "'person_id':'Haeyoung1',\n",
    "'person_info': {\n",
    "'face_rect': {'min_x': 515, 'min_y': 0, 'max_x': 831, 'max_y': 411}, \n",
    "'full_rect': {'min_x': 270, 'min_y': 0, 'max_x': 1025, 'max_y': 768}, \n",
    "'behavior': 'stand up', \n",
    "'predicate': 'none', \n",
    "'emotion': 'Neutral', \n",
    "'face_rect_score': '0.5', \n",
    "'full_rect_score': '0.9'}, \n",
    "'related_objects': []}],\n",
    "'objects': []},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install graphviz xdg-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import json\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Yolo_v2_pytorch.src.utils import *\n",
    "from graphviz import Digraph, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_blank(s):\n",
    "    return bool(s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "(39, 129, 113)\n"
     ]
    }
   ],
   "source": [
    "MissOh_CLASSES = ['person']\n",
    "print(MissOh_CLASSES[0])\n",
    "global colors\n",
    "colors = pickle.load(open(\"../Yolo_v2_pytorch/src/pallete\", \"rb\"))\n",
    "print(colors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, conf_threshold=0.35, data_path_test='./Yolo_v2_pytorch/missoh_test/', display=False, emo_net_ch=64, image_size=448, img_path='./data/AnotherMissOh/AnotherMissOh_images_ver3.2/', json_path='./data/AnotherMissOh/AnotherMissOh_Visual_ver3.2/', model='baseline', nms_threshold=0.5, pre_trained_model_type='model', saved_path='./checkpoint/refined_models')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from Yolo_v2_pytorch.src.utils import *\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from Yolo_v2_pytorch.src.yolo_net import Yolo\n",
    "from Yolo_v2_pytorch.src.anotherMissOh_dataset import AnotherMissOh, Splits, SortFullRect, PersonCLS,PBeHavCLS, FaceCLS, ObjectCLS, P2ORelCLS\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from lib.place_model import place_model, label_mapping, accuracy, label_remapping, place_buffer\n",
    "from lib.person_model import person_model\n",
    "from lib.behavior_model import behavior_model\n",
    "from lib.pytorch_misc import optimistic_restore, de_chunkize, clip_grad_norm, flatten\n",
    "from lib.focal_loss import FocalLossWithOneHot, FocalLossWithOutOneHot, CELossWithOutOneHot\n",
    "from lib.face_model import face_model\n",
    "from lib.object_model import object_model\n",
    "from lib.relation_model import relation_model\n",
    "from lib.emotion_model import emotion_model, crop_face_emotion, EmoCLS\n",
    "\n",
    "num_persons = len(PersonCLS)\n",
    "num_behaviors = len(PBeHavCLS)\n",
    "num_faces = len(FaceCLS)\n",
    "num_objects = len(ObjectCLS)\n",
    "num_relations = len(P2ORelCLS)\n",
    "num_emos = len(EmoCLS)\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"You Only Look Once: Unified, Real-Time Object Detection\")\n",
    "    parser.add_argument(\"--image_size\",\n",
    "                        type=int, default=448,\n",
    "                        help=\"The common width and height for all images\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1,\n",
    "                        help=\"The number of images per batch\")\n",
    "    parser.add_argument(\"--conf_threshold\",\n",
    "                        type=float, default=0.35)\n",
    "    parser.add_argument(\"--nms_threshold\",\n",
    "                        type=float, default=0.5)\n",
    "    parser.add_argument(\"--pre_trained_model_type\",\n",
    "                        type=str, choices=[\"model\", \"params\"],\n",
    "                        default=\"model\")\n",
    "    parser.add_argument(\"--data_path_test\",\n",
    "                        type=str,\n",
    "                        default=\"./Yolo_v2_pytorch/missoh_test/\",\n",
    "                        help=\"the root folder of dataset\")\n",
    "\n",
    "    parser.add_argument(\"--saved_path\", type=str,\n",
    "                        default=\"./checkpoint/refined_models\")\n",
    "\n",
    "    parser.add_argument(\"--img_path\", type=str,\n",
    "                        default=\"./data/AnotherMissOh/AnotherMissOh_images_ver3.2/\")\n",
    "    parser.add_argument(\"--json_path\", type=str,\n",
    "                        default=\"./data/AnotherMissOh/AnotherMissOh_Visual_ver3.2/\")\n",
    "    parser.add_argument(\"-model\", dest='model', type=str, default=\"baseline\")\n",
    "    parser.add_argument(\"-display\", dest='display', action='store_true')\n",
    "    parser.add_argument(\"-emo_net_ch\", dest='emo_net_ch',type=int, default=64)\n",
    "    args = parser.parse_args([])\n",
    "    return args\n",
    "\n",
    "# get args.\n",
    "opt = get_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import read_dot\n",
    "#from networkx.drawing.nx_agraph import read_dot\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.img_path = \"../data/AnotherMissOh/AnotherMissOh_images_ver3.2/\"\n",
    "opt.json_path = \"../data/AnotherMissOh/AnotherMissOh_Visual_ver3.2/\"\n",
    "opt.saved_path = \"../checkpoint/refined_models\"\n",
    "opt.display = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = [\n",
    "    Resize((448, 448)),  # should match to Yolo_V2\n",
    "    ToTensor(),\n",
    "    # Normalize(# should match to Yolo_V2\n",
    "    #mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]\n",
    "transf = Compose(tform)\n",
    "\n",
    "# splits the episodes int train, val, test\n",
    "train, val, test = Splits(num_episodes=18)\n",
    "\n",
    "# load datasets\n",
    "train_set = AnotherMissOh(train, opt.img_path, opt.json_path, False)\n",
    "val_set = AnotherMissOh(val, opt.img_path, opt.json_path, False)\n",
    "test_set = AnotherMissOh(test, opt.img_path, opt.json_path, False)\n",
    "\n",
    "episode = 7\n",
    "infer = [episode]\n",
    "infer_set = AnotherMissOh(infer, opt.img_path, opt.json_path, False)\n",
    "\n",
    "\n",
    "# model path\n",
    "model_path = \"{}/anotherMissOh_{}.pth\".format(\n",
    "    opt.saved_path,opt.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "loaded with ../checkpoint/person/anotherMissOh_voc_person_group_1gpu_init_none.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'lib.behavior_model.behavior_model' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'Yolo_v2_pytorch.src.yolo_tunning.YoloD' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded with person and behavior model ../checkpoint/behavior/anotherMissOh_global_diff_subset_batch1_local_wloss_output_1_noise_global.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_face.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_emotion_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_object_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_relation_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_place_integration.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "place_model(\n",
       "  (detector): YoloD(\n",
       "    (stage1_conv1): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv4): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv5): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv6): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv7): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv8): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv9): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv10): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv11): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv12): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv13): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_maxpl): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (stage2_a_conv1): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv2): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv3): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv4): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv5): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv6): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv7): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_b_conv): Sequential(\n",
       "      (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage3_conv1): Sequential(\n",
       "      (0): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "  )\n",
       "  (place_conv): Sequential(\n",
       "    (0): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (bert): BERT(\n",
       "    (embedding): BERTEmbedding(\n",
       "      (position): PositionalEmbedding()\n",
       "      (dropout): Dropout(p=0.0)\n",
       "    )\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=22, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(123)\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "# set test loader params\n",
    "test_params = {\"batch_size\": opt.batch_size,\n",
    "               \"shuffle\": False,\n",
    "               \"drop_last\": False,\n",
    "               \"collate_fn\": custom_collate_fn}\n",
    "\n",
    "# set test loader\n",
    "test_loader = DataLoader(infer_set, **test_params)\n",
    "\n",
    "# ---------------(1) load refined models --------------------\n",
    "# get the trained models from\n",
    "# https://drive.google.com/drive/folders/1WXzP8nfXU4l0cNOtSPX9O1qxYH2m6LIp\n",
    "# define person model\n",
    "if True:\n",
    "    # model path\n",
    "    if False:\n",
    "        model_path = \"../checkpoint/person/anotherMissOh_only_params_{}\".format(\n",
    "            'voc_person_group_1gpu_init_none.pth')\n",
    "    else:\n",
    "        model_path = \"../checkpoint/person/anotherMissOh_{}\".format(\n",
    "            'voc_person_group_1gpu_init_none.pth')\n",
    "        \n",
    "    model_p = person_model(num_persons, device)\n",
    "    ckpt = torch.load(model_path)\n",
    "    \n",
    "    # in case of multi-gpu training\n",
    "    if False:\n",
    "        from collections import OrderedDict\n",
    "        ckpt_state_dict = OrderedDict()\n",
    "        for k,v in ckpt.items():\n",
    "            name = k[7:] # remove 'module'\n",
    "            ckpt_state_dict[name] = v\n",
    "\n",
    "        print(\"--- loading {} model---\".format(model_path))\n",
    "        if optimistic_restore(model_p, ckpt_state_dict):\n",
    "            print(\"loaded with {}\".format(model_path))\n",
    "    else:\n",
    "        model_p = ckpt\n",
    "        print(\"loaded with {}\".format(model_path))\n",
    "        \n",
    "    model_p.to(device)\n",
    "    model_p.eval()\n",
    "\n",
    "if False :\n",
    "    print(\"-----------person---behavior-------model---------------\")\n",
    "    model1 = behavior_model(num_persons, num_behaviors, opt, device)\n",
    "    trained_persons = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_integration.pth')\n",
    "    if optimistic_restore(model1, torch.load(trained_persons)):\n",
    "        #model1.load_state_dict(torch.load(trained_persons))\n",
    "        print(\"loaded with {}\".format(trained_persons))\n",
    "\n",
    "else:\n",
    "    # pre-trained behavior model\n",
    "    # step 1: person trained on voc 50 epoch\n",
    "    # step 2: person feature based behavior sequence learning 100 epoch\n",
    "    model1 = behavior_model(num_persons, num_behaviors, opt, device)\n",
    "    if False:\n",
    "        trained_persons = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "            'anotherMissOh_only_params_integration.pth')\n",
    "        model1.load_state_dict(torch.load(trained_persons))\n",
    "        print(\"loaded with person and behavior model {}\".format(trained_persons))\n",
    "    else:\n",
    "        trained_persons = '../checkpoint/behavior' + os.sep + \"{}\".format(\n",
    "            'anotherMissOh_global_diff_subset_batch1_local_wloss_output_1_noise_global.pth')\n",
    "        model1 = torch.load(trained_persons)\n",
    "        print(\"loaded with person and behavior model {}\".format(trained_persons))\n",
    "        \n",
    "model1.cuda(device)\n",
    "model1.eval()\n",
    "\n",
    "# face model\n",
    "if True:\n",
    "    model_face = face_model(num_persons, num_faces, device)\n",
    "    trained_face = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_face.pth')\n",
    "    model_face.load_state_dict(torch.load(trained_face))\n",
    "    print(\"loaded with {}\".format(trained_face))\n",
    "model_face.cuda(device)\n",
    "model_face.eval()\n",
    "\n",
    "# emotion model\n",
    "if True:\n",
    "    model_emo = emotion_model(opt.emo_net_ch, num_persons, device)\n",
    "    trained_emotion = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_emotion_integration.pth')\n",
    "    model_emo.load_state_dict(torch.load(trained_emotion))\n",
    "    print(\"loaded with {}\".format(trained_emotion))\n",
    "model_emo.cuda(device)\n",
    "model_emo.eval()\n",
    "\n",
    "# object model\n",
    "if True:\n",
    "    # add model\n",
    "    model_object = object_model(num_objects)\n",
    "    trained_object = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_object_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_object))\n",
    "    model_object.load_state_dict(torch.load(trained_object))\n",
    "\n",
    "model_object.cuda(device)\n",
    "model_object.eval()\n",
    "\n",
    "\n",
    "# relation model\n",
    "if True:\n",
    "    # add model\n",
    "    model_relation = relation_model(num_persons, num_objects, num_relations, opt, device)\n",
    "    trained_relation = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_relation_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_relation))\n",
    "    model_relation.load_state_dict(torch.load(trained_relation))\n",
    "model_relation.cuda(device)\n",
    "model_relation.eval()\n",
    "\n",
    "# place model\n",
    "if True:\n",
    "    model_place = place_model(num_persons, num_behaviors, device)\n",
    "    # add model\n",
    "    trained_place = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "        'anotherMissOh_only_params_place_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_place))\n",
    "    model_place.load_state_dict(torch.load(trained_place)['model'])\n",
    "model_place.cuda(device)\n",
    "model_place.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the color map for detection results\n",
    "colors = pickle.load(open(\"../Yolo_v2_pytorch/src/pallete\", \"rb\"))\n",
    "\n",
    "width, height = (1024, 768)\n",
    "width_ratio = float(opt.image_size) / width\n",
    "height_ratio = float(opt.image_size) / height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_blank(s):\n",
    "    return bool(s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(episode, scene, frm, info):\n",
    "    \n",
    "    save_file = 'temp_graph'\n",
    "    import string\n",
    "    strseq = string.ascii_uppercase\n",
    "    \n",
    "    # define  graph\n",
    "    dot = Digraph('G',filename='{}.gv'.format(save_file),engine='fdp')\n",
    "    dot.attr('graph', rotate = '0', dpi='600',rankdir='TB', size='10,8')\n",
    "    dot.attr('node', height='0.1', fontsize='6')\n",
    "    dot.attr('edge', fontsize='6')\n",
    "\n",
    "    place = \"{}\".format(info['place'])\n",
    "    sound = \"{}\".format('sound')\n",
    "    \n",
    "    if not is_not_blank(place):\n",
    "        place = 'none'\n",
    "    if not is_not_blank(sound):\n",
    "        sound = 'none'\n",
    "        \n",
    "    num_of_persons = len(info['persons']['person_id'])\n",
    "    num_of_objects = len(info['objects']['object_id'])\n",
    "    \n",
    "    frm_graph = 'episode_{}_scene_{}_frame_{}'.format(\n",
    "        episode, scene, frm)\n",
    "    \n",
    "    #dot.node(frm_graph, style='filled', color='lightgrey')\n",
    "    episode_node = \"episode_{:02d}\".format(episode)\n",
    "    scene_node = \"scene_{:03d}\".format(scene)\n",
    "    frame_node = \"frame_{:04d}\".format(frm)\n",
    "    dot.node(episode_node, style='filled', color='lightgrey')\n",
    "    dot.node(scene_node, style='filled', color='lightgrey')\n",
    "    dot.node(frame_node, style='filled', color='lightgrey')\n",
    "    \n",
    "    dot.node(place, style='filled', color='lightblue')\n",
    "    dot.node(sound, style='filled', color='lightblue')\n",
    "    \n",
    "    if is_not_blank(episode_node) and is_not_blank(scene_node):\n",
    "        dot.edge(episode_node, scene_node)\n",
    "    \n",
    "    if is_not_blank(scene_node) and is_not_blank(frame_node):\n",
    "        dot.edge(scene_node, frame_node)\n",
    "        \n",
    "    if is_not_blank(frame_node) and is_not_blank(place):\n",
    "        dot.edge(frame_node, place)\n",
    "    \n",
    "    if is_not_blank(frame_node) and is_not_blank(sound):\n",
    "        dot.edge(frame_node, sound)\n",
    "    \n",
    "    for p in range(num_of_objects):\n",
    "        try: \n",
    "            object_id = info['objects']['object_id'][p]\n",
    "        except:\n",
    "            object_id = 'none'\n",
    "            \n",
    "        try: \n",
    "            predicate = info['objects']['relation'][p]\n",
    "        except:\n",
    "            predicate = 'none'\n",
    "            \n",
    "        if is_not_blank(object_id) and object_id is not 'person':\n",
    "            dot.node(object_id, style='filled', color='gold')\n",
    "        if is_not_blank(predicate) and predicate is not 'person':\n",
    "            dot.node(predicate, style='filled', color='gold')\n",
    "        if is_not_blank(frame_node) and is_not_blank(object_id):\n",
    "            dot.edge(frame_node, object_id)\n",
    "            \n",
    "    for p in range(num_of_persons):\n",
    "        \n",
    "        try:\n",
    "            person_id = \"{}\".format(info['persons']['person_id'][p])\n",
    "        except:\n",
    "            person_id = 'none'\n",
    "        try:\n",
    "            behavior = \"{}\".format(info['persons']['behavior'][p])\n",
    "        except:\n",
    "            person_id = 'none'\n",
    "        try:\n",
    "            predicate = \"{}\".format(info['persons']['predicate'][p])\n",
    "        except:\n",
    "            person_id = 'none'\n",
    "        try:\n",
    "            emotion = \"{}\".format(info['persons']['emotion'][p])\n",
    "        except:\n",
    "            person_id = 'none'\n",
    "        try:\n",
    "            robj_id = \"{}\".format(info['persons']['related_object_id'][p])\n",
    "        except:\n",
    "            robj_id = ''\n",
    "            \n",
    "        if is_not_blank(person_id):\n",
    "            dot.node(person_id)\n",
    "        if is_not_blank(behavior):\n",
    "            dot.node(behavior, style='filled', color='green')\n",
    "        #if is_not_blank(predicate):\n",
    "        #    dot.node(predicate, style='filled', color='yellow')\n",
    "        if is_not_blank(emotion):\n",
    "            dot.node(emotion, style='filled', color='blue')\n",
    "\n",
    "        if is_not_blank(frame_node) and is_not_blank(person_id):\n",
    "            dot.edge(frame_node, person_id)\n",
    "        if is_not_blank(person_id) and is_not_blank(behavior):\n",
    "            dot.edge(person_id, behavior)\n",
    "        if is_not_blank(person_id) and is_not_blank(predicate) and is_not_blank(robj_id):\n",
    "            dot.edge(person_id, robj_id, label=predicate, color='red')\n",
    "            #dot.edge(predicate, robj_id)\n",
    "        if is_not_blank(person_id) and is_not_blank(emotion):\n",
    "            dot.edge(person_id, emotion)\n",
    "            \n",
    "    # show in image\n",
    "    dot.format = 'png'\n",
    "    dot.render('{}.gv'.format(save_file), view=True)\n",
    "    \n",
    "    graph = cv2.imread('{}.gv.png'.format(save_file))\n",
    "    graph = cv2.resize(graph, dsize=(0, 0), fx=600.0/graph.shape[0], fy=600.0/graph.shape[0])\n",
    "    \n",
    "    if True:\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(graph)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------0-th----------------frame\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAG2CAYAAACqHSU4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeXycZb3//9d1z75kMtnXbpRSlrYUKFAQBC0UREXkHGU5iLvgUVHA/YHLz4Uj6lePesQjRxA5B2QTBA5QEU4rZe0K3ZTSvc2+T2afue/r90dy3ySle5PMJPk8H480yT333HMlncx7rl1prRFCCCFEcTAKXQAhhBBCvEWCWQghhCgiEsxCCCFEEZFgFkIIIYqIBLMQQghRRCSYhRBCiCIyKsGslLpYKfWGUmqLUurro/EYQgghxESkRnoes1LKBWwGLgT2ACuBq7TWm0b0gYQQQogJaDRqzGcAW7TW27TWWeB+4AOj8DhCCCHEhOMehWs2ALuHfL8HOPNAd6isrNTTp08fhaIIIYQQxWfHjh10dnaqfd02GsF8SJRSnwE+AzB16lRWrVpVqKIIIYQQY2rBggX7vW00mrKbgClDvm8cPDaM1voOrfUCrfWCqqqqUSiGEEIIMf6MRjCvBGYppWYopbzAlcDjo/A4QgghxIQz4k3ZWuu8UurzwF8AF3CX1nrjSD+OEEIIMRGNSh+z1vop4KnRuLYQQggxkcnKX0IIIUQRKdiobCGEKLQDL7B0CIsvaY3WGmUcSh1nnzNjUGr/t4nJSYJZCDFpaK2xzAxWPo3WJlprtJUbPJbBzKecDyufhkNaGVFz0GBVCsPlw+X243IHMNwBDLcfl8uHcnlQGGAYuFw+DLcfpaQxczKTYBZCTBjDasDawjTTmJl+sukeLDMDWpPPxcln+rGsHGiLQ6oZjwArnyaf6dv3jcpAGW7c3hLc3jBKuVCGC4+vFLcvissTZGC148HTldSwJzIJZiHEuKW1Bm1hmVnMfAqtTdLxFnLJTiwzM1grttCWyVgF8BHRFtrMkkt1kUt1OYeVcoFyoZSB4fLiCZThDzdguDwYbj+GyzcQ4hLUE4oEsxBifNB6SLRqcqluMqlOzFySfLafXKoHsApXvlGgtQnaRAOWmSafjZHq2wkoPL4Ibl8pLk8Qt68Uf6gWhjSBS1iPXxLMQoiiZ5k5zFwSM5cg1b+bbKoHbeXQVp6irgmPGk0u00dusGlcGW5ihge3J0wwOgOXN4TLHcRweSWgxyEJZiFE0bH7is18klRsN/lMjEyiHW1lC1yy4qStPNrKk82nyKY6UMqNN1iB21dKoKQRty8CqIEhahLURU+CWQhRNLS2MHNJcpk+Ej1bMXNxrHyGyVkrPnJa58kk2sgk2kj17cRwBwiWTsUbrMLtCaMM18EvIgpGglkIUVADtWNNLt1Dur+ZdLwZM5codLEmDMvMYJkZYu29KMNNIDINX7ASX7gOe5qXNHcXFwlmIURB2HOI89l++js2ks/2D0xpEqNGW3mSvVtJxXbi9kYIlR2LN1g5OLpbwrlYSDALIcac1haZRCvJvp1k4q1IU/XY0laeXLqb3pYVeAKVBCKNBCPTpIm7SEgwCyHGjNYW+UyMeNc/yCQ70FaOt0JZamyFkEt1kkt3k47tIVR+HL5glQR0gUkwCyHGhGlmSHZvJdm3DcuU0dVFRVtkU51km7oIlR1LoHT64Apk8mapECSYhRCjSmtNNtVFvHMj2VQ3b2+2lhf/4qFJ9GwhHW8hUjMPX0Bqz4UgK6ULIUaNtkxSsV30NL1MNtWF9CWPBxozF6e3eQX9nZuwzFyhCzTpSI1ZCDEqLCtHonsLiZ4tg33JYjzRVp5EzxbyuQSltafgcnmR1o2xITVmIcSIs8wM/R2biHf9Q0J5XNNk4s30tazCzKcPsn+1GCkSzEKIEaUti3j3myT7diBN1+PdwOIvmUQbfW2vTeK1yceWBLMQYsRorUn17yHRswW0WejiiBGUibcQa1+HZcn/62iTPmYhxIjQWpNLdxPv3AS6OLdfTGey5HJ5ALweD16vm3gihdvtIuD3jUkZtNbE+hO4XW6sweVIXYZBMOgfk8c/PMP7lNP9TfhLGvGFqmUq1SiSYBZCjBBNovtNzHyy0AXZr3v++BfWrHuTi959OrOPncIJs6fxze/9Fwvmz+ajV188JmUwLYtPfO7HXHzBGVRXlfHq6r9jWRY/+s5nxuTxj5xG6xyx9teomHoeLncxvpGYGKQpWwgxIrKpbtKJ1kIX44C272yhrb2bD77vXE48fjoAwaCfvDm2zbNuj4sZ02r5wCXvwO0y2LBp25g+/tEw8ynS/XtkINgokhqzEOKoaa1J9e0s2ibsA3nv4oUEA34ymSypdBaXy0VbRzdTG6rxeNwopUilMry+YSud3X3MnF7P8cdNRSmF1prevjjR0jAtbV0opaitLneaeTOZLE0tnfj9PmqryzEMhaEMPnLFYmYe01Dgn/xwDTZda4tMop1AyRSUe2ya/ycbCWYhxFGz8iny2f5CF+OInHHqCTz7t9X84j8fZt6cmXR09LLpjZ2865z53PT5DxOLJfjP3z/OvJOOIRIO8uvf/Zlzz5rLJYsXctu/38eOXW1c+U/v5sFHl5JKZfjmTdcwf96x9MUSPPjoUt6xcA4/+vf7uOySc7j4gjNQSrHonafi9ozfFbUyyXbMfArD5QXpax5x0pQthDhquUwfuUxvoYtx2JRS+HweLl50Blu3N9PbG+fbX/0on/vUZSx78TUAlr+yjlQ6w+J3n865Z8/jC5/5IP/5+ydoaunk8ve/k7b2buprKvjNz25izokzWP36ZizL4ie/vB+fz0tHRy/HTKvnhq/9kr5YAqUUgYAPj3sc14u0hWVmZOLUKJFgFkIcNa3NcdmMDQPh7HINvBRWVZYSDgdobKjC7/MC8OgTy1FKYRgGSimqKqNYlkV3dwyfz4vf72XOSccQDPg4cfZ00pkM7R29bN3ezLTGagIBH+ecNZfb/9+NhIpy5PWRGa8tJOPBOH7LJoQQo2PoVKB0ZmDlMq31YIi7iJaG93kfw1CgIZ5IEU8kmdJYzcwZDc79k6kMXq9nbH6IUSZraI8eqTELIcTehrTRvv/is9i8ZTdd3bGBudq5HF6vh/KyyLBztdZoPfBtXU051ZVl3PvQs2SyOXK5PK+u2kQimRrzH2W0GDJdatRIMAshjprh8mG4xucIXa01La1dZLI5mpo7ae/sYe36N+ns6uPvb+xk0XmnEgoGeOixZby8YiPP/W0t/3TpOzlmRh0b/7Gdnr44GzZto7Wtm9WvvcHmLbvpiyW49qrFvLJyE9d/6f/xH//1KE0tnZSVlhT6xx0xHl+k0EWYsKQpWwhx1Dy+Ujy+KJlkW6GLckRMy+I7X/0ofr8Xy9RMbazmi5/9J7TWlEUj/OCWT7L69c1ksjmmNFZz5mnHY2lNfW0lX/7ChwGwtOYdC+eiLY3WmvPeMZ+Guire2LKbaVNqOP64qeN7wNcQyuVFGW5Z/WuUTIxniRCioJThweOPkkm2U9SbHChFXyzBs39bzYypdcycUY9SiikN1UxpqHZOq60pH3a3qsooFy86Y9gxF3DOwrnDjjXUVQ77ftbMRmbNbNxnUVpau/jHm7vY3dQx7gIuEK7H7Xl7P7sYGRLMQoijppQiUDqdRO/WwR2IitOHPnA+p508i97eOOnqTEHLks3l6O2L897FZ77VXz0OKMONN1SNMsbvPOxiJ8EshBgRLk+QcMXx9HdspFhrzaeePItTT55V6GIAMG1KLdOm1Ba6GIfNG6jEH64vdDEmNBn8JYQYEUopAiWNeALlBz9ZjEuGO0BJ5YnsveuUGFkSzEKIEWO4A5RWz8PlCRa6KGKEKcNNScWJuH2l465PfLyRYBZCjBilFG5flJLKE8ft9Cmxb6Hy4wiUTpVQHgPSxyyEGFFKKfwljaAMYu3rsfITZ1GNyUgpF+HKEwlFjyl0USYNCWYhxIhTysAfbkBhEOvciCnrKo9LSrkpqTqJYHQGSkkD61iRYBZCjAqlFL5wHeW+Uvra1pBNdY3bjS4mI4+/jHDF8fhCNRLKY0x+20KIUaOUwuUJEq07nXD5bJQhdYGipwz8kSlE68/AH66TUC4A+SsRQowqpRQut59wxWx8oSriXW+QSXaCNgtdNDGMwuUJE6meizdYiSFvogpGfvNCiDGhlIE3UElZfRnJvp0k+7aRz8QKXSwBuNwBgtFjCESmyFS3IiDBLIQYU8pwEYzOwF9STzreTLJnG/lcXPqfx9xAN4M/3ECw7Bhcbr80WxcJCWYhxJizm7dD0WMIlDSQiu0hHW8mm+wodNEmBbc3QqB0Kv5wAy5PUOYmFxkJZiFEQRkuH8HoMfhLGslnYyR7t5FL92LmkhTrmtvjkeH24/aWEIrOxOMvw3D7JZCLlASzEKLgBmrQPgxXJd5AJZaZJdm3g3y6l0yyHW3lCl3E8UkZ+AKVePxl+CONuL0Du1hJIBc3CWYhRNGwA8Pl9lFScRyWmcfMp8hnY8Q7/4Fl5bDMrIzo3h9lYLi8KMNNKDoTb7ASl8uPcnkljMcRCWYhRJFSGC4PhsuD21uCP9yAlU+RSXaQz/aTz/SRSXbIoDHA7YviC1bi8oTwhapxecIADGSxBPJ4I8EshCh6Tk3aEyRYOg2tNZaZxcqnMPMpMok2sqkuLDOLtvITtulbGW6U4UEZLjz+cvyhGlzeMIbLh8sdGIhgqRmPexLMQohx560+aS9uXym+UC0A2jLJpXvIpjrQVh4zN9AMbubTIxbWb7y5i/WbtnPB+acRLQ2PyDX3RSmXM2DL5QmhlAtPoBxfsOptK6hJM/XEIsEshBi39g4k5XLjC1XhC1WhtUZbeSwz49SiLStPPttPNtlJPhNDowENWqO1hdYW6MFj+xgRHk+k+MFP/4eXVmzg57d+jvdffPZhhKKyCz0wX1gZg/OG32oN8AWrcfsiTj+xodwDX0sf8aQiwSyEmJCUUqjBPmq0dmLWF6olVDZryJkaK5/BzCXI5xJoM4ulTbSVB20OBPxgaD/y1GO8tGIDqVSGZS9u5J//+cMYhh2YakifrhoMYAUYKMOFUq7Bpmg3Lrcflyc0OIfYtd/yi8lJglkIMfEpdYAhUAqXJ4DLE8BL5V636YEKNJrenh4e+d8XSaUyAKxYs5lI9cm43O4hV3rr34GUHjwiISsOgwSzEELs11u14BdfepmlS5c5t8Ri/SRTGUpL/YUqnJigZGFUIYQ4iFQqxS9+8Qu0fqvfOZFI8MQTTxSwVGKikmAWQoiDWLJkCatXrx52LJVK8cILLxSoRGIik2AWQogD6Ovr4w9/+AM9PT1vu62rq4t4PF6AUomJ7KDBrJS6SynVrpTaMORYuVLqr0qpNwc/lw0eV0qpXyqltiil1imlTh3NwgshxGhbt24dTz311D5v27hxI7t27RrjEomJ7lBqzHcDF+917OvAc1rrWcBzg98DvAeYNfjxGeA3I1NMIYQYe/l8np/97GfkcvtenGTbtm20trYO63sW4mgdNJi11s8D3Xsd/gDwh8Gv/wBcNuT4PXrAK0BUKVU3UoUVQoixorXmmWeeYfny5fs9J5PJ0NbWNoalEpPBkfYx12itWwa/bgVqBr9uAHYPOW/P4DEhhBhXUqkUjz32GF1dXQc879FHH8U0ZbcrMXKOevCX1nrfa9cdhFLqM0qpVUqpVR0dHUdbDCGEGFEbNmzg7rvvPuh5S5cuxbJkhysxco40mNvsJurBz+2Dx5uAKUPOaxw89jZa6zu01gu01guqqqqOsBhCCDHyLMviP/7jP8hmswc9N5fL0dS0z5c5IY7IkQbz48BHB7/+KPDYkOPXDo7OXgj0DWnyFkKIceGVV17h2WefPaRzU6kUzzzzzCiXSEwmB12SUyn1R+B8oFIptQf4DvAj4EGl1CeBncCHB09/CrgE2AIkgY+PQpmFEGLUZLNZ/vznP9Pa2npI5+dyOdatW4fWWtbEFiPioMGstb5qPzct2se5Gvjc0RZKCCEKQWvNhg0b+M1vfnPIU6C01rS2tpJMJgmFQqNcQjEZyMpfQggxxN13333Yq3mtW7eOLVu2jFKJxGQjwSyEEIM2b97M448/ftj327p1K3v27JGFRsSIkGAWQggG+orvuOMOdu7cedj31Vqzc+dOCWYxIiSYhRCTntaaHTt28PDDDx/xNR577DFZaESMCAlmIYQA7rrrrqPakGL9+vX7XVNbiMMhwSyEmPT27NnDH//4x6O6Rn9/Py0tsmyDOHoSzEKISW/FihX73G/5cGQyGZYsWTJCJRKT2UHnMQshxER30UUXcfPNN/OXv/yFTCYDQCKRIBaLkUgkSCaTB22mzuVyrFy5ciyKKyY4CWYhxKQXDof59re/zbe//W0ATNOkra2N7du309TUxAMPPMAjjzzCvHnzOO+889i1axcbNmxg27Ztw0Ziy2YWYiRIMAshxF5cLhf19fXU19eTSqV47rnnADj33HO57bbbyGQyTk0a3tqX+cQTTyxkscUEIcEsxAEcaF6q1hrLstBaO1+bpolpmliW5dxm16KGXsteU1kphWEYzmfDMHC5XLhcLuf40I/9kTWaR08ikWDTpk0opSgpKSEQCBAIBIhGo8POmzNnToFKKCYaCWYx6dmBaYfp0LmouVyOTCZDJpMhn88PC929728H9NDvh37en6Ghu/fXe3+2g9swDDweDz6fD7/fj2EYzjlDQ33o/cWRyWQy7Nq1C8MwCAaDhS6OmAQkmMWko7Umm82SyWTI5XJOLTefz5NOp8lms2O6gtPQMD9aLpcLv9+Pz+dzQtztduP1evH7/bhcrhF5nMkkn8/T29uLz+dj6tSphS6OmAQkmMWENLRp2bIs8vk8/f39JBKJYbeNZCgWA9M0SSQSJBIJ59jetWi32000GnWC2r79YM3lk1UmkyEej1NeXs6pp55a6OKISUCCWUwIdrjaL6KmaZJOp0mn05N+NSatNfl83vneHrgEYBgGXq+XYDCIx+PB6/USDoeHNYVPdj09PViWhd/vZ/bs2YUujpgEJJjFuKS1dmrDqVSK/v5+0uk0pmlO+iA+HJZlOW9gAKfv2u12EwqFKCkpweVy4fF4Jm1Qd3R0ADitDUKMNnmWiXEln8+TTCbJZrPEYjFnuooYGZZlOYPdEokE7e3tuFwuotEoXq+XUCiEz+ebVCG9adMmAAllMWbkmSaKml0zzufzdHR0DBuwJcaGaZp0dXUB4PF48Hg8RKNRwuHw20aAT0Rr1qwB4Jhjjinan3NfMwH29fVI2N8MApkFMHIkmEVR0loTj8dJJpPEYjFnmURRWLlcjlwuRzKZRClFJBIhGAxSUlKC1+stdPFGxZYtWwCKZuDX0FaNofPo7dkFQz/y+fzbpgAeLXu+vdvtdubcD/0YOv/e6/Xi8/mcwYXi0Egwi6Jhv7j09/fT19dHKpWSmnER01rT19dHX18f3d3dhEIhysrKnKbuifJCbNc2jz322DF5nKEL0+RyObLZLKlUyhkHMLQVqRBLgNrz+IcOKNwXe7S/2+125tm73W78fj+BQACv1ztscZ2J9Jw5WhLMouDsecV9fX309vaSzWYLXSRxmOwaXE9PDyUlJZSWllJSUuK8II9XmUzGeXNYV1c3ote2wzefzztvQu1pfdlsdtyvu23PBtg7wGOxmPO1PaAuHA7j9/tRSuH3+/F6vZO6li3BLArG/sPt7OwkHo9Lc/UEoLUmFosRj8cJBAJUVVURDAbHbW1ox44d9Pf3o5SioqLiiK4xtK/Xrm3aAxft1eTGelGbYqG1JpfLDdty054V4HK58Pl8lJaW4vV6h9WsJzoJZlEQ+Xyenp4eurq6DtokJsYfy7KchU5KSkqoqKggFAqNuxfVTZs20dPTQyAQwO/3H9Z97SbnVCpFNpslnU4Ti8Wke+Yg7HEMAPF4nK6uLpRShEIhQqGQs4qdHdYTkQSzGFOWZTl/bENXpxITV39/P6lUimg0SkVFBW63e9y8oLa3t5NMJolEIgedyz10M5NUKuV0y2SzWQnjo2QPBo3H486gMo/HQyQScbpMJlJtWoJZjJlsNkt3dzddXV2TstluMhvaZVFbWztuas+JRIJ8Ps+UKVMoKSnZ5zn2GIlkMumEhwTx6NFaO2Ma7KD2+/2UlpYSCAScrpPxTIJZjDr7D6m5uVkWBJnk0uk0e/bsoaKigoqKiqLue7Ysi/7+fkzT5Nhjj6W8vBwYPnrarhmnUikZI1EgWmtSqRSpVAq3200gECAcDlNaWups2lKsz7H9kWAWo0prTSKRoKmpSZbKFMBA7bmtrY1MJkNtbW3RrqiVy+Xo7u4GcGrM9pvMRCJBd3e3hHGRsUe19/f3097eTnl5OaFQiGAwOK5mCBTnX4SYEOx3shLKYl96e3sBqK+vL8qa89BghoEXfbvPWQK5+JmmSUdHhzN4r7KykkAgUJTPtb1JMItRYYfyrl27ZNS1eBu7OdgO57q6uqLbKzqZTLJ161aUUiSTSbZs2SJ9x+OQXYuOx+MEg0EqKysJBoNF93wbSoJZjDh7bmJLS8uECuV8Ps+WLVuYOXMmHo/nqK6zdu1aAE4//fQjvo5lWfT29rJjxw5qamqora3F5XI5K0btPcDOXmmp2PT19REIBCgvL3dqMvYcd611QXa2srtgtm7ditfrpaqqSkJ5nLP/T9PpNKFQiOrqanw+H1B8fdASzGJUdHZ2kkqlCl2MEZVIJPj5z3/ODTfcwEknnXTE1zFNk6VLlxIOh484mLXWrFq1iieeeIJPfvKTPPnkk0ydOpXFixezfft2brvtNhKJBEopTNOkvb2d3/3ud8yYMeOIyz2Shr4Qaq3p7OwkGAwSCASAgfmrX//61+nu7ubaa69l3rx5TpP3aLKnPCUSCbZs2UJ7ezvRaJRZs2aN6uOKsWOaJrFYjEQiQXl5OeXl5Uf1Rns0SDCLEWcvpDDRhMNhvvWtb1FfX7/fc4au8rR3X5Z9m8fj4aSTTmL79u1HXJZMJsP999/PVVddxfTp07nyyiv54he/yPTp0zFNkyuvvJJp06ahlGL37t088MADlJaWHvHjjbZcLkdfXx8+nw/DMGhvb+c3v/kNWmsee+wxFixYwLnnnstnPvMZ6uvrnQFjIxnUdii3trbS19fn9CN7vV5qampG7HFEcbD7oFOpFNXV1U7/czGQYBYjSmtNb29v0Tdhx2IxNm/eTCaTobGxkalTp6KUor+/n507d1JXV8eWLVtwuVwcf/zxhMNhYKBP1O/3U1FRwc6dO/H7/XR1dTFt2jRCoRCdnZ1s377dWVji7LPPdlaMampqYvfu3WitaW5uHlaepqYmdu7cicvlYvbs2USj0QOWv7u7m2Qy6dSAg8EgjY2NbNy4kcsuu4wTTjgBwzDQWtPU1MSZZ55JWVnZKPwmR053dzdlZWXOLlX2G5lUKsXy5ct56aWXuP3227ngggu4+uqrOf3002loaBiRF1OtNclkkvb2dmfhG/uzy+Xa7xxmMf7Zu9jV19cTiUSKorun8CUQE0oulyv6Fb1isRjPPfccbW1tvPbaa/z0pz9l9+7dmKbJCy+8wC233MJTTz3Fpk2b+N73vscjjzxCd3c3jzzyCDfeeCNr165l586d/O1vfyOVSrFp0yaam5vJZDLcfffd5HI5qquree6557jjjjvI5/M0NTXx+9//3llacPXq1cBAIPz9739n9erVdHd389RTT/Ff//Vf9Pf3H/Bn2LRpE6FQiEgkAgyEx/z58511ne0XF601zz//PDNmzCia2sD+2POC98c0TXp7e3n44Ye58sorufrqq/nmN7/pDDA80kVr7FWlmpqahj13N27cCAzUmO0mdjExWZZFc3MzXV1dRbF5iASzGFGmaRb9VJL169ezZs0aGhsbOeOMM+js7GTp0qUYhsGxxx5LJBLhfe97Hx/5yEf4xCc+wb333kswGOT888+np6fHqfG+8sormKbJ+9//fkKhEA899BA9PT2cffbZzJo1i5tvvpm//e1vvPrqqzz99NNUV1dzxhlnMG/ePC688EJgYDW0xx9/HNM0mTp1KmeeeSZ//etf2bNnzwGDpre319lSzxaNRt8WUP39/bS1tXHKKaeM3i90BB1qF0g2m2X58uX85Cc/4dRTT+XSSy9lyZIlTovEodJa09/fz549e962q9maNWsAKC0tLYpalBhdlmXR3t5Oe3t7wQf6ybNNjCi7n66YPf/88yQSCdrb2+nt7eUTn/gECxcuBN7a2SYSieB2u5k3bx41NTUYhjGsD+r4448nGo1yyy238L//+79UVVU5TdF233I0GiUej7Njxw6WLVvmbCIPOM3b/f39rFmzht7eXtra2vB4PHzlK1+htrb2gD9DVVWVs1evra+vb9gIZq01y5Yto6GhYdw0xdpdIIc6cNA0Tbq6unj66ae59NJLufrqq/n2t7/N5s2bMU3zgM9He0pfa2vrPl+I29raAIq+C0CMHK013d3d9PX1FfR1TPqYxaSjlKKyspLzzz8fj8eDZVnOJvR7sxfL35vP5+PGG2/kxRdf5O6776a5uRmfz0dHRweWZTkB7PV6KSkpIZ1O7zcklFIcd9xxnH322SilyGQyB212njt3Lvfeey+xWAy/349pmqxevZqFCxc6983lcrz22mt87GMfO8zfUOF1dnYe9n3y+TwvvPACL7/8MrfffjtnnXUW//qv/8pJJ53ElClThtV67Sl9ra2t+9z/2w5tQEZk78VuZejv76eqqsoZE2Df1t3dTTabpaqqaliLjtaatrY2DMOgsrKyaFshLMuitbUVr9frjC0Za8X5mxHjWrH3ZZ5//vksXbqUNWvWkM/naW5uZu3atcNGVNtNwps3b6aqquptLyIbN25k8+bNXHbZZXzqU59i69atnHfeeXR1dTnNqel0mvr6ek4//XTOPvts1q5d67wT7+jocOZTnnbaafz+97+ns7OTbDbLmjVraG9vP+DPEAqFqKmpYdu2bc4ykZ2dncydOxelFFprdu3aRXd3d1GPxh4qn8+Tz+fJ5XIH/fPE4ecAACAASURBVPkPxDRNuru7efLJJ7n00ku58sorufHGG9mxY4dTiwbo6ura79rt9jaNACeccMIRl2Wisf8mHnnkETZv3sydd95JR0eHs8Xl888/z3PPPcfq1au58847nRaQXC7Hn/70J1auXMnSpUt54oknirplzW7WLtQgVglmMaJcLlfRzQnc28knn8zll1/OPffcw9e+9jVefPFFTjvtNCd8k8kkf/zjH1m9ejUbNmzg2muvxeVykcvlmDdvHpFIhGw2y5IlS1i9ejVbt27lnHPO4bTTTuM973kP999/P2vWrOHBBx/ks5/9LLW1tfzzP/8zHo+Hb3zjG/zyl78kkUjw5ptvsn79ev7lX/6F8vJyfvjDH/Ld734Xt9tNbW3tAd/geL1ePvShD/Hyyy+zatUq7r//fj784Q8zdepU55xsNstZZ51VsHf9h+uBBx7gvPPOY/r06Vx//fUjck3TNHnllVf41a9+xZlnnskll1zCk08+ydatW51Vx/bF3rIROOD0uMmmu7ub//zP/+TCCy/k3HPPpaysjIceegiAPXv28Oyzz/Lud7+bCy+8kN7eXh5//HFnAGJzczOLFi3ikksu4dVXX+WFF14o6nBOJpPOmJKxJk3ZYkR5PB7C4fCwNYaLTSAQ4LOf/ex+bw+FQlx44YVs27aNT3/6086I3LKyMu68805gYJBSY2Mjzc3NXHzxxRx33HEYhsHVV1/Nrl272LFjB+9///upqKgAYOrUqdx2222sWbOGuro6KioqCAQCzpuYH//4x28rR3t7O7t3795nGWfOnMm8efM49thjWbFiBRdddNGwqUNKKU488UROPPHEI/9FjbF4PE57e/uojIrVWtPe3s4zzzzDX//6V+bPn89Xv/pV5syZs8/ze3p6nGAuxD6/e4eB3Qqyt6HjCQ7l/EO93v4sX74cy7KcxV7OPfdcvvvd75LJZHj00UepqamhsrISgGuuuYZf/vKXXHDBBSxZsoSLL77Y+Vs699xzWblyJQsXLizqN/K9vb2UlZWN+UYrEsxiRBmGQSQSoa+vr+AjG4+EZVlYlkVlZSUNDQ37PS8SiRCJRJg+ffqw40oppk2bxrRp0952H7/fz9lnn33IZdm0aRP333//Pm+7/vrrmT9/vjNafCL47Gc/yw033EAsFuMHP/gBf/7zn0flcbTWrF+/ntWrV+83mO0tSj0ez5j3hVqWxcMPP8yUKVN49dVXqa6u5kMf+hDLly9n6dKlZLNZtNZ84xvfoKysjP7+fpYuXcoLL7xAf38/73znO7n88svxer08/PDDrFu3joULF/L000+TyWT46U9/SiQSYc+ePTz66KM0NzfT29vLF7/4xYM227e3tw97DttvPNeuXcvmzZv54Ac/6NxWUlLCG2+8wZtvvskbb7zBFVdc4QR/IBDg5Zdf5rrrrivqYM5kMuTzeQlmMf6FQiFCodC4W/0rkUhw3333sWvXLn7xi19w1VVXMWXKlIKV5/zzz58woXswLpeLKVOmOM3u9vzskeb1ern88suZPn06l1122X7Pa25uJpVKDSvTWMlms7z00kv8/Oc/Z+bMmaxdu5Z169axbNkyvvrVr2IYBjfeeCNr1qzh3e9+N//3f/9HNBrltttuY9OmTdx8883MmTOHOXPmUFlZyZ49e5g9ezannHIKt9xyC1u3bmXevHk8+OCDXHHFFdTX13Prrbfyq1/9il//+tcHrTU3NjY6X3u9XkzTZPv27RiG8bYR7C0tLU4f9N4BbK8dUOwSiYQzi2KsSDCLUVFVVUUqlRpX2z36/X4+/vGP89GPftQZuS3GRllZGaFQyPl+pNZZj0QiTJs2jVmzZnHttdcyd+5cwuEwbW1tBwygeDxOPp9nxowZo/YmYX88Hg+5XI4vf/nLfOxjH+Od73wn3//+96muriYcDqOU4tZbbyUcDpNKpVi2bBm1tbXOtK/Fixc7TcbRaJTa2lpmzpwJDPSXd3V1sWfPHlavXk19fT2GYVBVVcWMGTMwTfOgtcO+vj7na601hmE4e1Xv/f8WDAadUNs7hEOhUNEPFIWB54LdMjBWJJjFiFNK4ff7qa2tpampqShW0jkULpfrgM3XYnSEw2EqKyuHvUgfzSI1Pp+PefPmcdFFF3HSSSdxySWXUFJS4lzf3txjf4b2vVZUVDg7EI0VwzD45je/ya9//Wu+8pWvcNNNN7Fjxw6qqqqGlcuetrR7926uuOIKZy7+gfqO7b7lnp4ewuEw73nPe5zlXw9lDQLDMNi6davzfTqddub7L1myhI6OjmHnH3vssUybNg2Px/O2aWknnnhiUTdj2wrx+iXBLEaFUopIJIJlWbS0tIybcBZjKxQK0dDQ8La9cQ8nmH0+HzU1NdTX13P11Vfzrne9i8rKSqqqqo5oz13TNInH48BAX+hY9y9mMhl8Ph+33HILL730Ej/5yU+YP38+y5cv57zzzuPYY4+lpaWFrq4uFixYwOmnn86jjz7KnDlzCAQC7N69G4/H87bR5EODd+rUqezZs4dly5bx3ve+F601O3fuJBKJHHDDjrlz53LXXXdhWRYul4udO3fi8XhobGzkAx/4AGvXrnXm8W/ZsoUZM2bQ2NjIxRdf7DRpa61paWnhrLPOGjYHuliNdTM2SDCLUaSUcubQ7m91JTF52aG8r1rToQTz9OnTueiii5gzZw6LFi3i+OOPP6SmUZfLhdfr3efCIjCwGtubb77prGteiMFf99xzD1dddRW5XI4ZM2bwsY99jH/7t3/jpptuYv78+c6UMo/Hw0UXXcQtt9zCD3/4Q+rr6znmmGOchWaampqIxWL09/c787tbW1uJRqMsWrSI3/3ud2zevJnS0lLn93kgp512GitWrOCZZ57h1FNP5aGHHuIDH/gAhmGwcOFCVq5cyYoVK6ipqeF3v/sdn//85/F4PJx33nncf//9HH/88SSTSVavXs0XvvCFol1kZKhCrJqnimEe2YIFC/SqVasKXQwxSuxNApqbm8dVn7MYHXZrSl1dnbOE6d7e8Y538NJLLw27T1VVFZWVlZx99tlce+21NDY2Ultbi9/vP6y+SnvDgv3NY969ezfXXnstfX193HTTTVxzzTWH/0MehWw2yxtvvMHu3btJp9O8853vpLy8nO7ubqfMtbW1Th+t/fOk02mUUs5t8NYuZHYtuLW1lUAgQEVFBel0mpaWFkzTxOfzUV9fj8vlore3d59vol0ul7PM7Lp162htbeXEE0/kmGOOcWq+XV1dvPbaayQSCU444QRmzZrllLGlpYXVq1fjdruZP38+dXV1Rd/HbBgGs2bNGpUm9wULFrBq1ap9/gKkxixGnVKKcDjM1KlT6ejoGHejtcXIcbvdVFdXE41G37Zf9VD2gKtIJMKFF17I3LlzueCCCzjttNOcPt8jfVG3n4/7Ww85l8sRi8XweDwFWSfb4/E4o6pt9mDEfQ1INAxj2EjpocrLyykvL3e+HzrLIBAIcMwxxww7X2vNz372s32uQ1BdXc0tt9xCOBweNmVq6P9DRUUFixYtettthmHQ0NAwrHm92EMZBjYwOZLukKMlwSzGhFKKQCBAfX09gUCA7u5uqT1PInazcE1NzSHVcH/1q1+xdetW6urqmDp1KqWlpSP2Qm7X2Ds7O/e5RrplWeTzecLhcEEGAxY6sD796U/vcylKe073gcp3sLIX+mc7HG63e0Sfd4f12GP+iGJSc7lcVFZWEolEnNqzDAyb2Px+P+Xl5U7t81Be6GbOnOlM8RmNF0alFHV1dezatWtYs63d7WJZFoFA4G0LyEx0Sqlhy7pOZvYUPglmMeHZT3K7T6usrIz29nZSqZQE9ASilMLtdlNRUUEkEhm2HeWh3n802S045eXldHZ2DmvSbmlpAd6qMYnJJxQKUV5eXrAavgSzKBjDMAgGg0yfPp1EIkFvb68zelSMX4FAgEgkQjQaxe12F23zpWEYVFdXY1kWXV1dzvH9rU8uJgefz0ddXd2YT5MbSoJZFJT9oh0OhwkGg6TTaSeg7a0XRfEzDAOfz0dFRQXBYPCwa8iFVF1d7ewjDLBz506AYSuRicnB5/PR2NhYkLnLQ0kwi6JhGAaBQIBAIEBNTQ29vb0kEgkSiYTUoouU/f8VjUadZSDHSyDDQFkNw3Cm7vT09LB9+3YA5s+fX+DSibFUUlJCTU3NmK/0ti8SzKKo2C/qLpeLiooKotEomUyGbDZLR0cH+XxeQrqAlFK4XC5KSkqIRCL4fL5xVTveF7vsNTU1BAIBZ6T2vHnzClksMUaUUlRUVFBRUVE0S4RKMIui5nK5nFpZaWkp2WyWWCxGJpMhmUzud/UmcXB2N8GhTHEJhUL4fD5n57ChKzaN51AeyjCMYfNWD7Q0pZgYAoGAM0ukmEgwi6I39IXf5/NRWVmJ1ppsNks+nyeRSNDf308ul8OyLOmXPkqGYWAYBn6/n9LSUrxeLz6fb7+rdE0k3d3dzpu9qVOn4vV6Zb79BGRvUWnXkovteS3BLMYde8Uov9+P1ppQKER1dTWmaZJKpZyR3el02glr8Xb2i5Hb7cbv9+PxePB6vZSUlOD1eoftSDRZrFy5kt7eXvx+PzU1NcycOZOuri76+vqkdWYCMAyDSCRCeXk5gUCgaJ/bEsxiXBv6h+V2uykpKXH2hs1ms+RyOUzTJJPJkEgknP1iD2WLu4lk6PKXLpeLcDhMIBDA4/E4mzpMhhrxwaxfv55YLOYMArKXEC0tLSUWi9HZ2Slv9MYhwzCcucmF2JjkcB00mJVSU4B7gBpAA3dorX+hlCoHHgCmAzuAD2ute9TAX/YvgEuAJPAxrfWa0Sm+EPumlMLn8w3bVq6qqsoJ5FQqRSKRIJ/PY1kWpmmSz+edIB+vlFJ4PB7cbjcul8v58Hq9hMNhZ3DL0ACe7GE8VDweJ5/POwPB4K39xX0+n7OZRDweJ5VKTao3d+OR1+slGAxSUVHhTIEaD8/3Q6kx54GbtdZrlFIlwGql1F+BjwHPaa1/pJT6OvB14GvAe4BZgx9nAr8Z/CzEmNv7j3DovOlwOAwM1J7t9ZH3HvWdzWZJp9OkUilM0xxW097Xi/JIvFDv64VjaLOy/eHxePD7/QQCAWfAkr3iltvtdvqKx8MLUTGwnwcw0L8cDAaH3W7/bquqqohGo6TTaWf3JqlFFw/7b6OyspJAIHDYu48Vg4MGs9a6BWgZ/LpfKfV3oAH4AHD+4Gl/AJYxEMwfAO7RA69QryilokqpusHrCFF07ClALpdr2BzGoSG7d+BaluXUtPf12R6EZn/eV2AP3XnHnk9rGAYul2vY56Ff7++Nxnh74SlGuVzO2VZxxowZzhu3vSml8Hq9eDweSkpKyOVy9PX1Oa0w47nFZbyyl1i1WzV8Pt8Bdy8rdofVx6yUmg6cArwK1AwJ21YGmrphILSHrmm3Z/DYsGBWSn0G+Awgi6aLonSg5t5i76MShy+ZTNLa2gowrNl/f+znhNfrpaqqCsuySCaTZDIZYrGYrP8+yuyacWlpKX6/n2AwWNRLwB6OQw5mpVQY+BPwJa11bOgPr7XWSqnDasPTWt8B3AGwYMEC6agRQhRUMplkz549R3x/wzAIh8OEQiHKysrQWhOLxZzlZe3pfeLIGIbhtFR4vV4qKiqGBfFECGTbIQWzUsrDQCjfq7V+ZPBwm91ErZSqA9oHjzcBU4bcvXHwmBBCFK1UKkVra+tR7yo1tAm1rKyMaDRKPp8nk8mQy+XIZDL09PTInPuDsH+PwWCQSCSC2+12BnROpBDel0MZla2AO4G/a61/NuSmx4GPAj8a/PzYkOOfV0rdz8Cgrz7pXxZCFDOtNclkkpaWFqLRKKeccsqIXXvoSHmbPUMgmUySSqVIp9NYluVM8TuYdDpNV1cXDQ0NI1bOQrLHdxiGgdvtdlaYs6fwjef+4iNxKDXmdwAfAdYrpV4bPPZNBgL5QaXUJ4GdwIcHb3uKgalSWxiYLvXxES2xEEKMArtW29jYyEknnTTi1x8aLPYo+kgkQklJCTDw5iCdTpPNZtFak8vlnGVnc7mcU7u2LIs777yTVatWccstt3DMMceMm9CyB1raq8nZi3zYMwxkLv2AQxmV/QKwv9/Uon2cr4HPHWW5hBBiTNmjqe0BRWNlaB9pMBgkGAwOm5Jnf1iWRTqd5he/+AX33HMP2WyWpUuXMnfuXLTWw2YEAGMy8GxobdaePTA0XO0d4+yBWfYsg73vK4aTlb+EEALYtWsX8FbTcyHta0CT1ppnn32W22+/nWQyycUXX8zXv/51ampqnAVyTNN05tsPnaq3r6Af+r39tf2Yez/+0BDd+8OexudyuZw59BK4R0eCWQghgCVLlgBQXl5edNPhtNasXbuWG2+8kdbWVs4++2zuvPNOampqhi0qs6/7Hcq193YooSrBO3okmIUQAlixYgVQnOsqtLS08IUvfIHNmzdz/PHH87Of/Yy6urpD2rLzYCRgi09xvS0UQogCSSQSAMycObPAJRmutbWVT37yk7z00ktUVlZy6623smDBAgnUCUxqzEKISW9oc+5xxx1XwJIMF4/H+d73vsezzz6Lz+fj61//OpdddpmE8gQnNWYhxKTX0dHh7Lc8e/bsApdmQDab5b777uOuu+7CMAxuueUWPv/5zxe6WGIMSDALISa9Xbt2kU6nASgpKSl4jVRrzRNPPMHXvvY1MpkMH/7wh7npppuczRnExCbBLISY9IYGc6FprXnuuee4/vrricViLF68mO9///vO/tBi4pNgFkJMes3NzWQyGSorK/F6vQUrh9aaTZs28cUvfpHOzk6mT5/OT3/6U6ZPny415UlEglkIMalprWlrayObzXL66adTVlY24tdvb28nHo8fcF6x1ppdu3Zx8803849//IPq6mr+8Ic/MGfOnBEtjyh+EsxCiEnNXqNaa83cuXOdtatHyhtvvMFHPvIRpxa8P7lcju9///v85S9/oaysjN/+9recddZZUlOehGS6lBBiUjNN0xmRba/pPFIsy+Kuu+7i2WefRWvN7t27+fGPf8y8efOGrS6WTCb5t3/7N/77v/8br9fLN77xDd73vvc5m12IyUVqzEKISS2RSNDc3Aww4kHY1NTEiy++6Kxb/de//pUrrriCJUuWDFuj+re//S0//vGPsSyLa665hk9/+tMj+gZBjC8SzEKISa2zs5P169fj9XqJRqMj1nSstWbFihWsXLly2PHNmzdz3XXXceedd5JKpXjyySe57bbbyGazXHDBBfzoRz8iEomMSBnE+CRvyYQQk1pfXx9bt26lpKSE+vr6EbtuLpfjwQcfJJfLve22PXv2cN1117F27VqWLVtGW1sbCxcu5A9/+AOVlZUjVgYxPkkwCyEmNXsv40AgQF1d3Yhdt7Ozk2effXa/t1uWxe233w4MrM/97//+71RWVspgLyFN2UKIyUtrTT6fByAUCtHQ0DBi17777rvp6+s7pHNLSkoIBAISygKQYBZCTHI7d+4EIBAIUFtbOyLX7OnpYenSpZimeUjnv/7661xzzTWsW7cOy7JGpAxi/JJgFkJMauvXrwcGRmR7PJ6jvp7WmhdffJFXXnnlsO6zfv163vve9/L4448707fE5CTBLISY1LZu3QoMBPNINCWbpsnLL79MPB4/7Ps2NTUNG7F9oJXCxMQlwSyEmNR27doFwKxZs0bkeolEgt/85jdHfP/29na+/OUv853vfIdEIjEiZRLjiwSzEGLSsiyLtrY2ABYtWnTU19Na86c//Yn+/v6juk4ymeS+++6jvb39qMskxh+ZLiWEmLQymYwzz/iss8466uul02n+/Oc/OyO9j9SsWbP4yle+MqLzqsX4IcEshJi0UqmUMwr6aLd71FqzcuVKVq9efcTXCIfDXHHFFXzuc59j/vz5Mn1qkpJgFkJMWm+++SapVArDMI46BE3TZPny5c6624fD5/Nx7rnn8uUvf5lFixaN2EA0MT5JMAshJq3XX3+dRCJBZWXlUU+VSiQS3H333Yd1H8MwqKur4wc/+AEXX3wxNTU1EshCglkIMXlt3bqVdDrNySefTCAQOKprvfTSS85iJYeiqqqKa665hptvvpm6urph20CKyU2CWQgxadn9y42Njfh8vqO6zn333bfPDSv25vV6WbRoEV/60pc4//zzj7pvW0w8EsxCiEnJNE0nSBsaGvD7/Ud8rddee+2gK30ppTjjjDO44YYbuOyyy2RtbLFfEsxCiEkpHo/T2toKQHV19RH3MVuWxcsvv8y2bdv2e055eTnXX389n/rUp5g+fboEsjggCWYhxKTU29vLtm3bUErh8/mOuI83kUhw77337nPzibKyMhYvXsx3vvMdZs2ahdstL7ni4ORZIoQYN/ZeO3p/a0lrrdFaY1mWc87e53Z3d9PW1uZMlcpmsyilUEodMKT3ru02NzezatWqYccMw2D+/Pl861vfYvHixQSDwUP+GYWQYBZCFAU7TE3TxLIsLMvCNM1hgWqaJplMxvnY+3b7OoeitbWVxsZGSktLCYVCbNmyZdjtewewHdperxefz4fP58Pj8fCtb33L6atWSjFt2jQ++tGP8oUvfIGysjIZbS0OmwSzEGJU7S8oLcsimUySTCadgDVN0/nI5/P7DN6R0tDQwG233UZfXx+VlZWHvA9yLpdzNpeIxWJOoHu9Xv7pn/6Jyy+/nFNOOYV4PD5s8RKfz0c4HN5vX7b0OwubBLMQYlSYpkk2m3VqvtlslmQyOWwZzKFNzWPNMAzKysooKys74muEw2HOOeccKioq+Jd/+RfmzZuHx+MhlUq97Vy7xm1/+Hw+gsEgXq8Xj8eDYRh4PB7cbreE9CQnwSyEOGJDQ9WyLDKZDIlEglwuRz6fJ5VKkc/nJ+y+woZh8OlPfxqt9UGbrO2mels+nx+2raPL5cLv9+P1ejEMg1AoRCAQGDZgTAJ7cpBgFkIcFrvJOZfLYZom8XiceDxOPp93+oYnE7sGfLRM0ySRSDhh3dPT4wxECwQClJaW4na78Xq9zlraEtQTkwSzEGK/9q4R9/f3k0qlnGZp0zQLWLqJzX6DY78JisViAASDQXw+H16vl0gkMmzlMAnqiUGCWQixT3a/cCaToaenZ7+joMXYsgfMAXR2duJyuYhGo4RCITweDx6PRwJ6nJNgFkIAb9WOs9ksvb29ZDIZ4vH4pGuaHk/sEezt7e3OVK5wOEwoFCIcDjsBLUE9vkgwCzHJaa3JZrOk02m6urrIZrPk8/lCF0scJq21M7+7p6cHj8dDJBJxmrtHYs9pMTYkmIWYhOzacSqVIhaLEYvFyGazBS6VGCn2CPmOjg66urooKSlxPiSgi58EsxCTiL1MZTabpbW1lXQ6LQO4JjjLsujr66O/vx+3201VVZXTHy0BXZwkmIWYBOwacjwep6enh/7+fhnENcnYb8iamprw+XyUlZURjUadqVeieEgwCzHB2X2PHR0dxONxqSELMpkMbW1t9PT0UF1dTTgcxuVyFbpYYpAEsxATmGmadHZ20tPTIwO6xDD2G7bdu3cTiUSorq7G7/cXulgCCWYhJiStNalUivb2duLxeKGLI4pcLBYjnU5TWVlJNBqVHbEKTIJZiAlGa01/fz/Nzc1SSxaHLJvN0tzcTDabpbKyctga3WJsyW9eiAlEa01PTw9tbW3SlyyOSFdXF7lcjtra2v1uUSlGl7RXCDFBaK3p7e2lpaVFQlkcMa01fX19tLS0SItLgUiNWYgJwG6+bm1tLeppUHY5U6kUhmFQXl5edKOBLcsiFouRz+eHTSeyd9Xq6+vDMAwikciwxTpyuRy9vb34fD5KSkqc4/Ygq1gsRigUIhgMjovpSf39/bS3t1NTU1N0/0cTnQSzEBOA3T9Y7DXl9vZ2HnzwQfr7+3n11Vf57W9/S21tbaGL5dBas3TpUjZv3gxAdXU1ixcvpqSkhEwmw9NPP01LSwsul4upU6dy0UUXoZSis7OTZ555hp6eHnw+H3PmzOHMM89EKUVLSwtPPvkk6XSaUCjEOeecw6xZs4o+nLXWdHd34/P5qKioKHRxJhVpyhZinNNa09XVVfTNjlprXnjhBUKhEDfeeCO33norZWVlhS7WMFu2bOHJJ5/kiiuu4OMf/zh79uxh+fLlaK1Zs2YNGzdu5Nprr+Wqq67i+eefZ8OGDZimyZIlSzAMg+uuu45LLrmE++67j+3bt5PNZvnv//5vFixYwL/+679y3HHHcccddzh7Lo8H9vrpYuxIMAsxziWTSWev3mJlNwO//vrrKKXweDyceOKJ+Hw+tNbO7ZZlobUmn8+zadMmXn31VXK53LDrWJblfOTzeef++Xzeub/NPudQdsiyLIunn36aOXPmUFZWhs/n4+STT+aRRx4hn8/z0EMPMW/ePEKhECUlJZx11ln86U9/or+/n6effprjjjsOl8tFTU0Nc+fO5fXXX2fTpk2sW7fOuW3hwoUEg0H27NkzKr/n0ZDNZunr6yvqLpKJRpqyhRjH7PnKxV5bBmhra6OlpYVwOMy2bdtobGxk165d3HvvvVxwwQU8++yzlJWVccMNN3D77bcze/Zs2tvb2bBhA9deey1KKZYtW8YDDzzApZdeyquvvkosFuMd73gHbrebFStWkMlk+MEPfkAoFGLdunX84x//cEL+S1/6ElVVVfstXyqVoqmpiQ9+8IPAwFaJJ5xwAkopWltbSaVSnHrqqU4T9OzZs3n66afp7u4mEAjQ0NCAUgrDMKiqqmLFihUEAgFKS0udPlq3243b7WbZsmUcf/zxo/9LHyH9/f1Eo1EZpT1GpMYsxDimtR43C4jU1dURDoepqalh1qxZBAIBZsyYgc/nY82aNVx//fWcddZZ9Pb2smvXLi688ELOP/98HnzwQXbu3InL5eLkk09mxYoVAHz3u9/lpuMxYQAAIABJREFUPe95D//zP//D7Nmz+e53vwvA//3f/5FMJnnggQc47bTTOPnkk+no6OC3v/3tAcuXyWTo7u6mvLzcOVZRUYHH46G7uxulFNXV1c5tZWVl9PX1kUgkKC0tJRwOO7f5fD7efPNNTNOkrKxs2IIdWms2bdo0Er/SMZNMJot+/MJEIjVmIca5TCZT6CIclD2qWSnlfMBAgEUiEc455xwaGhpoaGggn89z3XXXkUqlePLJJ+nr6yOdTg+7X0VFBW63mzPPPJMnn3ySxsZG/H4/LpeLjRs3EolEiMfjuN1uQqEQn/zkJ/H5fAcso2EYeL1eUqmUc8w0TbTWeL1etNYkEgm8Xq9zm8fjwe12k8lkyGazhEIhYCB8w+EwSinS6fTbmoFLSkpG7Hc7Vuwug2IftDYRSI1ZiHHuUPpPi93QVaYsy2LDhg387W9/44ILLjhg36bb7XaCwv6czWbZsWMHhmEwbdo0pk+fzhlnnMHJJ598wGuFQiEaGhpobW11ju3evZtsNkt9fT1KKXbt2uXc1tLSQk1NDdFolJ6eHnp7ewGcAF+4cCF+v5/Ozs5h/0dKKd71rncd5m+o8KSPeewcNJiVUn6l1Aql1OtKqY1Kqf9v8PgMpdSrSqktSqkHlFLeweO+we+3DN4+fXR/BCEmt/G2dKJd87K/3tvKlSt56KGHWLx48UE3Vdjftc444wx27NjBqlWrsCyLTCbD2rVrD9gc63a7aWho4PXXX3eut2HDBqqrq4lEIkz7/9k77/ioyuz/v+/09Jn0QgKB0IOABBQRsYBlVVBBwWVlFQXR3y5iX7GAirtfV/gqgqIgoKAuArKi8hUVKbqEGnrvPaSXSabPfX5/JDMLSEkgMJnked/XvDK5bc7cufd+7nme85zTtCkbN270f+bGjRtJSUnBbDaTkJDA8ePH/UFsBw4coFWrVrRp04awsDB/q0ZZWRkVFRVcddVVtTto9QCZP/vKUZMj7QRuFkJ0BDoBtyuKci3wNvCuECIDKAEerV7/UaCkev671etJJJLLgKIohIaGBtqMC+JLLFJUVMTx48cpKSlBCMHJkyc5cOAAGzduxGaz+ZNxWK1WFi1axLZt29BoNGzevBmv10txcTFQVXTB6XSya9cu8vPzOXbsGOXl5VRUVGCz2UhLS6N9+/a8+eabfPHFF8yePRuj0XjeRBmKovDggw/i8XhYvXo1O3bsYNeuXTz6aNWt7eGHH+bo0aNs2rSJDRs2cPz4cYYNG4bJZGLgwIGsWbOGvXv3kp2djaqqZGVlkZSURJ8+fZg7dy779+9n4cKFNG/evN4NE7sQvkQqshn7yqDUpnlCUZRQ4D/AE8AiIFEI4VEUpTswVghxm6IoP1a/X6Uoig44CcSJ83xQVlaWWL9+/SV9EYmkMeJLn1jfh9/4gtQ2bdqEyWSiZcuWREVFUVhYyPbt2wkNDaVDhw6YTCYcDgcrVqygsrKSq666ip07dxIZGUnPnj0pLCxk27ZtZGRkkJiYyKFDhzhx4gQZGRmYzWa2b9+OwWAgMzMTm83G9u3bcbvdpKenk5qa6u/zPRuKomA0Gjl+/DgHDx7EYDAQERFB69at0Wq1qKrK/v37/WPGk5OTSU9PR1EUvF4v27Ztw+l0Yrfbad26tT9xitvtZt26df6+6Pbt258WYBYMWCwWkpKSpNdch2RlZbF+/fqzPunUSJgVRdECOUAG8AHwDrC62itGUZRU4AchRKaiKNuA24UQx6qX7QeuEUIUnrHP4cBwgLS0tC6HDx++2O8nkTRqXC4XR48ePS1oKdg5V6DRpXpsqqry97//HavV+rtlSUlJjBo16rSm8TO9xDPtqsmy8+0vGNBoNKSkpBAZGRl0ttdnzifMNeqcEkJ4gU6KopiBfwOXPABPCDEVmFptoIwqkEguEoPBgMViOWv0b7ByuQRMURRGjBhx1oA5X1/92US3Jnada9n59hcMmEwmf4S55MpQq6gRIUSpoijLgO6AWVEUnRDCAzQBjlevdhxIBY5VN2VHAUV1aLNEIjkDs9lMRUVFvc8AFmgURSE2NjbQZgQNer2elJQUWcTiClOTqOy4ak8ZRVFCgD7ATmAZMKB6tT8DC6vff1v9P9XLl56vf1kikVw6Go2GxMTEoAgEkwQHvvSivnHbkitHTXryk4BliqJsAdYBPwshvgdeBJ5RFGUfEANMr15/OhBTPf8Z4G91b7ZEIjkTvV5PamoqISEhgTZFEuT4RDkqKko2YQeACzZlCyG2AJ3PMv8A0O0s8x3A/XVinUQiqTGKoqDT6WjSpAknTpwIqgpGkvqDTqcjMTFRBnsFEBn7LpE0IBRFwWAwkJqaitlslsNbJLXCaDSSlpZGVFSUPHcCSHClDJJIJBfE5zknJSURFhZGXl5eUFSfkgQWs9lMXFwcBoNBesoBRgqzRNJA0Wq1mM1mQkNDKSwspLy8XFYIkvyOkJAQYmNjiYiIkF5yPUEKs0TSgPFls0pOTiYiIoKioiLZ9ywBqoIFo6OjZZ3leogUZomkEaAoChEREYSFhVFZWUlRURF2u71BVKaS1A6j0UhERIS/dKZstq5/SGGWSBoJiqKg1WqJjIwkPDwcq9VKWVkZVqu1wWQMk5wbk8lEZGQkZrNZjk2u50hhlkgaIRqNxi/QbrebkpISKisrcTqdUqQbEDqdjpCQECwWC6GhoWi1WukhBwFSmCWSRorPg9ZqtSQlJeHxeCgvL8dut8tAsSAnLCyM8PBwwsLCCAkJkWIcZEhhlkgkQJV3ZbFY/MNmnE4nhYWFuN1u3G639KTrMTqdDr1eT1hYGBaLxf/AJQU5OJHCLJFI/PgqJBkMBn89YrfbTUVFBS6XC6vVes56xpIri1arJSoqCoPBQGhoqPSMGxBSmCUSyXnR6/VYLBaEEERHR6OqKna73S/SXq9XJjC5zGg0GvR6PVqt1h9dr9Pp/FHVUpAbFlKYJRJJjVAUxT/e1Wg0YjabEULgdDqxWq14vV6cTicOhwO32x1ga4MbjUaDyWTCZDKh0+n8NZFlApDGgRRmiURy0SiK4hcQIQRerxdVVVFVFa/XS2lpKTabDSGEf35txk57vV40Gk1QeYRut9ufFvV8KIqCRqPx1zrW6/WYzWZ/k7RWq0Wj0UgxboRIYZZIJHXCqWLkCxQ7tT60y+Xye9MejwchBC6XC7vdftamcFVVmTt3Li1atKBbt98VsquXOJ1O5s+fj8lkol+/fv7j4XuACQkJ8YutXq/HaDRiNBp/J77B9CAiqXukMEskkjrnbMLiE6FTo7u9Xq/fy4YqMXY6nVRUVDB16lTee+89oqKimDx5Mu3btwfwe99CiCseKe7rzz31der83377jSlTpuD1egkLC2P48OHo9frThqaduo1EcjakMEskkivKqYLkC2DyIYQgNDSU7777jvHjx+N2u7n11lu59tprSUhIQAiBx+PxD+HyeDznbRo/VcRPnXemLWcT27PZ7bPXYDCg0+n8zey+bYxGI4sXL+a7777j5ZdfJjo6miFDhlywWVsiORV5tkgkknqDqqosWbKEMWPG4HQ66dq1K5MmTSI5Odm/ji8Y6kL4BPhMr/pswnzq+0vxZNPS0pg4cSIVFRUsX76c5557DkCKs6RWyKgCiURSb9i2bRvPPvsshw8fplOnTsyZM4eUlJSL2pfPk/X16fpeviblU4OrzvR8L4WmTZvy8ccfc8stt1BaWsqTTz7JnDlzZCY1SY2RwiyRSAKOEIKTJ0/y9NNPs337dpo1a8aUKVNo1qxZ0PXFKopCRkYGU6ZMoUuXLrhcLp5++mkpzpIaI4VZIpEEFCEEBQUFPPLIIyxbtozY2FgmTpzINddcE9RDhZo3b87s2bPp0aMHRUVFPPbYY8ybN0+mNpVcENnpcYURiN/99eJFPWUS1ZMPpXrSVE9atGjQoKD4l5+6rkQSaIQQFBYWUllZSVJSEgaD4Zyer8Ph4Pnnn+fHH38kIiKC0aNHc+uttwadp3wmiqLQunVrpk2bxr333svu3bsZNWoUGo2G/v37+8cvSyRnIoX5MmHDRh55FFBAKaWUUYYVK06cePDgrZ7cuCmmmHLKKaOMCipwV08+DBjQoyeyejJjJooodOjQokVXPYUQQgQRRBGFBQvx1ZMBWXtVcmU5dOgQgwcPZufOnYwcOZKXXnrprAFbFRUVjBs3jq+++gpFUfjrX//KU089FdSe8qn4xHn+/PkMGTKEDRs28Nhjj6HX67nnnnuC/uFDcnmQwlxLBAIVFSdOXLhw48aDh01s4nu+Zz/7/cvLqqdKKrFXT14uXx+THj0mTIQSSjjhRFVPPgHvTGf60pemNEVfPRkxokd/mgcukVwKQgjWrFnDmjVrUFWV8ePHU15ezptvvklYWJhfjLxeL19++SUffvghHo+HoUOH8uKLLzY4sVIUhXbt2vHZZ59x7733sm/fPkaOHIlGo+Huu+9uMA8hkrpDqQ/9HVlZWWL9+vWBNuOcCATFFLOSlRRQQD755JDDFrZwhCN48foF+9Qm6PqGrzlcQcGIkXTS6UIXruIqzJhJI43ruI5QQi+8M4nkHPjGHi9fvtw/T6vV0r9/fyZOnEhiYiKqqvLDDz8wZMgQiouL+fOf/8zEiROJjIxscMLsQwjBli1beOihh9i6dSvR0dHMnDmTvn37Bto0SQDIyspi/fr1Zz3Zpcd8BioqduxUUslOdvJ//B872UkJJWxlK2WUBdrEi8bXnw3gwcO26slHAglkkkkoofSgBzdyI61ohREjIYRIj1pSI44cOUJOTs5p87xeL3PnzsXtdvOPf/yD0tJSRo4cSUlJCddffz1vvPEGUVFRAbL4yqAoCh07dmTmzJkMGDCAQ4cOMWrUKIxGI3369JGes8SP9JipEuOjHGUrWznEIb7kSzaz2d9MXZ+94MuFL8jMhIme9OQBHiCJJDrTmVhipUhLzorX6+Xxxx9n+vTpZ13uE6eSkhKOHj1KZmYmM2bM4Oqrr26wnvKZCCHYuHEjf/zjH9m9ezfx8fF8/vnn9OnTJ9CmSa4g5/OYG6UwCwRu3Nix8wu/MI957Gc/u9iFFesVsyPYiCGG9rQnjTQe4zG60AUTJrRopVBLADh48CADBw5k3bp1513PbDajqipffvkld9555xWyrv6gqiobNmygX79+nDhxgjZt2jBp0iRuvvlm6Tk3EmRTdjUCwTGOsYY1/MRPLGQhJZScFgEtOTdFFPErvwIwl7nEEsvDPEw3unEjNxJFw26KlJwfIQQ5OTm/a8Y+G6Wlpeh0OnJzc1FVtdGJkUajoUuXLixYsIAhQ4awa9cuRowYwZQpU6TnLGn4HrNA4MLFMY4xhSlkk81GNuLAcVk+rzESSig96clN3MQQhhBLLDp00otuZDidTu644w6WLVtW420sFgtjx47l0UcfJSws7DJaVz9RVZXs7GwGDRrE8ePHyczM5JNPPqFr166N7mGlsdFom7LLKGMVq5jOdBazGBs2VGpepF1SO7RoMWNmEIMYwACu5VqMGKVANxK2bt1K9+7dqaysrNV2er2eJ598kpdeeon4+PhG09fsQwhBdnY2Q4YM4eDBg2RkZDBz5kx69OgRaNMkl5HzCXODeyQTCBw4WMxihjKUB3iA+cynggopypcZL16KKOIDPuABHmAEI8ghp9EG0DUmhBB8+umn2O32Wm/rdrv56KOPGDlyJLm5uY0uZaWiKFx77bVMmzaN+Ph49u7dyzPPPMP69esb3bGQVNGghNmBg6Us5S7u4l7uZQELZDBXgCiggFnM4hZuYTjDWcc6Kc4NmMOHD7Ny5crz1kY+H06nk3nz5jFo0CCKiorq2Lr6j1ar5cYbb2TevHmkpaWxbt06Hn/88QsG0UkaJg1CmAWCEkp4nucZyEB+4RfZh1wPEAjKKWcmMxnIQP6X/6WUUinQDQwhBKtWrbpkERFCsG/fPg4cOFBHlgUXGo2G7t27M23aNBISEtiwYQPPPPMMO3bskJ5zIyPohdmBg/nM51qu5UM+pIjG97QdDBziEC/xEn3owypWyUj4BoTT6WT69OkX7S1DlSi1bduWMWPG0Llz5zq0LrjQ6XT07t2badOmkZqaSnZ2NsOGDWPLli1SnBsRQSvMAkERRbzFWwxlKHvYI/uQ6zlu3KxnPYMZzCQmyb7nBsLJkydZvXr1RW8fGRnJ888/z/z58xk+fDh6vb4OrQs+NBoNd9xxBxMnTiQmJobs7GyeffZZDh06JMW5kRCUwiwQHOAA93AP/8P/UEFFoE2S1AKf9zyMYRRRJMU5iFFVlXHjxmGz2Wq9rcViYeDAgeTk5PDGG2/Qrl27RheRfS60Wi133303n332GfHx8SxdupQRI0awd+9eKc6NgKATZoFgP/sZzGBWshIPnkCbJLkIXLiYxSxGMpJKKqU4ByFCCA4dOsSmTZtqJRaKotClSxdmzJjBp59+SkZGBgaDLE16Jr5m7QkTJhATE8NPP/3Ec889R35+vhTnBk5QCbNPlO/jPtawRt7MgxwVla/4imEMo5BC+XsGIdnZ2WzZsqXG63fp0oUpU6awePFi+vXrd9YazZL/YjAYGDRoEOPHjycmJoZFixYxfPhwDh8+XCNxttlsWK1yZEqwETQpOQWCXHL5C385rSKSJLhRUZnDHGKI4T3eQxc8p2Sjx+FwMGfOHNzuCwfyxcbG8tBDD/H000+Tmpp6BaxrOOh0OgYNGkRlZSUvv/wy3377LQaDgY8++ojo6OizNv8LIThw4ADvv/8+LpeLF154gWbNmsmugiAhaO6CXrz8k3+yhCXSs2qAzGQm7WnPcIajRRtocyQ14OjRoyxduvS868TExHDLLbcwZswYWrRogdFovELWNSyMRiOPPvooXq+XV155hQULFqDX6xk/fjxJSUmnCa4Qgv379/Poo4+ycuVKADp06MCIESOkMAcJQdGULRAsZzkzmemvJyxpWNiwMZnJ7GGPfPAKAoQQfPjhhzgc584XcPPNNzN9+nRmz55Nu3btpChfIkajkWHDhvHiiy8SFhbGv/71L5599lnsdru/WVsIwZ49e3j88cf57bff8Hq9eL1ePv7444vKyiYJDEEhzFaszGAG5ZQH2hTJZWQnO5nFLCnMl4gQAo/Hg8PhwG63Y7PZqKiooLKyEpvNhsPhwOVyXdK44yNHjpCdnf27fk69Xk/btm2ZOnUq8+bNo2/fvjKwqw4xmUw8/fTTfnGeN28eTzzxBIWFhQgh2L17Nw8++CDLly8/7bfZsWMH8+fPl0FjQUK9b8oWCDaykX/z70CbcvGc7VpQLrDsXNfPqS1R4hzzgxSBYAYzGM1oIogItDkB48ybpxACp9PpF9iDBw9y5MgRjh07RkXF74cKqqqKw+HA4XDg8XhQVRWPx4NWq0VRFPR6PXq9npCQkLOOGdbpdCQmJtKkSRNatGhBbGwsoaGhhISEoNVWdTP85z//YdOmTadtZ7FYGD16NA888ACpqamy2fQyERISwjPPPENlZSUTJ05k9uzZaDQahg0bxrPPPsvGjRt/t43H4+GLL76gb9++WCyWAFgtqQ1BIczLWR68KTadwC5gGXAj8A3QGbgNMAGHgXnAHsAM3AX0BPKBTdXzCoGVwFCgJaACJ4AN1dv1AToQJO0f56eUUmYzmyd5MtCmXBFUVcXlclFcXExxcTFerxer1crGjRtZu3Ytx48fJz8/H7vd7hdYu93uF16vt+67dhRFwWAwYDKZCA0NxWAwoNFo0Ol0REdHExsby6FDh04L+rrhhht466236NatG3q9XoryZSYkJITRo0ej0WgYP348s2bNYtGiRRQWFp5zm+zsbJYsWcKAAQPk71PPqffCrKLyDd8E2oyLpxIYByynSmT1wHNAKtAMeAl4tnreiur3nwNHgUeAPwLNgWPAa8CXwAHgX8D/A7TAQ8BMoMsV+UaXFRcutrIVgWiQ5SKFEJSWlpKTk8POnTvJy8ujpKSEjRs3smHDBpxO5wX3odVqiY6OpmnTpsTExBAdHU1ISAihoaGYTCYMBoPfK9ZoNP6XqqoIIVBVFa/Xi8vlwuVy4XQ6sdvt2O12rFYrRUVFFBQUUFhYSG5ubo2+15EjR/jggw9YuHAhFouFjIwMOnbsSEZGht/LltQt4eHhjB49mqNHjzJr1iwKCgrOu35lZSWzZs3irrvuIiQk5ApZKbkY6r0wA+RSs5tDvSQa6AqsAQYDZcAXQDmQDewAOlLVFN2DKrH+HHgZiAPaUyXQNwFjq/e5ElhKlVftoUrsdwJX0yCatIspxo6dUEIDbcol4fF4KCoqorS0lIKCAr755huWLFmCzWajpKSE8vJyXC4XUOWlhoeHEx0d7RdYo9FIYmIivXr1onv37kRHR/vXNRgMGI1GDAYDBoMBrVbrf/mEWFEUv2fk+yuE8DeVq6rqF2nfy+Px+MXa6XT6PXJVVdm3bx9Llixh8+bNWK1Wf/O6zWbjxIkTzJkzB6hKKRkeHo7ZbCYsLIyEhAQee+wxOnTogNlsxmKxEB4eLr22S8RX9GP58uU13ubnn39mw4YNstZzPScohLlBBAMp4B8F5GtyzqNKqH3ogVCqvGXfNsbqv+HVf1VgAfAAMOIsn9EAcODAhSsohVkIwfHjx5k/fz65ubmsXLmSTZs2UVlZedp6iqIQHx9P7969adasGQaDgZYtW9K6dWvS09OJior6nXDVhZCduo/aeLJCCDIzM7nnnnv881wuF0ePHuXQoUPs2LGDgoICKisrWblyJRs2bKC8vCpYc+fOnSxfvhxFUWjRogXXXnstbdq04dprr6Vnz54yOOwiEEKwZs0aHn30UY4cOVLj7ZxOJx999BHXXXedfDCqxwSFMDdYoqkSY3v1X6gS1/TzbONbfghwAwbAARQDCdAQhgDr0AXNWGYhBMXFxZw4cYJffvmFefPmkZ+fz6FDh/B4qtLFhoWFkZ6eTmRkJNdffz19+vQhLS2N0NBQkpOTg8J7PJt9RqORjIwMMjIy6N27NwBut5v8/HyKioqwWq2sWrWKFStWsHv3bioqKjhw4AD79u1DURRiY2NJSUnh6quvZtCgQbRq1YqkpCTZR10DNmzYwJAhQ9i7d2+tt/35559ZsmQJvXv3lse5nhIUwhxOOPnkB9qMusNb/eoBZFDVXzyMqiAvD/Cn6vVUqiKvBWCrXqYCA4G+QCyQBWwFugFJV+wbXFaiiCKE+t0H5nK52LhxI8uXL+enn35ixYoVpwViJScnc+2119KyZUvat2/PfffdR2jo6S0ADfGmqNfrSUlJISUlBSEE1113Hc8++yyqqrJ7927mz5/PyZMnWbVqFTt37qSgoIBNmzYxY8YMYmNjefjhh+nUqRO33norsbGxDfIYXQqqqrJu3ToefPBBDh48eFH7yMvL47vvvuOGG26QY8vrKfVemBUUbuAGDhCkxdPzgF+BMKqaoA9Xz/8UmA5MAP5JVb+xBRhOVbDXl1QJ8tdAU6r6pQ9Wb/Mg8BXwDnAE+DPQiQbRlK1FSxOa1Co1py+gyRe85HQ6yc3NZdasWWzdupWUlBQmT55MXFzcJdnmdrspKChgxYoVTJ48mSNHjnD8+HGEEERGRmI2m+nZsydDhw4lKSmJxMREzGZzoxWXM5vN27Vrx2uvvYbT6eTkyZMUFBSwcuVKpkyZQklJCcXFxYwfP57w8HCaNWtG7969GTZsGKmpqUHRqnAl2LdvHwMHDuTw4cMXXvk8fP755zz33HOkpaXVkWWSukSpDwPOs7KyxPr168+6TCBYyEL60z846y1fqcPbQO5ZZsysYQ2taHXe9YQQVFZWsmbNGvbs2UNhYSE7d+5kzZo1HDp06LTkGRaLhZkzZ9KvX7+LsklVVXJycvjmm2/44osvTrspduzYkZtuuombbrqJm2++mbCwMP8yKSTn59R7z/bt2/n222/ZvHkz33//vb+MpMlkol+/ftx22208+OCDjb7oxWeffcbDDz98yftRFIWRI0fy3nvvXbpRkosiKyuL9evXn/UmERQec0c60oUurGNdoM2pPfLeXCuu4zqa09z/v6qqWK1WbDYb5eXl7N27lx9++IEtW7Zgt9s5duwYRUVF/v7csxEVFUWrVucX+rNht9vZvXs37777LsuXL+fo0aNoNBri4uLo2bMnf/7zn8nMzCQtLc2fvENSc049XpmZmbRv357y8nL27NnD999/z5w5czh27BhfffUV3333HTNmzGD48OHceeedmM1mNJoGMHC/lvTt25eXX36Z2bNnc+zYsYvO3iaE4KeffmLHjh20bdtWnrv1Dd/wiUC+unTpIs6HKlTxofhQGIVRIKcGO0WJKPGj50eRm5srli5dKiZNmiTefvtt0adPHxEXFye0Wq1QFMXX617jV7t27URpael5z7FT8Xg8YvXq1eKJJ54QJpNJAEKr1YrMzEwxduxYsXPnTuH1eoWqqjXep6TmqKoqVFUVlZWVYvbs2eLee+8VERERAhAajUZ0795dfPLJJ6KioiLQpl5xfMfm6NGj4oUXXhCtWrWq9fXgeymKIv75z38Kj8cT6K/VKKnWvbNqYsBFWdRAmIUQokyUiWvENQEXDznV8eRAcBDBZ4iowVGi203dRKdOnURSUtJFifDZXp06dRJut/uC55jX6xUFBQXilVdeEU2bNhWKogij0SiaNWsmZs2aJXbv3i28Xu8F9yOpO1RVFcXFxWLZsmVi4MCBIioqSgAiNDRU3HXXXWLlypXC5XIF2syA4PF4xLZt28Qrr7wi0tLShFarrfW10axZM3Hy5MlAf5VGSYMQZlWoYpvYJlqKloGWEjnV5fQOAi0ChToR4bO97rjjjgt6t16vVyxcuFBkZWX5Hwg6d+4sJk2aJIqLi/2eiiQwqKoqvF6vWL58uRgwYIDfgw4JCRGvv/66OH53WFU3AAAgAElEQVT8eKP8fXzHpbCwUDz//POibdu2tfaaJ02aFOiv0ShpEMIshBBu4RbzxDwRL+IDLSdyqqvpHwhdmO6yiTIgnnjiifOeV0VFRWLcuHEiLi5OAMJisYhRo0aJPXv2NMqbfX1GVVVRUlIiFi1aJFq2bCl0Op3Q6/WiR48eYvv27TVqGWmouN1usWPHDvHWW2+JlJQUodPV7Lrq2bOnKCkpCbT5jY4GI8xCCOEVXvG5+FyKcwOZmjmbibe+e0sMGjRIGAyGyyLMn3766VnPJVVVxc6dO8Vtt90mNBqN0Gq1olevXuI///mP8Hg8UpTrMaqqiry8PPHqq6/6vefU1FQxderURi3OPg/6xIkTYsyYMaJNmzYXvD4MBoP4+OOP5fl+hWlQwiyEEHZhF3PFXJEiUgIuLHK6uEkRirhaXC1+ED8IVaiivLxcfPXVV6JHjx4iJCSkToU5KytLDBw4ULz22mviX//6l9i1a5coKioSW7duFZ06dRIajUYYjUbxzDPPiMOHD9fy8pIEErfbLb788kuRmZkpABETEyP+93//VzidzkCbFnBUVRVbt24V48aNE+np6UKj0ZzzGrnllltq7DX7unX++/IK1esRqtctvF638Hpcp7yc1a9T5lWvp3o9VduesT8hGscDwvmEucbjmBVF0QLrgeNCiLsURUkH5gAxQA7wkBDCpSiKEZhFVa2jImCgEOLQ+fZ9vnHM50JFZTObeZzHySEnOMc4N1IUFO7hHiYzmSSS/FWkhKiqO7xo0SKmTJnCr7/+elppwUvFV9jB91cIgdvtJiYmhgkTJjB48GA57CkIUVWVkydPMnjwYFasWIHJZOKFF17g5ZdfPmu96caEEFXJd2w2G2PGjGHZsmVs3ryZM+/7Go2GRYsWcfvtt/u3Q6ioqgvV60T1uhFeN6rqwa/nQiCEiupx4vXYq9ZTq9YTqgeBWr2OQFE0oCgoihaNRoei1aPRGNDoQ9DqTGg0evBfd9XrafUoGj0arR6N1oiiaVipWs83jrk2wvwMVQkgI6uFeS6wQAgxR1GUj4DNQogpiqI8CVwlhBihKMog4F4hxMALGFhrYQYQCA5ykPd4j6lMxcmFS+ZJAosZM4/zOE/zNPHEn7O0Y15eHj/99BMTJkxgx44dFy3QERERPPfcc6xevZq1a9fidrtxOBz+qk7R0dFMnDiRP/7xj41yXGxDQQjBkSNHePzxx/npp58IDw9nypQpPPjgg/J3rcbr9bJ//36++eYbJkwYT1FR8WlpZP9wx618MWMCqrcCRJWoqqobVXUhvB6E6kaIuq//fVYUDYqiqxZxHRqNAUWjAxQ0WgPGsAQMoXH/FXwUUKp+52AR70sWZkVRmgCfAW8BzwB3AwVAohDCoyhKd2CsEOI2RVF+rH6/SlEUHXASiBPn+aCLFWaoEmcnTr7hG97nfVax6qL2I7m8GDDQk568xmtcx3U1Srnpe9KfMWMGX331FatWrfrdk/6FuO222/jiiy+IiIjA6/XicDh47LHHWLBgAWazmY8//pgBAwbIm3cDQIiqWtf9+/dn2bJltGrVis8//5ysrKyguVlfToTw4nFacTnKKSrK54PJk1i4aBl79h1DCEG0JZKJ//NXbul19YX2VP03kMdUqfawFbQ6E3qTBb3JUuV9aw3oTWYUjaFe/+51kfnrPeAFIKL6/xigVAjhS7d0DEipfp9CdeHCatEuq16/8CJsvyAKCiZMDGIQ13AN05nOVKZSSCGC2t3EJXWPBg2ppPIcz9Gf/iSSeE4v+XfbVtf1/etf/0q/fv2YP38+H374IYcPHz7tSf98tG/fnoiICAwGA6qqsnDhQpYsWYJWq+Vvf/sb999/f0AvXpvNxqpVq3A4HGi1WoxGI+Hh4aSmpmKxWDAYLnxzKS0t5d///jcFBQW88MILV8jy+oeiKJjNZt59913+9Kc/sW3bNt58803mzJnzuwIiDRvx36ZorwunrQCXrRDV68TjqsDrrkSP4KnH+3JH76v5edl6PvvXj6hetdYPvoGjqikdwOuuxOuuxGE9BoCi0aM3RaHRGtEZIjGGJaAzRFR715p6LdY+LijMiqLcBeQLIXIURbmxrj5YUZThVJVsqLNE6umkM5axDGUob/M2i1nMEWpeq1RSd2jQ0Ja23MqtjGY0FiwXXcpRURTS0tIYNWoUQ4cOZfLkycybN49t27Zd8EZiNpvR6apO8/z8fN5//32sViv3338/w4cPvyh76pKQkBCaNWtGv379uOmmmxg9ejRbtmzhk08+oaysjOHDh3PjjTee16OPiKh6Xl6zZs2VMrveoigKHTp04KWXXuLRRx9l8eLF/PLLL9x9992BNu3yUt3f63FX4HFV4HYUYy87Wt387CtTdzqKotCqRRMy0lMYMuhW3G4v5qjwGnxY/RY2obpx2Xx+4AkqinejKFr0JjMhEalo9aHojJFV/db1VKRr0n7XA+irKMohqoK9bgYmAubqpmqAJsDx6vfHgVSA6uVRVAWBnYYQYqoQIksIkXWpVX9ORYeO5jTnAz7gS77kGZ4hjjg0NfqqkktFh45kknmbt5nDHN7hHWKJveT6yoqioNVqsVgsvPzyy8yZM4fXXnuNxMTEc15cWq2WyMhIf6DX6tWrWbVqFTExMYwYMQKLxRLwC1NRFJo3b47RaMRkMpGUlMRtt93G+++/T7t27XjqqadOa8IXQuByuXA6nf48yVqtlvj4eDQajT/Yx+v14vV6f/deCPG7Zb5IUN/8Uz/Ltz/ftj58drjd7nrnZWk0Gvr3788NN9yA2+1m0qRJ2O32QJtVt/gjeFW8bhsVxXsoyV1H6Ym1lJ5YQ2XxXlSvo7pP+Ny/T9V1pSEyIoyY6Ei02oZ2n6xqOagS6wLK8jZQcmItpSfWUp6/GaetAKH+9xqoL1zQYxZCvAS8BFDtMT8nhBisKMo8YABVYv1nYGH1Jt9W/7+qevnS8/UvXy506LiO6+hGN17kRT7iI5aznDWswYbtSpvT4LFgoStd6U9/BjKQcMIvWYzPhUajoW3btrzyyis8+eST/OMf/+Dbb7/l4MGDp11cYWFhfuEWQvDhhx8CcNVVV3HDDTdcFtsuBkVRfveAYDAYeOmll1i7di1Tp06lS5cuuN1uVqxYwY4dOygpKaFFixb069ePuLi407bfsmULGzZsoGvXrkRERLBw4UJiYmLo06cP8fHxrF69mqKiIjp37sySJUvo0aMHKSkpbNq0iezsbB566CGsVitbtmwhISGBgwcPUlxcTP/+/UlJSUFVVX799VdWrlyJEIL27duTkJBA69atiY2NvdKH76wYDAZGjBjBkiVL2L59O2vXrqVXr16BNqtOEELgcZbhdpZhLz+K2158QQGW/BehunDZC3HZC7GVHUKrNWGKTMUYGovOaEajDXzf9KU8Hr0IPKMoyj6q+pCnV8+fDsRUz38G+NulmXjxKCjo0RNPPK/yKnOZyyxm8TiPE0NMrWr+Sn6PDh1Nacrf+Btf8AVf8zXDGEYUUZdNlH0oioJOpyM+Pp533nmHOXPm8PzzzxMVFeVfJyIigtTUVAAqKys5dOgQAMOGDav3wV6KoqDX67n++uvZvn07R44c4YcffmDHjh385S9/4bnnnmPDhg189NFHp1XWcrvd5OTkEBcXR+vWrUlNTaW0tJQZM2b4hw6Vlpai0WhITExk27Zt7N69m9DQUMxmM2+//Tb5+flUVFQwduxYFi5ciNFoZOPGjYwfPx4hBGVlZYwbN46bb76ZrKwsXnrpJQ4ePHjeCl9XGkVRaN++PVdddRV5eXns37+/XnlEtUUIgVC9uOxFlJ3MoeTEWspO5uCy5VMV6hO83y2gCBWvx0Zl8W5KTqyhNHcdlSV7Ub3OgJ4vtbo7CSGWCyHuqn5/QAjRTQiRIYS4XwjhrJ7vqP4/o3r5gctheG1RUIgllvu4j4lMZAc7+JqvuYd76EQnDBgCbWJQEEEE13ANQxjCD/zARjbyBm9wO7cTTniNA7vqEp1OR1ZWFm+++SZr167loYceomnTpnTs2JH27dsDcOLECX9zpm9eMJCQkIDD4aCsrIypU6fSrl07QkJCiI6O5s4772TatGn+71VcXMyLL77Iddddx5133onBYECj0XDfffdx9OhR9u7di6qqfP3119x6663o9frT6kcbDFXXgEajoVOnTiQnJ3PjjTdy//33c80117BgwQK8Xi8nT54kPz+f8PBwunfvTqtWrUhOTiYxMTEgx+hcZGRk0KFDB7xeL1arNSiFWQiB123DYT1G4ZHlFB9dib38CF53RaBNa3AI1YPLlo+1YDsFB5dgLdiKy16MuMjSmpdCo3MZFRSMGIknnr7V0wEOkE02e9nLN3zDTnbixSuTlgDa6ul6rqc3vWlDG7rTnQQSAiLC50JRFAwGA61atWL69OmsX78es9ns96BLSkpOGwsd6KaqmiCEYN26dbRq1Yq4uDhycnL8yxRFISEh4bQWgpKSEtasWUPXrl1p06aNf72WLVvSq1cvPvzwQ55//nn+8Ic/+EX4XPia13U6nf9Y+R4ALBYLVquVAwcOYDab8Xq9dRbAWZec2kVQH/vCz0dVVLUXW9lh7NZjuO3FSK/4SqGieh1UluzDXn4MU3gSoebm6IyRVXe8K3DvaHTCfDaa05x00vHi5RmewYmT/+P/+J7vySOPk5zkKEcbRQKTcMJpQhOSSCKBBIYylE50IqR60qCpV4J8NvR6Pd27dz9tnslkqvfN16fiS5ixadMmhgwZQmxsLJ07d6agoKA6k5KC0+nEZDL5xSc9PZ1BgwYxYcIEWrVqRZcuXVAUBZPJxMiRIxk+fDiTJk3ilVdeOe2zfEFkNRWu+Ph43n77bebMmcOCBQt47rnnaN68ed0egDrGl+0tGFC9TpwV+VQU78TjtlUl+5AEBNXrwFZ2ELv1KKFR6YRENUVnCK8aenUZkcJcjYKCDh1RVHkgD/Mwf+bPVFLJPvaxla1UUME61rGYxRRRhAePP/lzMOETVl8ffDLJDGAAzWlONNG0pz3NaU4IIQG2tO5ISEjAaDQC4HK5/OIWaIQQ2O12PB4Pqqr6/27evJnRo0fTp08fhg4dik6n449//CMzZ87k/vvvJyQkhKNHj3LvvfdiMpn8rQH33HMPa9eu5dlnn2XBggVER0ejKAqZmZk0adIEp9NJdHS0//MVReHnn3/mjjvuIDs72x+Z7bPDF419aqR2eXk5P/74IyNGjKBz587o9fr/5vitB8fUh9VqpbS0FOC0B5h6iai6i3hcVqwF23Da8qUgB4zfnydC9VBZshdHRS6h5maEWTKoSh16ec4pKcznQUEhnHA6VU8CwcM8TAUVuHGTSy6b2cxGNrKTnbhw4cbNyerJgSPQX4FwwkkiiXji0aAhnHAyyaQLXWhHO+KIQ4eOSCIbdD97XFwcFouFQ4cOMWXKFKZNmxZok4Aq8fjggw9ISEhg9+7dPProo4SGhtKhQwfee+89MjIy0OurcgT/6U9/wuPxMGbMGJo1a4ZGo+Evf/kLJ0+eZMWKFWi1WhYvXsztt9/Oli1beP3113nqqado0aIFiqLwyCOPkJube1qyjT59+jBhwgSGDh3KoEGD6N69O7t376asrIzw8HDWr19P27ZtOX78OFdffTUbNmygTZs25Ofn8+677/oToHTs2JEnnnjiNNEPJEII1q5dy9KlS4mIiKh3/d+nUhXY5cZWepDKkv2oXgdVzdb1+EGikeJ1V2At2IHLVkB4dGsMoTFcjt+pxrmyLyeXkpKzPiEQ2LGzgx1sZzvllCMQuHFTQAF55FFEEcUUU0YZ5ZRTQQWVVOLGXSPP29dHHkYYEdWTGTMxxBBLLAkkEEMMmuopllg60IFWtEJP403oL4Rg7NixvPHGG7Rs2ZL//Oc/xMfHB9qsy86p3u67777Lww8/TExMzCXtc8qUKZhMJh555BH/ZyxfvhytVltvhqF5vV7GjRvH2LFjufrqq/n3v/9dL/vBq4K7KrEW7vBnrqofKS8lF0KjNRIZ3xFTRPJFNW3XRUpOSQ1QUAgllKzqyYdA4MGDGzdevHjw+IPLfH/PrIt45n59fxUUv+hq0PiDs7Ro0Z0y1fd+4EDwwAMPMHnyZA4cOMDEiRMZM2bMBYOggh2Hw8Hjjz9OamoqmZmZlyzKAGvXrsXlctG6dWsAQkNDOX78OPfff/8l77uuOHDgAB988AGKotCjRw+aNGkSaJN+hxACZ2Ue1oKteFzWU5bIazcYUL1Oyk7m4HGVE2bJQKOtu3uJFOYrgK8vtzF7rIFGURRatGjBww8/zHvvvcesWbO49957/QFSDRW3203Hjh3RarV1lpbyxRdf5Pvvv2fJkiUYDAbatWvHoEGD/KlPA4lvnPXrr79OYWEhKSkpjB49ut4F/vlEuTxvI15PA8tK1ogQwktF8R5Ur5uI2LZ1Js6Bv5IkkiuE0Whk5MiRrFixgpycHJ588kkWLFhQL72puiIiIoJRo0adNbvYxdK6dWtatWrlD/aqy31fKl6vl2nTpvH1118TFhbGq6++Sl2m/K0LqkT5JGV5G1E9gY9DkVwiQsVWegCESkR8ZlVt6Uukfj1GSiSXEUVRaNq0KW+88QaRkZGsX7+exx57jJMnTwbVGNfa4MsxXpfDhRRFQaPR1Pl+LwVfru8vv/ySV199FafTyeDBg/nTn/6EVnt5s9DVBiEEHlc55fmbpSg3KAS28sPYSg9XFw25NKQwSxodvXv35rXXXiMsLIwlS5YwcOBAjh071mDFuTHgcDiYMmUKI0eOxO12061bN1577bV6Vu6xKvq6omg3XrfM138uhBBYK2xYK4LsGAmViqIdVYUxLvFeIoVZ0ugwGAw8/fTTjB071l+QoX///vz222/1rsqM5PwIIcjNzWXcuHE8/fTTlJWV0aNHD2bPnk1ycnKgzTsNIcBefuSU6GvJ2SgqLmfC5Ln830+rA21KrRGqB2vh9uqiIhePFGZJo8Q3Bnjy5MkkJyezbt06Bg8ezJQpUygrK5PiHAS4XC42bdrEgAEDGD9+PDqdjr59+/L555+TkZERaPN+h1DdVBbvC7QZ9Z6IiFBMRj0lZcGZD9zjKMNWcuCS7iFSmCWNFqPRyBNPPMG0adO4+uqrOXbsGCNHjmTEiBGsWrXKn6pSUv/wRV7fddddZGdno9FoeO2115gxYwZpaWn1ot/7TGzlhxtUBLZXVamstONy1U0eciEEdocToQrCw+pTF0RtETht+ajei0/hLKOyJY0aRVG4/fbbadOmDWPGjOGbb75h7ty5/PrrrwwaNIhRo0aRkpJSb4KcGjO+dKC//PILEyZMYM2aNQgh6NSpEy+//DJ33323P+1qfUOoXty24CtEIYRg45a97N1/nJIyK8mJMdx123Vs23GA7xZn06ZVU9as30GH9s25/54bKSgs5fX/+ZTMtun8v+H3MvXT7/jxl3XM+3QslTYHf5/wOVlXt+HI0Tx27j7MS88MplVGKja7k/kLl2N3uLDZHGzcspfrrskM9Ne/aFz2IrzuSjRa40XdN6THLGn0aDQa0tPT+eSTT5g8eTJdunQhNzeXd999lz59+vD2229z+PDhQJvZqHE6nXz99dcMHz6cAQMGkJ2dTVRUFCNGjGDRokX079+/XieL8bpteNzWC69YD5n40dfcdktXBvTtRWiIieLScj6c/g0P3HsT993dkxeeepB/zf+FDZv20CQ5Dmulndy8YnRaLU2S49h/8ASqEBiNBr5Z9B9Wrt7K8IfvJjkplncmzUEIwaIfV3HoyEke+ePtPDViACZT/f0ta4Tw4nVffOuIFGaJhCrP2Wg08tBDDzF//nxef/11kpOT2bt3L2PGjKFPnz68+OKLHDx4EJvNJvugrwAej4f8/Hy+/fZbbr/9dh577DHmzp1LeHg411xzDUuWLOGdd94hKSmpXo2lPhuq1xm0w6McDhfvvD8Ha4WNntddRUWFDY1GQ2JCVYEUc1Q4vXp0ZP7CFVVj26u3O9fvcfMNV2OOCqdFejIetxdVVfn397/RNDURg0GPokCHdvW7WllNOD2bW+2QwiyRnIJGoyEtLY1XX32VJUuWMGrUKBISEti3bx///Oc/6dq1KyNHjuSrr76isrIy0OY2WDZv3sy4ceP4wx/+QL9+/Vi+fDlWq5UBAwYwffp0li5dSqdOnQgNDa3XguxDCBWhXlqkbqCY8NaT5BWUMGTE3/nxl7W4XB7KyitxuTwAaLUaoi2RHDtRUKuGeo1GgwBUIdi198hpy4LhN70QlxJPIPuYJZIz8N0U2rRpw9tvv80jjzzCF198wfz58zly5AjTp09n7ty5tGrVijvvvJMBAwaQnJyMxWKpd6kfgwEhBE6nk8LCQlatWsWsWbPYvn07Bw8eRFEUoqOj6dq1K3/5y1+4/vrriYqKCr4bt6KAooFLHEYTCIwGPe+8MYIffl7D6//zGRPGPcHmbfs5nltAtCUCVRU4HC7uuq07mjNbLmqg1AoKifHRVFTY8KoqGkXB61XRajX1rpRobbiU9JxSmCWSc6AoCnq9nszMTP7xj38wevRoPvroI3799VeWLVtGTk4OOTk5/P3vfycrK4v77ruPzMxMunfvHpzicYVxu93s2rWLtWvXsnnzZj799FMqKioQQqDRaGjTpg29e/dm8ODBdO3aNagD8DRaAxqtEa/qDrQptWb85K94YeQg2rZuSmiIgYSEaPr9oQff/ZBNs7QkiorLyCso5q7buwPQNDWRI8fyyF67jQ2b9+DxeDh4KJe01AT/PoUQVNqqIro9Hi8P9r+FqZ99R1JiDIkJ0ezdf5Ryq43evbrQskVwpszVGSIveltZ9lEiqQVCCIqKiti1axc//vgjn376KaWlpVRWViKEIC4ujqZNm9K8eXMGDx5MVlYWISEhhIeHo9PpglZYLgVf0haHw0FFRQXl5eXMnDmT7Oxsjh07xpEjR3C5XOj1eqKioujQoQMjRoygY8eOpKen1+ugrpqiel2U5q7DWZkXaFNqhRCCRT+t5mReEaVlldx8Q2c6tGtOWXklK9dsZceuw7Rv04zMduk0S0tCo1E4eDiX9z/6mrQm8cTFWSgptTKgXy+MBgOr1m6neXoyzdIS2Ln7MOVWG106tQJg6a8b+fGXtfTsfhUREaEYjXo6d2hJbExUgI/CxaAQ3eR6DKGx57zmz1f2UQqzRHIR+MTGbrezdOlSfvrpJ7Zv385vv/2Gx1PV96YoCgaDgY4dO9K7d2+aNWtG06ZN6datW6PwqFVVZevWrWzfvp0TJ06wZcsWfvjhB4qLi08bI960aVN69uxJx44dGThwICkpKf5j01COkRACa+F2Kov3BNqUWnNqNrxTg+x888/8rf67vkJtf76zNV0H4zmgM5qxpFyDThfKuQ6CFGaJ5DIihEBVVfLy8tizZw9btmzhiy++8Edw+6K4tVotMTExpKenEx4eTrt27bjtttvIyMjAYrGg1+sxGo2YTKag6KsWQuB2u7Hb7bjdbhwOB8ePH2ft2rUsXryYyspKjh8/zokTJ7DZqvIeGwwGwsLCsFgs3HjjjfTv358mTZqQkZFRz/Ja1z1et43Cw0tRva5AmyK5zIRZWhIR1x5FOfd1LIVZIrlC+LwFVVUpLy8nOzubn3/+mYKCAnJycjh8+DBOZ1VGoFNLJkZERJCYmEjnzp3p1q0boaGh6PV6kpKSaN68OTExMYSEhGA0Gq9oX6sQApfLhdPpxGq1cvjwYQ4fPozVakUIwZ49e1i9ejUHDhygpKQEj8eDqqp+D0uj0WA2m8nKyiItLY3MzEzuuOMOmjVrVq+qU10JqrzmbVQW7w20KZLLiFYfRkxaL7Q603nXk8IskQQQX//qvn37yM/PJzc3lw0bNrB48WLy8vLwer04HA7cbvdpTbxarZbo6GgSEhKIjIzEYDCg1+uJjIwkKiqKyMhILBYLSUlJxMXFERcXR3R0NJGRkZhM578pQNU4YavVSllZGYWFhRQUFJCXl0dBQQFlZWWUl5dTWlrqt81ut5Ofn09BQQF2+3+HgvhKSxqNRgwGAzqdjl69enH99dfTsmVLoqKiaNmyJXFxcY1GhM+GEAKvu5LS3HW4HSWBNkdyWVCIjO9IqDn9gue6FGaJpJ7gu95UVfW/8vLyWLJkCdu2baO8vJySkhJKSko4ceIEubm5lJeXn3Vfp/b3nfm+tjb57Drz/ZkYDAbi4uJo0qQJMTEx/geBpKQkevXq5Y+e9r3qe+KPK40QAmflSUpz1yFUT6DNkdQpCqHmdCJi26NoLhzoeT5hlsOlJJIriO9i1Wq1aLVaANLS0hg6dChQdeO22WyUl5dTWFhIUVGRP+Lb7XZz8OBB1q9fz65duygsLMTj8eDxePB6vX6hP5uwnhq849ufXq8nJCQERVHQaDR+m3Q6HaGhoTRv3pxOnTrRoUMHoqKqImP1ej0Wi4X4+HiioqKIiIhAp5O3kZqiKArGsEQiYttTXrAVhCyU0lDQGSMJj26FRqu/9H3VgT0SiaSOUBSFsLAwwsLCSEpKOm2Zz5v1ifCZHq2qqjgcDhwOB06nE5fL5V/X4/H4vdgHH3yQbdu2ceuttzJz5kxMJhN6/ek3E5+n6+sH9s2TXDqKovibOsvytwZl0hHJ6ehNMZiTs9DoQupkf1KYJZIgwSeW54vYvlBksxCC22+/nW3btlFQUEBs7LnHWUouH4qiISQqHaF6sRbtlM3aQYuCITSeqPgO6PRhdbbX+j8mQyKR1Cl9+/YFoKKiAocjOAsrNBRCLRlEJWahM158lihJYFAUHeHRLbEkZ6E1RNTpvqXHLJE0IhRF8XvVbrebsrIyQkLqpvlNUjt8LRWm8CR0+lAqinbhqMgl2Go2N0Y0WiMRcZmERDRB0Wjrfv91vkeJRFKv0QJQXB0AABi6SURBVOl0hISEUFRURE5OTqDNafQoioLOGIU5qSuRCR3R6sMDbZLkHCgaHSGRacSk3UBIZNplEWWQwiyRNDoiIiJo1qwZpaWlbN++PdDmSKiOH9BoCY1Kx5LcjTBzBooiGzTrDwp6UzRRiV2ITOiEzhBxWWMz5C8vkTQyoqKiaNGiBTt37sThcAR1ab2Ghs97jojPJMScTkXRTly2AlSvM9CmNU4UDXqThdDIppgiUmo0PrkukMIskTQywsLCSElJAaC8vByPx/O74VKSwFF141fQGyMwJ3XBZS/GWZGLrfQgQg6tukIoVYIc1QxjeOIF02vWNVKYJZJGhtFo5P+3d+dRUpV3Gse/v6qupbvpha07bIq2GAIuYFpUhByQ6ADRkDN6ok5yZCKJJ4njmGVi1MRMMv+ox5zJJKPjRE0m2zgxGgnELQgxMzgZF0xAQVREIS60IEtD791V7/zx3rKrW6C76eXW8nzOuafuVtVvvd1VT7/vfe+9Y8eOBWDz5s00NjYybty4kEslh2MWJVE2nnjpWMpHT6O58TU6mnfT1X5QIT0MorEyH8jVJxJLVmMWzq1aFcwiRcbM3ruD1fbt22lublYw5zizCNFYKRVjZ5CuPomOlt20t+yh7dBbuHRn2MXLcxFKEpWUVR1PLDkmCORwD+0omEWK0PTp0xk1ahS7du2itbVVx5nzhJkRLUmQrJhMctREKsbNoKPlXVoPvUGqs5mujiZd5rMfItEEJfEK4qVjKa2cQqQkiUViOfMZUDCLFKH58+czevRodu7cSVNTU9jFkQEyM7Ao0UiU0srJJCsmke5qpb3lXVIdh2hv2U1n2wEK95xoBwwsRCPRBPGyGuKlY3wol4076v2Sw6RgFilCtbW1xONxAPbs2RNyaWSwzIxorIzSyimAozw9DZdO0dm2n5bG10mnOkmn2kh3tRfQsekjhbMRicaJlCSJRGLESsdSVnkcFo0Fo6qjOdMyPhIFs0iRytwVauPGjSxevDjk0shQyIzotmgcohCNlZKsmIhLp+jqOERXx0FSXe2ku1ppa3qbVGdL2EU+Rr2C1SIkyj9APDkai8QoiZdTkqgiEk3kfAgfjoJZpEjNnDmTrVu3smbNGq6//vqwiyPDyCJRYslqYslqAJxLUz7mZJxL49JddLUfpLNtH10dh0inOsA5nEuRTnWEfw61RYhEE0Si8fe68EtiPnhjySqisXIM8y3ikEZRDzUFs0iRqq+v54EHHqChoSHsosgIM4v0ODc3lqiktHKyD2QAHOmudro6DtLZfgjwA8qcS5Hu8mGdTnXg0p24dBfOpXDpFM6lwaVxOHCO7mPcQVhaJLhLWgQsikWimEWJREp893M0gUUTRCIlEARsJBqnJFFFSWxU0BWd9XoFSsEsUqSmT58O+FtBdnZ2vnfMWYqYWRB5RjRWSjRWSqK89r3Nzrms4M3cE7xnCPtt2S+adSz4vQff5U4Qsr6VGwkC27LWFScFs0iRmjJlCpFIhKamJl555RVOOeWUsIskOS7TlVy8kTkycnOsuIgMq8xFRpLJJI2NjWzatCnsIolIQMEsUqSSySQ1NTW0t7frOLNIDlFXtkiRGjt2LHPmzOFXv/oVDQ0NvP322xw6dIh0Os3evXtZv349zz77LE1NTVxzzTVcdNFFYRdZpCgomEWKiHOOhoYGtmzZws6dO9m/fz8Aq1atYu3atWzZsoXOzvdfe7murk7BLDJCFMwiBay1tZW1a9dy//338+KLL5JKpWhtbWX//v00NTXR1tYGwLZt2476OpmLkYjI8NOnTaSArVmzhk9/+tODuh52WVkZ8+bNG8JSicjRaPCXSAGbPXs2lZWVg3qN8vJyFi1aNEQlEpG+KJhFCtjkyZO58sorB/UayWSSqqqqISqRiPRFwSxSwMyMyy+/nJNPPvmYX+NDH/oQkYi+KkRGij5tIgXMzJg+fTorVqwgFosd02vMnz+/qC+PKDLSFMwiBS4SibB8+XKOO+64Y3p+fX29gllkBCmYRYpATU0NX/7ylwf8vGg0Snl5+TCUSESORMEsUgTMjGXLljF37twBPe/UU09l4sSJajGLjCAFs0iRmDRpEldccQWlpaX9fs7cuXOZOnXq8BVKRN6nX8FsZjvM7AUz22hmG4J1Y8zscTPbFjyODtabmf3AzF41s+fN7IzhfAMi0j9mxqWXXjqgoE0kEhqRLTLCBvKJW+icm+Wcqw+WrwfWOeemAeuCZYAlwLRgugq4c6gKKyKDU1VVxW233UY0Gu1z32QyyYwZM9SNLTLCBvOv8DLgp8H8T4FPZK3/mfOeAqrNbMIgfo6IDBEzo76+ngULFvS5b1lZGbNnzx7+QolID/0NZgesMbPnzOyqYF2tc25XMN8A1Abzk4A3sp77ZrBORHJATU0NK1asoKKi4qj7lZaWMnPmzBEqlYhk9DeY5znnzsB3U19tZh/J3uicc/jw7jczu8rMNpjZhj179gzkqSIyCGbGxRdfzKxZs466XzKZJB6Pj1CpRCSjX8HsnHsreNwNrATmAO9kuqiDx93B7m8BU7KePjlY1/s173LO1Tvn6sePH3/s70BEBiwWi3HTTTcd9WpgH//4x3V8WSQEfQazmZWbWUVmHrgA2AysBpYHuy0HVgXzq4ErgtHZZwONWV3eIpIDzIwzzzyTZcuWHXGfpUuXjmCJRCSjPy3mWuBJM9sEPAM87Jx7DLgFON/MtgEfDZYBHgFeA14F7ga+OOSlFpFBq6qq4nOf+xzjxo1737ZYLEZFRYVazCIhKOlrB+fca8Dph1m/F3jfTVqD481XD0npRGTYmBkLFy7kzDPP5NFHH+2xberUqVRXV4dUMpHipisHiBSxWCzGLbfc8r4QnjlzJjU1NSGVSqS4KZhFilxdXR2XXHJJj3XHHXcclZWVIZVIpLj12ZUtIgXCOUinoasLUin/2NFBWWsrn5k3j4cffJBd+/YRNWPswYNEn3nGP8cMIhE/xWJ+ischmYSyMr9cUgLRqH+MRPxzROSYKJhF8plzPeczy6kUvP46bN0KO3dCY6Ofmpqgo6N7am3FGhuZe+gQf93Swh3AKOc48777YOVKH+SRiA/daNSHcSaQKyqgqgpKS31Qx+OQSPjlykq/bfJkmDEDTjrJBzj40M4OboW4SA8KZpF8k0rBgQPQ0AAHD/rAfecdWLsWnn7ah69zPnjb26Gz0z8nne4Z5L1cC6zHn4axqLUVWluPrXyZFnamBZ1M+tA284E+dy4sWgTjx8Po0T7Aa2pgzBj/PJEip2AWyVWZEHUOWlrguefg8cd9KO/cCVu2+HA+1gDtpQ5/9aA4cOTLjvSDc/4fgVTK/3PQ0tJz+/bt8POf+/nSUpgwwbeqp071Le2lS+G006C8vLs1rVa1FBEFs0gucc63eF99FfbsgXXr/NTQAM3NvoWcTg/Lj44AJw7LKx9Fayu89pqfwLeY77zTt6wnTICFC2HxYt+aPumknmEtUqAUzCJhyrSK29th/Xr43/+FbdvgkUd8y7jYpNOwf7+f3noLNmyA226D6mq46CLfql64EM46y7e2QUEtBUfBLBKGri7YtcuHz49/7I8PHzjgjxcPU4s4rx044Lu/IxG44w5/XPqCC2D5cpgyBWpruweXieQ5BbPISMg+XvzHP8Lq1fCHP8Cf/+xDWvonnYZ9+/z0wx/C3XdDfT3Mnw+f+ASce273vmpJS55SMIsMN+dgxw7fLfu97/mu6r17jzpCWvopnYZnnoFnn4Wf/tQfh/7Sl2DOHDj+eI3ylrykYBYZLs75EcirVsE998BLL4VdosLlHLz7rp8uv9wH9IoVcPHFUFen1rPkFQWzyFBLp+Evf/HHRH/yEz+v7uqR45zvlfjmN3139yc/CVdfDRMn+nOrRXKcgllkqDjnu6jvvRd+8APfWpbwdHX5q5/deqvvtfjiF31r+jC3uRTJJToAIzIU2trgqadgyRK47jqFcq556SX/e1myBJ58csguyiIyHBTMIoPV2Ag33eQvhLFhgz8nWXJPW5v//Vx4Idxwgz9XWiQHKZhFjpVz/nSnK67wo60PHgy7RNIfjY1w++3+97Z1q84bl5yjYBY5Fs7B738Pl17qz0lOpcIukQxEKgUPPeQHhq1bF3ZpRHpQMIsMVDrtL5n52c/60b+SvzZvhi98AR58UP9cSc5QMIsM1Pr1/lKQO3aEXRIZCtu3+4uSPPlk2CURARTMIv3nnL/V4te/7k+LksLxxht+QNhrr+mKbBI6BbNIf7W3w803w9NPh12SvJQGdoddiKP5v/+DG2+EQ4fCLokUOQWzSH84B48/Dr/+ddglOSwHbAb+FrgG2B+sc8CbwJeBfwDeHeTPyEwDfd6TwF8D1w3i54+IlSv9oQq1miVECmaR/ti/358S1dYWdkmOaAYwDvgF8I9A5mzqSfhw/BgwdhCv3wn8CTiWGpgblOOVQfz8EdHRAbfcooFgEioFs0hfnPNX9dq4MeySHJHhP8wJ4GvAfwGP4APZgml88AjQBTTiW9aZa2A5fOg2BvMp4BDQjO+GXg/cHmxPAS3BtkNAU/AanfgW+vPArqyfHyGPvmy2bvX3xxYJia6VLdKXdNp/WefBlaIMuBIftt8CjgfOCLZlgrEFeALfvbwTKAf+CagB1gG3AP8D7AG+gQ/7m4HXgReAB4AFwK3B6zkgCfwQ+DdgB3AO8BXg3uB188revX6E9gUX6LaREgr91Yn0pb09ry5CkcAfZx4FfAkfsBkO2AZswB/vvRV4BliN/zKYA1QF+9YCp+Jb1xXAMqAOuAKYiB/IZfgW+t8F+z0KzAv2ncTgjmmH6vXXobk57FJIkVKLWaQvHR15d47reODfgU8C38Z3PWesBP5I93/lFwFTg/nsuxZb1tTbaKAU+ABwerDOAb8BtuMHou0FOgb1LkK0bZu/xGpFRdglkSKkYBbpi3M+nPOI4Vu73wa+Hqy7Nnh8E9/VfCMQxQfq4a4WfbRxyYcLawf8N/AX/ECziQMtdC5pa9MAMAmNurJF+hKJQHV12KXolxTdo6aj+Bbz3wANWft8An+ceAs+kN/Bt6C78IGbxg/wSgMH6RnaHcF+h4usduDvgcn40eHtR9gvL1RVQTwedimkSCmYRfqSSMBHPxp2KY7K4UdI7wZ+iw9P8OH8FeCv6O6WngOcgG9BX4kfwT0RiOEHgnUC1wN3AG/jB3y9ELzepmD9enzwttEzuJuB+4Ef448v/wR4OdgnAsQ5fOs853zwg1BZGXYppEipK1ukL/E4zJ8P996b0xeeKAP+FR+A0WCd4UdF34UfwAX++PP9+AAGH8ilwXwC+Bk+UJcA5wevOzF43duD1zwH3+qO0N2tnQQeBh7Dt9RPwXeb1wX73IIP5cN1g+eUSAROOAFKS/veV2QYKJhF+mIGJ58MtbXQ0ND3/iHIhF3ZEbZN7LVcSncY9953AnDDEX7O0qz5xGGeezrdg8Hm9dqeNzE3YQJceKH/vYuEQF3ZIn0xg3PPhUWLwi6JjIRzz4VTTw27FFLEFMwi/RGPwzXXQHl52CWR4VRa6n/Pai1LiBTMIv11xhnwta9BLBZ2SWQ4JBLwne/A2WcrmCVUCmaR/orF4LOfhfPP1xd3ITrvPPjMZ6BEQ28kXApmkYGYNAl+9COorw+7JDJUzOCss+D222HcuLBLI6JgFhmw2lr42c98l6fkv/p6uOsuf4qUSA5QMIsMlJm/AMVvfgNLl+oKUfkqkYBly+CXv4TTTtPhCckZCmaRY2HmW8733ANf/ar/kpf8EY3CddfB3XfDiSeGXRqRHhTMIoMxYQJ861vwwANwyim6f2+uM4NZs+AXv4Abb4Tx48Mukcj76FtEZLCSSfjYx+C3v/XnwOpSjrmpshI+/3lYuRIuu8z/3kRykIJZZCiYwfHHw803wxNPwJIlMHp02KUS8PdUvvBCWLMGvvtdmDo17BKJHJVO2BMZKma+tXzWWbBqFTz6qD+GuWZN3t3PuSAkk/6uYJdd5qdotO/niOQABbPIcIjF4KKLYN48eOMNP9Bo82Z/E4x0Xtz4MD9FIn5Q3sknw223QV2d77nQiGvJIwpmkeFiBmPG+GB45BHYtMkf31y9Gp5/PuzSFZ7TT/f/DC1b5i+faqZAlrykYBYZbma+G3X2bH++7FVXwdatcOedPqDffhva2sIuZf5JJv2o+A9/GFasgJkzYeJE32pWIEseUzCLjBQzfx3mKVNg8mR/ze09e+DBB+HFF+F3v4Pt2yGVCrukuSsS8d3UCxb4056WLfNd1xkKZCkACmaRMGQCpKbGn8LT2QnXXuuPQf/hD3DffbB/P+zbB62t4FyoxQ2FmW8Vjx3rT3X61KfgIx/xreJJk/wV1xTEUoAUzCK5IBbzA5VOPBHmzvUXv2hogMceg5dfhjffhGefLfwWdTTqW8SzZ/vTz+rq/HHj3hcCUSBLAVMwi+SS7MCZMMHfhjCdhpYW2LXLt6L37oWHH4annupuUbe1QXOzb3nnulgMysv9ZUwzLeK5c/1FWsaM8VNtrd9HV1KTIqRgFsl1kQiMGgXTpnV3aS9e7OdTKd+y3r7dt6h37fJBfvAgvPKKX9/Y6AO7q2vkylxS0h3AU6f6m36MG+ffS2bAVl0dfOADfr/MPyRqCYsomEXySnZwmfmgmzLFTwsWdG9ra/MDy/bu9fOpFLS3+xb2vn3dLe+9e7uXm5v91Nrq9+39c2MxKCvz06hRUF3tw3bMGP9YXd3d4k0kfLd0PO6Xx4/3z1PwivRJwSxSiJLJ7sCGww8e671uIAPMegdsX8si0m8KZpFicLigVHiK5CSNrBAREckhCmYREZEcomAWERHJIQpmERGRHKJgFhERySEKZhERkRxiLgcujm9mh4CXwy5HDhkHvBt2IXKE6qKb6qKb6qIn1Ue3fKmL451z4w+3IVfOY37ZOVcfdiFyhZltUH14qotuqotuqoueVB/dCqEu1JUtIiKSQxTMIiIiOSRXgvmusAuQY1Qf3VQX3VQX3VQXPak+uuV9XeTE4C8RERHxcqXFLCIiIuRAMJvZYjN72cxeNbPrwy7PcDOzH5vZbjPbnLVujJk9bmbbgsfRwXozsx8EdfO8mZ0RXsmHnplNMbMnzOxFM9tiZtcG64uuPswsaWbPmNmmoC6+E6w/wcyeDt7zfWYWD9YnguVXg+1Twyz/cDCzqJn92cweCpaLuS52mNkLZrbRzDYE64rucwJgZtVm9oCZvWRmW83snEKri1CD2cyiwB3AEmAGcLmZzQizTCPgJ8DiXuuuB9Y556YB64Jl8PUyLZiuAu4coTKOlC7gq865GcDZwNXB778Y66MdOM85dzowC1hsZmcDtwLfc86dBOwHVgT7rwD2B+u/F+xXaK4FtmYtF3NdACx0zs3KOhWoGD8nAN8HHnPOTQdOx/+NFFZdOOdCm4BzgN9lLd8A3BBmmUbofU8FNmctvwxMCOYn4M/rBvghcPnh9ivECVgFnF/s9QGUAX8CzsJfKKEkWP/e5wX4HXBOMF8S7Gdhl30I62Ay/gv2POAhwIq1LoL3tQMY12td0X1OgCrg9d6/30Kri7C7sicBb2QtvxmsKza1zrldwXwDUBvMF039BN2Ps4GnKdL6CLpuNwK7gceB7cAB51xXsEv2+32vLoLtjcDYkS3xsPoX4DogHSyPpXjrAsABa8zsOTO7KlhXjJ+TE4A9wH8EhznuMbNyCqwuwg5m6cX5f+uKaqi8mY0Cfg18yTl3MHtbMdWHcy7lnJuFby3OAaaHXKRQmNmFwG7n3HNhlyWHzHPOnYHvmr3azD6SvbGIPiclwBnAnc652UAz3d3WQGHURdjB/BYwJWt5crCu2LxjZhMAgsfdwfqCrx8zi+FD+T+dcw8Gq4u2PgCccweAJ/DdtdVmlrl0bvb7fa8ugu1VwN4RLupwORf4uJntAH6J787+PsVZFwA4594KHncDK/H/uBXj5+RN4E3n3NPB8gP4oC6ougg7mJ8FpgWjLePAZcDqkMsUhtXA8mB+Of5Ya2b9FcHIwrOBxqzumrxnZgb8CNjqnPvnrE1FVx9mNt7MqoP5Uvyx9q34gL4k2K13XWTq6BLg90FLIe85525wzk12zk3Ffyf83jn3KYqwLgDMrNzMKjLzwAXAZorwc+KcawDeMLMPBqsWAS9SaHUR9kFuYCnwCv542jfCLs8IvN//AnYBnfj//lbgj4etA7YBa4Exwb6GH7W+HXgBqA+7/ENcF/PwXU7PAxuDaWkx1gdwGvDnoC42A98K1p8IPAO8CtwPJIL1yWD51WD7iWG/h2GqlwXAQ8VcF8H73hRMWzLfk8X4OQne3yxgQ/BZ+Q0wutDqQlf+EhERySFhd2WLiIhIFgWziIhIDlEwi4iI5BAFs4iISA5RMIuIiOQQBbOIiEgOUTCLiIjkEAWziIhIDvl/reomQEdluMEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip = 0\n",
    "frm = 0\n",
    "images, info = test_set[clip]\n",
    "\n",
    "print(\"----------------------{}-th----------------frame\".format(frm))\n",
    "graph(episode, clip, frm, info[frm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sequence buffers\n",
    "buffer_images = []\n",
    "graph_info = {}\n",
    "# load test clips\n",
    "for iter, batch in enumerate(test_loader):\n",
    "    image, info = batch\n",
    "\n",
    "    scene = iter\n",
    "    episode = episode\n",
    "    \n",
    "    # sort label info on fullrect\n",
    "    image, label, behavior_label, obj_label, face_label, emo_label, frame_id = SortFullRect(\n",
    "        image, info, is_train=False)\n",
    "\n",
    "    try :\n",
    "        image = torch.cat(image,0).cuda(device)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # -----------------(2) inference -------------------------\n",
    "    # person and behavior predictions\n",
    "    # person\n",
    "    # logits : [1, 125, 14, 14]\n",
    "    p_logits, _ = model_p(image)\n",
    "    predictions_p = post_processing(p_logits,\n",
    "                                    opt.image_size,\n",
    "                                    PersonCLS,\n",
    "                                    model_p.detector.anchors,\n",
    "                                    opt.conf_threshold,\n",
    "                                    opt.nms_threshold)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # logits : [1, 125, 14, 14]\n",
    "    # behavior_logits : [1, 135, 14, 14]\n",
    "    if False:\n",
    "        predictions, b_logits = model1(image, label, behavior_label)\n",
    "\n",
    "    # face\n",
    "    if np.array(face_label).size > 0 :\n",
    "        face_logits = model_face(image)\n",
    "        predictions_face = post_processing(face_logits,\n",
    "                                           opt.image_size,\n",
    "                                           FaceCLS,\n",
    "                                           model_face.detector.anchors,\n",
    "                                           opt.conf_threshold,\n",
    "                                           opt.nms_threshold)\n",
    "\n",
    "    # emotion\n",
    "    if np.array(face_label).size > 0 and False:\n",
    "        face_label = [fl for fl in face_label if len(fl) > 0]\n",
    "        emo_label = [el for el in emo_label if len(el) > 0]\n",
    "        image_c = image.permute(0,2,3,1).cpu()\n",
    "        face_crops, emo_gt = crop_face_emotion(image_c, face_label, emo_label, opt)\n",
    "        face_crops, emo_gt = face_crops.cuda(device).contiguous(), emo_gt.cuda(device)\n",
    "        emo_logits = model_emo(face_crops)\n",
    "        num_img, num_face = np.array(face_label).shape[0:2]\n",
    "        emo_logits = emo_logits.view(num_img, num_face, 7)\n",
    "\n",
    "    # object\n",
    "    if np.array(obj_label).size > 0 :\n",
    "        object_logits, _ = model_object(image)\n",
    "\n",
    "        predictions_object = post_processing(object_logits,\n",
    "                                             opt.image_size,\n",
    "                                             ObjectCLS,\n",
    "                                             model_object.detector.anchors,\n",
    "                                             opt.conf_threshold,\n",
    "                                             opt.nms_threshold)\n",
    "\n",
    "\n",
    "\n",
    "    # relation\n",
    "    if np.array(obj_label).size > 0 and np.array(label).size > 0:\n",
    "        r_preds, r_obj_preds, relation_predictions = model_relation(image, label, obj_label)\n",
    "\n",
    "\n",
    "    # place\n",
    "    images_norm = []; info_place = []; preds_place = []\n",
    "    for idx in range(len(image)):\n",
    "        image_resize = image[idx]\n",
    "        images_norm.append(image_resize)\n",
    "        info_place.append(info[0][idx]['place'])\n",
    "        frame_place = frame_id.copy()\n",
    "    info_place = label_mapping(info_place)\n",
    "    buffer_images = place_buffer(images_norm, buffer_images)\n",
    "    pl_updated=False\n",
    "    buffer_idx = 10 - (len(images_norm) %10)\n",
    "    images_norm = buffer_images[-buffer_idx:] + images_norm\n",
    "    for plidx in range(len(images_norm)//10):\n",
    "        batch_images = torch.stack(images_norm[plidx*10:(plidx+1)*10]).cuda(device).unsqueeze(0)\n",
    "        output = model_place(batch_images)\n",
    "        output = torch.cat((output[:, :9], output[:, 10:]), 1) # None excluded. For None prediction, comment this line out.\n",
    "        preds = torch.argmax(output, -1).tolist() # (T, n_class) ->(T, )\n",
    "        for idx in range(len(preds)):\n",
    "            if preds[idx] >= 9: preds[idx] += 1\n",
    "        preds_place += preds;\n",
    "        pl_updated = True\n",
    "    buffer_images = images_norm[-10:]\n",
    "    preds_place = preds_place[buffer_idx:]\n",
    "    assert len(preds_place) == len(info_place)\n",
    "    preds_place_txt = label_remapping(preds_place)\n",
    "    target_place_txt = label_remapping(info_place)\n",
    "    \n",
    "    for idx, frame in enumerate(frame_id):\n",
    "\n",
    "        # ---------------(3) mkdir for evaluations----------------------\n",
    "        f_info = frame[0].split('/')\n",
    "        save_dir = './results/drama-graph/{}/{}/{}/'.format(\n",
    "            f_info[4], f_info[5], f_info[6])\n",
    "\n",
    "        f_file = f_info[7]\n",
    "        mAP_file = \"{}_{}_{}_{}\".format(f_info[4],\n",
    "                                        f_info[5],\n",
    "                                        f_info[6],\n",
    "                                        f_info[7].replace(\"jpg\", \"txt\"))\n",
    "        if opt.display:\n",
    "            print(\"frame.__len__{}, mAP_file:{}\".format(len(frame_id), mAP_file))\n",
    "            \n",
    "        # --------------(5) visualization of inferences ----------\n",
    "        # out of try : pdb.set_trace = lambda : None\n",
    "        try:\n",
    "            # for some empty video clips\n",
    "            img = image[idx]\n",
    "            # ToTensor function normalizes image pixel values into [0,1]\n",
    "            np_img = img.cpu().numpy()\n",
    "            np_img = np.transpose(np_img,(1,2,0)) * 255\n",
    "            output_image = cv2.cvtColor(np_img,cv2.COLOR_RGB2BGR)\n",
    "            output_image = cv2.resize(output_image, (width, height))\n",
    "            \n",
    "            #**************************************\n",
    "            graph_info['persons'] = {}\n",
    "            graph_info['persons']['person_id'] = []\n",
    "            graph_info['persons']['behavior'] = []\n",
    "            graph_info['persons']['emotion'] = []\n",
    "            #**************************************\n",
    "            graph_info['objects'] = {}\n",
    "            graph_info['objects']['object_id'] = []\n",
    "            graph_info['objects']['relation'] = []\n",
    "            #**************************************\n",
    "\n",
    "            if len(predictions_p) != 0 :\n",
    "                prediction = predictions_p[idx]\n",
    "                \n",
    "                if False:\n",
    "                    b_logit = b_logits[idx]\n",
    "\n",
    "                # person and behavior\n",
    "                num_preds = len(prediction)\n",
    "                                \n",
    "                for jdx, pred in enumerate(prediction):\n",
    "                    # person\n",
    "                    xmin = int(max(pred[0] / width_ratio, 0))\n",
    "                    ymin = int(max(pred[1] / height_ratio, 0))\n",
    "                    xmax = int(min((pred[2]) / width_ratio, width))\n",
    "                    ymax = int(min((pred[3]) / height_ratio, height))\n",
    "                    color = colors[PersonCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "                    \n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "                        \n",
    "                    pred_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                    print(\"person_pred:{}\".format(cat_pred))\n",
    "                    \n",
    "                    #**************************************************\n",
    "                    graph_info['persons']['person_id'].append(pred_cls)\n",
    "                    #**************************************************\n",
    "                    \n",
    "                    # behavior\n",
    "                    if False:\n",
    "                        value, index = b_logit[jdx].max(0)\n",
    "\n",
    "                        b_idx = index.cpu().numpy()\n",
    "                        b_pred = PBeHavCLS[b_idx]\n",
    "                        \n",
    "                        cv2.putText(\n",
    "                            output_image, '+ behavior : ' + b_pred,\n",
    "                            (xmin, ymin + text_size[1] + 4 + 12),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "                        pred_beh_cls = b_pred.replace(' ', '_')\n",
    "                        pred_beh_cls = pred_beh_cls.replace('/', '_')\n",
    "                        \n",
    "                        #******************************************************\n",
    "                        graph_info['persons']['person_id'].append(pred_beh_cls)\n",
    "                        #******************************************************\n",
    "                        \n",
    "                        cat_pred_beh = '%s %s %s %s %s %s\\n' % (\n",
    "                            pred_beh_cls,\n",
    "                            str(pred[4]),\n",
    "                            str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "\n",
    "                        print(\"behavior_pred:{}\".format(cat_pred_beh))\n",
    "                        \n",
    "                    # emotion\n",
    "                    if False:\n",
    "                        fl = face_label[idx][jdx]\n",
    "                        face_x0, face_y0 = int(fl[0]/width_ratio), int(fl[1]/height_ratio)\n",
    "                        face_x1, face_y1 = int(fl[2]/width_ratio), int(fl[3]/height_ratio)\n",
    "                        emo_ij = F.softmax(emo_logits[idx,jdx,:], dim=0).argmax().detach().cpu().numpy()\n",
    "                        emo_txt = EmoCLS[emo_ij]\n",
    "                        cv2.rectangle(output_image, (face_x0,face_y0),\n",
    "                                      (face_x1,face_y1), (255,255,0), 1)\n",
    "                        cv2.putText(output_image, emo_txt, (face_x0, face_y0-5),\n",
    "                                    cv2.FONT_HERSHEY_PLAIN, 1, (255,255,0), 1,\n",
    "                                    cv2.LINE_AA)\n",
    "                        \n",
    "                        #******************************************************\n",
    "                        graph_info['persons']['emotion'].append(emo_txt)\n",
    "                        #******************************************************\n",
    "                    \n",
    "                    if opt.display:\n",
    "                        print(\"detected {}\".format(save_dir + \"{}\".format(f_file)))\n",
    "                else:\n",
    "                    if opt.display:\n",
    "                        print(\"non-detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "\n",
    "            # object\n",
    "            if len(predictions_object) != 0:\n",
    "                \n",
    "                prediction_object = predictions_object[0]\n",
    "                num_preds = len(prediction)\n",
    "                for jdx, pred in enumerate(prediction_object):\n",
    "                    xmin = int(max(pred[0] / width_ratio, 0))\n",
    "                    ymin = int(max(pred[1] / height_ratio, 0))\n",
    "                    xmax = int(min((pred[2]) / width_ratio, width))\n",
    "                    ymax = int(min((pred[3]) / height_ratio, height))\n",
    "                    color = colors[ObjectCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "\n",
    "                    # save detection results\n",
    "                    pred_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                    \n",
    "                    #**************************************************\n",
    "                    graph_info['objects']['object_id'].append(pred_cls)\n",
    "                    #**************************************************\n",
    "                    print(\"object_pred:{}\".format(cat_pred))\n",
    "\n",
    "                    if opt.display:\n",
    "                        print(\"detected {}\".format(\n",
    "                            save_dir + \"{}\".format(f_file)))\n",
    "                else:\n",
    "                    if opt.display:\n",
    "                        print(\"non-detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "                        \n",
    "            # relation\n",
    "            if len(r_preds) != 0:\n",
    "                r_pred = r_preds[idx]\n",
    "                r_obj_pred = r_obj_preds[idx]\n",
    "                relation_prediction = relation_predictions[idx]\n",
    "                num_preds = len(r_pred)\n",
    "                for jdx, pred in enumerate(r_pred):\n",
    "                    xmin = int(max(float(pred[0]) / width_ratio, 0))\n",
    "                    ymin = int(max(float(pred[1]) / height_ratio, 0))\n",
    "                    xmax = int(min((float(pred[2])) / width_ratio, width))\n",
    "                    ymax = int(min((float(pred[3])) / height_ratio, height))\n",
    "                    color = colors[PersonCLS.index(pred[5])]\n",
    "                    \n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % float(pred[4]),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % float(pred[4]),\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "\n",
    "                    for kdx, obj_pred in enumerate(r_obj_pred):\n",
    "                        xmin = int(max(float(obj_pred[0]) / width_ratio, 0))\n",
    "                        ymin = int(max(float(obj_pred[1]) / height_ratio, 0))\n",
    "                        xmax = int(min((float(obj_pred[2])) / width_ratio, width))\n",
    "                        ymax = int(min((float(obj_pred[3])) / height_ratio, height))\n",
    "\n",
    "                        color = colors[ObjectCLS.index(obj_pred[5])]\n",
    "                        cv2.rectangle(output_image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "                        \n",
    "                        text_size = cv2.getTextSize(\n",
    "                            obj_pred[5] + ' : %.2f' % float(obj_pred[4]),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                        cv2.rectangle(\n",
    "                            output_image,\n",
    "                            (xmin, ymin),\n",
    "                            (xmin + text_size[0] + 100,\n",
    "                             ymin + text_size[1] + 20), color, -1)\n",
    "                        cv2.putText(\n",
    "                            output_image, obj_pred[5] + ' : %.2f' % float(obj_pred[4]),\n",
    "                            (xmin, ymin + text_size[1] + 4),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "                        \n",
    "                        #*****************************************************\n",
    "                        graph_info['objects']['object_id'].append(obj_pred[5])\n",
    "                        #*****************************************************\n",
    "                        \n",
    "                        value, ind = relation_prediction[kdx].max(1)\n",
    "                        ind = int(ind.cpu().numpy())\n",
    "                        rel_ind = P2ORelCLS[ind]\n",
    "                        cv2.putText(\n",
    "                            output_image, '+ relation : ' + rel_ind,\n",
    "                            (xmin, ymin + text_size[1] + 4 + 12),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "\n",
    "                        pred_cls = rel_ind\n",
    "                        cat_pred = '%s %s %s %s %s\\n' % (\n",
    "                            pred_cls, str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                        print(\"relation_pred:{}\".format(cat_pred))\n",
    "                        \n",
    "                        #*****************************************************\n",
    "                        graph_info['objects']['relation'].append(pred_cls)\n",
    "                        #*****************************************************\n",
    "                        \n",
    "            # place\n",
    "            if len(preds_place_txt) != 0:\n",
    "                cv2.putText(output_image, \"place : \" + preds_place_txt[idx],\n",
    "                    (30, 30),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "                \n",
    "                #*****************************************\n",
    "                graph_info['place'] = preds_place_txt[idx]\n",
    "                #*****************************************\n",
    "                \n",
    "                if opt.display:\n",
    "                    print('place_pred :', preds_place_txt[idx])\n",
    "                    \n",
    "            # face\n",
    "            if len(predictions_face) != 0:\n",
    "                prediction_face = predictions_face[idx]\n",
    "                for pred in prediction_face:\n",
    "                    xmin = int(max(pred[0] / width_ratio, 0))\n",
    "                    ymin = int(max(pred[1] / height_ratio, 0))\n",
    "                    xmax = int(min((pred[2]) / width_ratio, width))\n",
    "                    ymax = int(min((pred[3]) / height_ratio, height))\n",
    "                    color = colors[FaceCLS.index(pred[5])]\n",
    "                    \n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "                    \n",
    "                    # save detection results\n",
    "                    pred_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                    \n",
    "                    print(\"face_pred:{}\".format(cat_pred))\n",
    "                    print(\"detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "            else:\n",
    "                print(\"non-detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "            # save output image  \n",
    "            cv2.imwrite(save_dir + \"{}\".format(f_file), output_image)\n",
    "            # save images\n",
    "            plt_output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(plt_output_image.astype('uint8'))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            #*****************************************\n",
    "            frm_name = \"episode_{:02d}_scene_{:03d}_frame_{:04d}\".format(episode, scene, idx)\n",
    "            save_file = save_dir + frm_name\n",
    "            graph(episode, scene, idx, graph_info)\n",
    "            #*****************************************\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
