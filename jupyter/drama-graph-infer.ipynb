{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MissOh DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnotherMissOh Visual Structure\n",
    "- json_data['file_name'] : 'AnotherMissOh01.mp4'\n",
    "- json_data['visual_results']\n",
    "- json_data['visual_results'][0].keys() : dict_keys(['start_time', 'end_time', 'vid', 'image_info'])\n",
    "- {\n",
    "'start_time': '00:02:51;16', \n",
    "'end_time': '00:02:54;15', \n",
    "'vid': 'AnotherMissOh01_001_0078', \n",
    "'image_info': ...}\n",
    "- json_data['visual_results'][0]['image_info']\n",
    "- [{'frame_id': 'AnotherMissOh01_001_0078_IMAGE_0000004295', \n",
    "'place': 'none', \n",
    "'persons': [\n",
    "{'person_id': 'Haeyoung1', \n",
    "'person_info': {\n",
    "'face_rect': {'min_x': 515, 'min_y': 0, 'max_x': 845, 'max_y': 443}, \n",
    "'full_rect': {'min_x': 278, 'min_y': 2, 'max_x': 1025, 'max_y': 769}, \n",
    "'behavior': 'stand up', \n",
    "'predicate': 'none', \n",
    "'emotion': 'Neutral', \n",
    "'face_rect_score': '0.5', \n",
    "'full_rect_score': '0.9'}, \n",
    "'related_objects': []}], \n",
    "'objects': []}, \n",
    "- {'frame_id': 'AnotherMissOh01_001_0078_IMAGE_0000004311', \n",
    "'place': '', \n",
    "'persons': [{\n",
    "'person_id':'Haeyoung1',\n",
    "'person_info': {\n",
    "'face_rect': {'min_x': 515, 'min_y': 0, 'max_x': 831, 'max_y': 411}, \n",
    "'full_rect': {'min_x': 270, 'min_y': 0, 'max_x': 1025, 'max_y': 768}, \n",
    "'behavior': 'stand up', \n",
    "'predicate': 'none', \n",
    "'emotion': 'Neutral', \n",
    "'face_rect_score': '0.5', \n",
    "'full_rect_score': '0.9'}, \n",
    "'related_objects': []}],\n",
    "'objects': []},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install graphviz xdg-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> da2aaeb33cb16abb617598277daddb931a6bb707
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-897117e53d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import json\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Yolo_v2_pytorch.src.utils import *\n",
    "from graphviz import Digraph, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_blank(s):\n",
    "    return bool(s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "(39, 129, 113)\n"
     ]
    }
   ],
   "source": [
    "MissOh_CLASSES = ['person']\n",
    "print(MissOh_CLASSES[0])\n",
    "global colors\n",
    "colors = pickle.load(open(\"../Yolo_v2_pytorch/src/pallete\", \"rb\"))\n",
    "print(colors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, conf_threshold=0.35, data_path_test='./Yolo_v2_pytorch/missoh_test/', display=False, emo_net_ch=64, image_size=448, img_path='./data/AnotherMissOh/AnotherMissOh_images_ver5.0/', json_path='./data/AnotherMissOh/AnotherMissOh_Visual_ver5.0/', model='baseline', nms_threshold=0.5, pre_trained_model_type='model', saved_path='./checkpoint/refined_models')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from Yolo_v2_pytorch.src.utils import *\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from Yolo_v2_pytorch.src.yolo_net import Yolo\n",
    "from Yolo_v2_pytorch.src.anotherMissOh_dataset import AnotherMissOh, Splits, SortFullRect, PersonCLS,PBeHavCLS, FaceCLS, ObjectCLS, P2ORelCLS\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from lib.place_model import place_model, label_mapping, accuracy, label_remapping, place_buffer\n",
    "from lib.person_model import person_model\n",
    "from lib.behavior_model import behavior_model\n",
    "from lib.pytorch_misc import optimistic_restore, de_chunkize, clip_grad_norm, flatten\n",
    "from lib.focal_loss import FocalLossWithOneHot, FocalLossWithOutOneHot, CELossWithOutOneHot\n",
    "from lib.face_model import face_model\n",
    "from lib.object_model import object_model\n",
    "from lib.relation_model import relation_model\n",
    "from lib.emotion_model import emotion_model, crop_face_emotion, EmoCLS\n",
    "\n",
    "num_persons = len(PersonCLS)\n",
    "num_behaviors = len(PBeHavCLS)\n",
    "num_faces = len(FaceCLS)\n",
    "num_objects = len(ObjectCLS)\n",
    "num_relations = len(P2ORelCLS)\n",
    "num_emos = len(EmoCLS)\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"You Only Look Once: Unified, Real-Time Object Detection\")\n",
    "    parser.add_argument(\"--image_size\",\n",
    "                        type=int, default=448,\n",
    "                        help=\"The common width and height for all images\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1,\n",
    "                        help=\"The number of images per batch\")\n",
    "    parser.add_argument(\"--conf_threshold\",\n",
    "                        type=float, default=0.35)\n",
    "    parser.add_argument(\"--nms_threshold\",\n",
    "                        type=float, default=0.5)\n",
    "    parser.add_argument(\"--pre_trained_model_type\",\n",
    "                        type=str, choices=[\"model\", \"params\"],\n",
    "                        default=\"model\")\n",
    "    parser.add_argument(\"--data_path_test\",\n",
    "                        type=str,\n",
    "                        default=\"./Yolo_v2_pytorch/missoh_test/\",\n",
    "                        help=\"the root folder of dataset\")\n",
    "\n",
    "    parser.add_argument(\"--saved_path\", type=str,\n",
    "                        default=\"./checkpoint/refined_models\")\n",
    "\n",
    "    parser.add_argument(\"--img_path\", type=str,\n",
    "                        default=\"./data/AnotherMissOh/AnotherMissOh_images_ver5.0/\")\n",
    "    parser.add_argument(\"--json_path\", type=str,\n",
    "                        default=\"./data/AnotherMissOh/AnotherMissOh_Visual_ver5.0/\")\n",
    "    parser.add_argument(\"-model\", dest='model', type=str, default=\"baseline\")\n",
    "    parser.add_argument(\"-display\", dest='display', action='store_true')\n",
    "    parser.add_argument(\"-emo_net_ch\", dest='emo_net_ch',type=int, default=64)\n",
    "    args = parser.parse_args([])\n",
    "    return args\n",
    "\n",
    "# get args.\n",
    "opt = get_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import read_dot\n",
    "#from networkx.drawing.nx_agraph import read_dot\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.img_path = \"../data/AnotherMissOh/AnotherMissOh_images_ver5.0/\"\n",
    "opt.json_path = \"../data/AnotherMissOh/AnotherMissOh_Visual_ver5.0/\"\n",
    "opt.saved_path = \"../checkpoint/refined_models\"\n",
    "opt.display = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = [\n",
    "    Resize((448, 448)),  # should match to Yolo_V2\n",
    "    ToTensor(),\n",
    "    # Normalize(# should match to Yolo_V2\n",
    "    #mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]\n",
    "transf = Compose(tform)\n",
    "\n",
    "# splits the episodes int train, val, test\n",
    "train, val, test = Splits(num_episodes=18)\n",
    "\n",
    "# load datasets\n",
    "train_set = AnotherMissOh(train, opt.img_path, opt.json_path, False)\n",
    "val_set = AnotherMissOh(val, opt.img_path, opt.json_path, False)\n",
    "test_set = AnotherMissOh(test, opt.img_path, opt.json_path, False)\n",
    "\n",
    "episode = 7\n",
    "infer = [episode]\n",
    "infer_set = AnotherMissOh(infer, opt.img_path, opt.json_path, False)\n",
    "\n",
    "\n",
    "# model path\n",
    "model_path = \"{}/anotherMissOh_{}.pth\".format(\n",
    "    opt.saved_path,opt.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "-----------person---behavior-------model---------------\n",
      "Network copied person_model.detector.stage1_conv1.0.weight, size:torch.Size([32, 3, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv1.1.weight, size:torch.Size([32])\n",
      "Network copied person_model.detector.stage1_conv1.1.bias, size:torch.Size([32])\n",
      "Network copied person_model.detector.stage1_conv1.1.running_mean, size:torch.Size([32])\n",
      "Network copied person_model.detector.stage1_conv1.1.running_var, size:torch.Size([32])\n",
      "Network copied person_model.detector.stage1_conv1.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv2.0.weight, size:torch.Size([64, 32, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv2.1.weight, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv2.1.bias, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv2.1.running_mean, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv2.1.running_var, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv2.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv3.0.weight, size:torch.Size([128, 64, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv3.1.weight, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv3.1.bias, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv3.1.running_mean, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv3.1.running_var, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv3.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv4.0.weight, size:torch.Size([64, 128, 1, 1])\n",
      "Network copied person_model.detector.stage1_conv4.1.weight, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv4.1.bias, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv4.1.running_mean, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv4.1.running_var, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage1_conv4.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv5.0.weight, size:torch.Size([128, 64, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv5.1.weight, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv5.1.bias, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv5.1.running_mean, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv5.1.running_var, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv5.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv6.0.weight, size:torch.Size([256, 128, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv6.1.weight, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv6.1.bias, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv6.1.running_mean, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv6.1.running_var, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv6.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv7.0.weight, size:torch.Size([128, 256, 1, 1])\n",
      "Network copied person_model.detector.stage1_conv7.1.weight, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv7.1.bias, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv7.1.running_mean, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv7.1.running_var, size:torch.Size([128])\n",
      "Network copied person_model.detector.stage1_conv7.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv8.0.weight, size:torch.Size([256, 128, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv8.1.weight, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv8.1.bias, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv8.1.running_mean, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv8.1.running_var, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv8.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv9.0.weight, size:torch.Size([512, 256, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv9.1.weight, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv9.1.bias, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv9.1.running_mean, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv9.1.running_var, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv9.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv10.0.weight, size:torch.Size([256, 512, 1, 1])\n",
      "Network copied person_model.detector.stage1_conv10.1.weight, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv10.1.bias, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv10.1.running_mean, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv10.1.running_var, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv10.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv11.0.weight, size:torch.Size([512, 256, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv11.1.weight, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv11.1.bias, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv11.1.running_mean, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv11.1.running_var, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv11.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv12.0.weight, size:torch.Size([256, 512, 1, 1])\n",
      "Network copied person_model.detector.stage1_conv12.1.weight, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv12.1.bias, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv12.1.running_mean, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv12.1.running_var, size:torch.Size([256])\n",
      "Network copied person_model.detector.stage1_conv12.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage1_conv13.0.weight, size:torch.Size([512, 256, 3, 3])\n",
      "Network copied person_model.detector.stage1_conv13.1.weight, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv13.1.bias, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv13.1.running_mean, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv13.1.running_var, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage1_conv13.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_a_conv1.0.weight, size:torch.Size([1024, 512, 3, 3])\n",
      "Network copied person_model.detector.stage2_a_conv1.1.weight, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv1.1.bias, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv1.1.running_mean, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv1.1.running_var, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv1.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_a_conv2.0.weight, size:torch.Size([512, 1024, 1, 1])\n",
      "Network copied person_model.detector.stage2_a_conv2.1.weight, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv2.1.bias, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv2.1.running_mean, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv2.1.running_var, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv2.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_a_conv3.0.weight, size:torch.Size([1024, 512, 3, 3])\n",
      "Network copied person_model.detector.stage2_a_conv3.1.weight, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv3.1.bias, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv3.1.running_mean, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv3.1.running_var, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv3.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_a_conv4.0.weight, size:torch.Size([512, 1024, 1, 1])\n",
      "Network copied person_model.detector.stage2_a_conv4.1.weight, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv4.1.bias, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv4.1.running_mean, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv4.1.running_var, size:torch.Size([512])\n",
      "Network copied person_model.detector.stage2_a_conv4.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_a_conv5.0.weight, size:torch.Size([1024, 512, 3, 3])\n",
      "Network copied person_model.detector.stage2_a_conv5.1.weight, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv5.1.bias, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv5.1.running_mean, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv5.1.running_var, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv5.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_a_conv6.0.weight, size:torch.Size([1024, 1024, 3, 3])\n",
      "Network copied person_model.detector.stage2_a_conv6.1.weight, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv6.1.bias, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv6.1.running_mean, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv6.1.running_var, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv6.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_a_conv7.0.weight, size:torch.Size([1024, 1024, 3, 3])\n",
      "Network copied person_model.detector.stage2_a_conv7.1.weight, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv7.1.bias, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv7.1.running_mean, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv7.1.running_var, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage2_a_conv7.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage2_b_conv.0.weight, size:torch.Size([64, 512, 1, 1])\n",
      "Network copied person_model.detector.stage2_b_conv.1.weight, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage2_b_conv.1.bias, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage2_b_conv.1.running_mean, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage2_b_conv.1.running_var, size:torch.Size([64])\n",
      "Network copied person_model.detector.stage2_b_conv.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.detector.stage3_conv1.0.weight, size:torch.Size([1024, 1280, 3, 3])\n",
      "Network copied person_model.detector.stage3_conv1.1.weight, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage3_conv1.1.bias, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage3_conv1.1.running_mean, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage3_conv1.1.running_var, size:torch.Size([1024])\n",
      "Network copied person_model.detector.stage3_conv1.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied person_model.person_conv.weight, size:torch.Size([130, 1024, 1, 1])\n",
      "Network copied detector.stage1_conv1.0.weight, size:torch.Size([32, 3, 3, 3])\n",
      "Network copied detector.stage1_conv1.1.weight, size:torch.Size([32])\n",
      "Network copied detector.stage1_conv1.1.bias, size:torch.Size([32])\n",
      "Network copied detector.stage1_conv1.1.running_mean, size:torch.Size([32])\n",
      "Network copied detector.stage1_conv1.1.running_var, size:torch.Size([32])\n",
      "Network copied detector.stage1_conv1.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv2.0.weight, size:torch.Size([64, 32, 3, 3])\n",
      "Network copied detector.stage1_conv2.1.weight, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv2.1.bias, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv2.1.running_mean, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv2.1.running_var, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv2.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv3.0.weight, size:torch.Size([128, 64, 3, 3])\n",
      "Network copied detector.stage1_conv3.1.weight, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv3.1.bias, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv3.1.running_mean, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv3.1.running_var, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv3.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv4.0.weight, size:torch.Size([64, 128, 1, 1])\n",
      "Network copied detector.stage1_conv4.1.weight, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv4.1.bias, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv4.1.running_mean, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv4.1.running_var, size:torch.Size([64])\n",
      "Network copied detector.stage1_conv4.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv5.0.weight, size:torch.Size([128, 64, 3, 3])\n",
      "Network copied detector.stage1_conv5.1.weight, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv5.1.bias, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv5.1.running_mean, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv5.1.running_var, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv5.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv6.0.weight, size:torch.Size([256, 128, 3, 3])\n",
      "Network copied detector.stage1_conv6.1.weight, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv6.1.bias, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv6.1.running_mean, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv6.1.running_var, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv6.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv7.0.weight, size:torch.Size([128, 256, 1, 1])\n",
      "Network copied detector.stage1_conv7.1.weight, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv7.1.bias, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv7.1.running_mean, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv7.1.running_var, size:torch.Size([128])\n",
      "Network copied detector.stage1_conv7.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv8.0.weight, size:torch.Size([256, 128, 3, 3])\n",
      "Network copied detector.stage1_conv8.1.weight, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv8.1.bias, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv8.1.running_mean, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv8.1.running_var, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv8.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv9.0.weight, size:torch.Size([512, 256, 3, 3])\n",
      "Network copied detector.stage1_conv9.1.weight, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv9.1.bias, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv9.1.running_mean, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv9.1.running_var, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv9.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv10.0.weight, size:torch.Size([256, 512, 1, 1])\n",
      "Network copied detector.stage1_conv10.1.weight, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv10.1.bias, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv10.1.running_mean, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv10.1.running_var, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv10.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv11.0.weight, size:torch.Size([512, 256, 3, 3])\n",
      "Network copied detector.stage1_conv11.1.weight, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv11.1.bias, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv11.1.running_mean, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv11.1.running_var, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv11.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv12.0.weight, size:torch.Size([256, 512, 1, 1])\n",
      "Network copied detector.stage1_conv12.1.weight, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv12.1.bias, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv12.1.running_mean, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv12.1.running_var, size:torch.Size([256])\n",
      "Network copied detector.stage1_conv12.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage1_conv13.0.weight, size:torch.Size([512, 256, 3, 3])\n",
      "Network copied detector.stage1_conv13.1.weight, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv13.1.bias, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv13.1.running_mean, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv13.1.running_var, size:torch.Size([512])\n",
      "Network copied detector.stage1_conv13.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_a_conv1.0.weight, size:torch.Size([1024, 512, 3, 3])\n",
      "Network copied detector.stage2_a_conv1.1.weight, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv1.1.bias, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv1.1.running_mean, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv1.1.running_var, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv1.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_a_conv2.0.weight, size:torch.Size([512, 1024, 1, 1])\n",
      "Network copied detector.stage2_a_conv2.1.weight, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv2.1.bias, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv2.1.running_mean, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv2.1.running_var, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv2.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_a_conv3.0.weight, size:torch.Size([1024, 512, 3, 3])\n",
      "Network copied detector.stage2_a_conv3.1.weight, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv3.1.bias, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv3.1.running_mean, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv3.1.running_var, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv3.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_a_conv4.0.weight, size:torch.Size([512, 1024, 1, 1])\n",
      "Network copied detector.stage2_a_conv4.1.weight, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv4.1.bias, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv4.1.running_mean, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv4.1.running_var, size:torch.Size([512])\n",
      "Network copied detector.stage2_a_conv4.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_a_conv5.0.weight, size:torch.Size([1024, 512, 3, 3])\n",
      "Network copied detector.stage2_a_conv5.1.weight, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv5.1.bias, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv5.1.running_mean, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv5.1.running_var, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv5.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_a_conv6.0.weight, size:torch.Size([1024, 1024, 3, 3])\n",
      "Network copied detector.stage2_a_conv6.1.weight, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv6.1.bias, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv6.1.running_mean, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv6.1.running_var, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv6.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_a_conv7.0.weight, size:torch.Size([1024, 1024, 3, 3])\n",
      "Network copied detector.stage2_a_conv7.1.weight, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv7.1.bias, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv7.1.running_mean, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv7.1.running_var, size:torch.Size([1024])\n",
      "Network copied detector.stage2_a_conv7.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage2_b_conv.0.weight, size:torch.Size([64, 512, 1, 1])\n",
      "Network copied detector.stage2_b_conv.1.weight, size:torch.Size([64])\n",
      "Network copied detector.stage2_b_conv.1.bias, size:torch.Size([64])\n",
      "Network copied detector.stage2_b_conv.1.running_mean, size:torch.Size([64])\n",
      "Network copied detector.stage2_b_conv.1.running_var, size:torch.Size([64])\n",
      "Network copied detector.stage2_b_conv.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied detector.stage3_conv1.0.weight, size:torch.Size([1024, 1280, 3, 3])\n",
      "Network copied detector.stage3_conv1.1.weight, size:torch.Size([1024])\n",
      "Network copied detector.stage3_conv1.1.bias, size:torch.Size([1024])\n",
      "Network copied detector.stage3_conv1.1.running_mean, size:torch.Size([1024])\n",
      "Network copied detector.stage3_conv1.1.running_var, size:torch.Size([1024])\n",
      "Network copied detector.stage3_conv1.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied behavior_conv.0.weight, size:torch.Size([512, 1024, 3, 3])\n",
      "Network copied behavior_conv.1.weight, size:torch.Size([512])\n",
      "Network copied behavior_conv.1.bias, size:torch.Size([512])\n",
      "Network copied behavior_conv.1.running_mean, size:torch.Size([512])\n",
      "Network copied behavior_conv.1.running_var, size:torch.Size([512])\n",
      "Network copied behavior_conv.1.num_batches_tracked, size:torch.Size([])\n",
      "Network copied behavior_conv.3.weight, size:torch.Size([256, 512, 3, 3])\n",
      "Network copied behavior_conv.4.weight, size:torch.Size([256])\n",
      "Network copied behavior_conv.4.bias, size:torch.Size([256])\n",
      "Network copied behavior_conv.4.running_mean, size:torch.Size([256])\n",
      "Network copied behavior_conv.4.running_var, size:torch.Size([256])\n",
      "Network copied behavior_conv.4.num_batches_tracked, size:torch.Size([])\n",
      "Network copied behavior_fc.0.weight, size:torch.Size([1024, 2304])\n",
      "Network copied behavior_fc.0.bias, size:torch.Size([1024])\n",
      "Network copied behavior_fc.3.weight, size:torch.Size([16, 1024])\n",
      "Network copied behavior_fc.3.bias, size:torch.Size([16])\n",
      "Network copied behavior_conv1d.0.weight, size:torch.Size([2304, 2304, 3])\n",
      "Network copied behavior_conv1d.0.bias, size:torch.Size([2304])\n",
      "Network copied behavior_conv1d.3.weight, size:torch.Size([2304, 2304, 3])\n",
      "Network copied behavior_conv1d.3.bias, size:torch.Size([2304])\n",
      "loaded with ../checkpoint/behavior/anotherMissOh_only_params_voc_person_behavior_new.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LeakyReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/serialization.py:454: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded with ../checkpoint/face/anotherMissOh_face.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_emotion_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_object_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_relation_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_place_integration.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "place_model(\n",
       "  (detector): YoloD(\n",
       "    (stage1_conv1): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv4): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv5): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv6): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv7): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv8): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv9): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv10): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv11): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv12): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv13): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_maxpl): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (stage2_a_conv1): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv2): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv3): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv4): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv5): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv6): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv7): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_b_conv): Sequential(\n",
       "      (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage3_conv1): Sequential(\n",
       "      (0): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "  )\n",
       "  (place_conv): Sequential(\n",
       "    (0): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (bert): BERT(\n",
       "    (embedding): BERTEmbedding(\n",
       "      (position): PositionalEmbedding()\n",
       "      (dropout): Dropout(p=0.0)\n",
       "    )\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=22, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(123)\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "# set test loader params\n",
    "test_params = {\"batch_size\": opt.batch_size,\n",
    "               \"shuffle\": False,\n",
    "               \"drop_last\": False,\n",
    "               \"collate_fn\": custom_collate_fn}\n",
    "\n",
    "# set test loader\n",
    "test_loader = DataLoader(infer_set, **test_params)\n",
    "\n",
    "# ---------------(1) load refined models --------------------\n",
    "# get the trained models from\n",
    "# https://drive.google.com/drive/folders/1WXzP8nfXU4l0cNOtSPX9O1qxYH2m6LIp\n",
    "# person and behavior\n",
    "# person and behavior\n",
    "if True :\n",
    "    print(\"-----------person---behavior-------model---------------\")\n",
    "    model_p = behavior_model(num_persons, num_behaviors, opt, device)\n",
    "    trained_persons = '../checkpoint/behavior' + os.sep + \"{}\".format(\n",
    "        'anotherMissOh_only_params_voc_person_behavior_new.pth')\n",
    "    if optimistic_restore(model_p, torch.load(trained_persons)):\n",
    "        #model1.load_state_dict(torch.load(trained_persons))\n",
    "        print(\"loaded with {}\".format(trained_persons))\n",
    "\n",
    "else:\n",
    "    # pre-trained behavior model\n",
    "    # step 1: person trained on voc 50 epoch\n",
    "    # step 2: person feature based behavior sequence learning 100 epoch\n",
    "    trained_persons = '../checkpoint/behavior' + os.sep + \"{}\".format(\n",
    "        'anotherMissOh_voc_person_behavior_new.pth')\n",
    "    model_p = torch.load(trained_persons)\n",
    "    print(\"loaded with person and behavior model {}\".format(trained_persons))\n",
    "model_p.cuda(device)\n",
    "model_p.eval()\n",
    "\n",
    "# face model\n",
    "if False:\n",
    "    model_face = face_model(num_persons, num_faces, device)\n",
    "    trained_face = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_face.pth')\n",
    "    model_face.load_state_dict(torch.load(trained_face))\n",
    "    print(\"loaded with {}\".format(trained_face))\n",
    "else:\n",
    "    trained_face = '../checkpoint/face' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_face.pth')\n",
    "    model_face =torch.load(trained_face)\n",
    "    print(\"loaded with {}\".format(trained_face))\n",
    "    \n",
    "model_face.cuda(device)\n",
    "model_face.eval()\n",
    "\n",
    "# emotion model\n",
    "if True:\n",
    "    model_emo = emotion_model(opt.emo_net_ch, num_persons, device)\n",
    "    trained_emotion = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_emotion_integration.pth')\n",
    "    model_emo.load_state_dict(torch.load(trained_emotion))\n",
    "    print(\"loaded with {}\".format(trained_emotion))\n",
    "model_emo.cuda(device)\n",
    "model_emo.eval()\n",
    "\n",
    "# object model\n",
    "if True:\n",
    "    # add model\n",
    "    model_object = object_model(num_objects)\n",
    "    trained_object = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_object_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_object))\n",
    "    model_object.load_state_dict(torch.load(trained_object))\n",
    "\n",
    "model_object.cuda(device)\n",
    "model_object.eval()\n",
    "\n",
    "\n",
    "# relation model\n",
    "if True:\n",
    "    # add model\n",
    "    model_relation = relation_model(num_persons, num_objects, num_relations, opt, device)\n",
    "    trained_relation = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_relation_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_relation))\n",
    "    model_relation.load_state_dict(torch.load(trained_relation))\n",
    "model_relation.cuda(device)\n",
    "model_relation.eval()\n",
    "\n",
    "# place model\n",
    "if True:\n",
    "    model_place = place_model(num_persons, num_behaviors, device)\n",
    "    # add model\n",
    "    trained_place = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "        'anotherMissOh_only_params_place_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_place))\n",
    "    model_place.load_state_dict(torch.load(trained_place)['model'])\n",
    "model_place.cuda(device)\n",
    "model_place.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the color map for detection results\n",
    "colors = pickle.load(open(\"../Yolo_v2_pytorch/src/pallete\", \"rb\"))\n",
    "\n",
    "width, height = (1024, 768)\n",
    "width_ratio = float(opt.image_size) / width\n",
    "height_ratio = float(opt.image_size) / height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_blank(s):\n",
    "    return bool(s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_json(episode, scene, frm, info, save_file=None):\n",
    "\n",
    "    if save_file is None:\n",
    "        save_file = 'temp_graph'\n",
    "    import string\n",
    "    strseq = string.ascii_uppercase\n",
    "\n",
    "    # define  graph\n",
    "    dot = Digraph('G',filename='{}.gv'.format(save_file),engine='fdp')\n",
    "    dot.attr('graph', rotate = '0', dpi='600',rankdir='TB', size='10,8')\n",
    "    dot.attr('node', height='0.1', fontsize='6')\n",
    "    dot.attr('edge', fontsize='6')\n",
    "\n",
    "    place = \"{}\".format(info['place'])\n",
    "    sound = \"{}\".format(info['sound'])\n",
    "\n",
    "    if not is_not_blank(place):\n",
    "        place = 'none'\n",
    "    if not is_not_blank(sound):\n",
    "        sound = 'none'\n",
    "\n",
    "    num_of_persons = len(info['persons'])\n",
    "    num_of_objects = len(info['objects'])\n",
    "\n",
    "    frm_graph = 'episode_{}_scene_{}_shot_{}'.format(\n",
    "        episode, scene, frm)\n",
    "\n",
    "    #dot.node(frm_graph, style='filled', color='lightgrey')\n",
    "    episode_node = \"episode_{:02d}\".format(episode)\n",
    "    scene_node = \"scene_{:03d}\".format(scene)\n",
    "    frame_node = \"shot_{:04d}\".format(frm)\n",
    "    dot.node(episode_node, style='filled', color='lightgrey')\n",
    "    dot.node(scene_node, style='filled', color='lightgrey')\n",
    "    dot.node(frame_node, style='filled', color='lightgrey')\n",
    "\n",
    "    # backgrounds--------------------------------------------\n",
    "    dot.node(place, style='filled', color='lightblue')\n",
    "    dot.node(sound, style='filled', color='lightblue')\n",
    "\n",
    "    if is_not_blank(episode_node) and is_not_blank(scene_node):\n",
    "        dot.edge(episode_node, scene_node)\n",
    "\n",
    "    if is_not_blank(scene_node) and is_not_blank(frame_node):\n",
    "        dot.edge(scene_node, frame_node)\n",
    "\n",
    "    if is_not_blank(frame_node) and is_not_blank(place):\n",
    "        dot.edge(frame_node, place)\n",
    "\n",
    "    if is_not_blank(frame_node) and is_not_blank(sound):\n",
    "        dot.edge(frame_node, sound)\n",
    "\n",
    "    # person ------------------------------------------------\n",
    "    for person_id in info['persons'].keys():\n",
    "\n",
    "        if is_not_blank(person_id):\n",
    "            dot.node(person_id)\n",
    "\n",
    "        # behavior---\n",
    "        if 'behavior' in info['persons'][person_id].keys():\n",
    "            behavior_id = info['persons'][person_id]['behavior']\n",
    "        else:\n",
    "            behavior_id = 'none'\n",
    "        if is_not_blank(behavior_id):\n",
    "            dot.node(behavior_id, style='filled', color='green')\n",
    "\n",
    "        # emotion---\n",
    "        if 'emotion' in info['persons'][person_id].keys():\n",
    "            emotion_id = info['persons'][person_id]['emotion']\n",
    "        else:\n",
    "            emotion_id = 'none'\n",
    "        if is_not_blank(emotion_id):\n",
    "            dot.node(emotion_id, style='filled', color='blue')\n",
    "\n",
    "        if is_not_blank(frame_node) and is_not_blank(person_id):\n",
    "            dot.edge(frame_node, person_id)\n",
    "\n",
    "        if is_not_blank(person_id) and is_not_blank(behavior_id):\n",
    "            dot.edge(person_id, behavior_id)\n",
    "\n",
    "        if is_not_blank(person_id) and is_not_blank(emotion_id):\n",
    "            dot.edge(person_id, emotion_id)\n",
    "\n",
    "    # relation ---------------------------------------------\n",
    "    for object_id in info['objects'].keys():\n",
    "        if is_not_blank(object_id):\n",
    "            dot.node(object_id, style='filled', color='gold')\n",
    "\n",
    "    for person_id in info['relations'].keys():\n",
    "        if person_id not in info['persons'].keys():\n",
    "            dot.node(person_id)\n",
    "            dot.edge(frame_node, person_id)\n",
    "\n",
    "        for object_id in info['relations'][person_id].keys() :\n",
    "            if object_id not in info['objects'].keys():\n",
    "                dot.node(object_id)\n",
    "                dot.edge(frame_node, object_id)\n",
    "            predicate = info['relations'][person_id][object_id]\n",
    "            dot.edge(person_id, object_id,label=predicate, color='red')\n",
    "\n",
    "    # convert dot graph to json\n",
    "    if False:\n",
    "        dot_to_json =json.dumps(json_graph.node_link_data(dot))\n",
    "    else:\n",
    "        dot_to_json = json.dumps(info)\n",
    "\n",
    "    with open('{}.json'.format(save_file), 'w') as f:\n",
    "        json.dump(dot_to_json, f)\n",
    "\n",
    "    # show in image\n",
    "    dot.format = 'png'\n",
    "    dot.render('{}.gv'.format(save_file), view=True) \n",
    "\n",
    "    graph = cv2.imread('{}.gv.png'.format(save_file))\n",
    "    graph = cv2.resize(graph, dsize=(0, 0), fx=600.0/graph.shape[0], fy=600.0/graph.shape[0])\n",
    "\n",
    "    if True:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(graph)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persons': {'Haeyoung1': {'emotion': 'happy', 'behavior': 'talking'}, 'Deogi': {'emotion': 'happy', 'behavior': 'eating'}}, 'objects': {'spoon': {'Deogi': 'N_R'}}, 'relations': {'Deogi': {'spoon': 'holding'}}, 'place': 'kitchen', 'sound': 'talking'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip = 0\n",
    "frm = 0\n",
    "\n",
    "#---------------graph structure--------------------------\n",
    "graph_json = {}\n",
    "graph_json['persons'] = {}\n",
    "graph_json['objects'] = {}\n",
    "graph_json['relations'] = {}\n",
    "\n",
    "# ---------------persons---------------------------------\n",
    "graph_json['persons']['Haeyoung1'] = {}\n",
    "graph_json['persons']['Haeyoung1']['emotion'] = 'happy'\n",
    "graph_json['persons']['Haeyoung1']['behavior'] = 'talking'\n",
    "graph_json['persons']['Deogi'] = {}\n",
    "graph_json['persons']['Deogi']['emotion'] = 'happy'\n",
    "graph_json['persons']['Deogi']['behavior'] = 'eating'\n",
    "\n",
    "# ---------------objects---------------------------------\n",
    "graph_json['objects']['spoon'] = {}\n",
    "graph_json['objects']['spoon']['Deogi'] = 'N_R'\n",
    "\n",
    "# ---------------Relations-------------------------------\n",
    "graph_json['relations']['Deogi'] = {}\n",
    "graph_json['relations']['Deogi']['spoon'] = 'holding'\n",
    "\n",
    "# ---------------Backgrounds-----------------------------\n",
    "graph_json['place'] = 'kitchen'\n",
    "graph_json['sound'] = 'talking'\n",
    "\n",
    "info = graph_json\n",
    "print(info)\n",
    "\n",
    "graph_to_json(episode, clip, frm, graph_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sequence buffers\n",
    "buffer_images = []\n",
    "graph_info = {}\n",
    "# load test clips\n",
    "for iter, batch in enumerate(test_loader):\n",
    "    image, info = batch\n",
    "    \n",
    "    # sort label info on fullrect\n",
    "    image, label, behavior_label, obj_label, face_label, emo_label, frame_id = SortFullRect(\n",
    "        image, info, is_train=False)\n",
    "\n",
    "    try :\n",
    "        image = torch.cat(image,0).cuda(device)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # -----------------(2) inference -------------------------\n",
    "    # person and behavior predictions\n",
    "    # person\n",
    "    # logits : [1, 125, 14, 14]\n",
    "    if False:\n",
    "        p_logits, _ = model_p(image)\n",
    "        predictions_p = post_processing(p_logits,\n",
    "                                        opt.image_size,\n",
    "                                        PersonCLS,\n",
    "                                        model_p.detector.anchors,\n",
    "                                        opt.conf_threshold,\n",
    "                                        opt.nms_threshold)\n",
    "    \n",
    "    # logits : [1, 125, 14, 14]\n",
    "    # behavior_logits : [1, 135, 14, 14]\n",
    "    else :\n",
    "        predictions_p, b_logits = model_p(image, label, behavior_label)\n",
    "        print(\"person_label:{}\".format(label))\n",
    "\n",
    "    # face\n",
    "    #if np.array(face_label).size > 0 :\n",
    "    face_logits = model_face(image)\n",
    "    predictions_face = post_processing(face_logits,\n",
    "                                        opt.image_size,\n",
    "                                        FaceCLS,\n",
    "                                        model_face.detector.anchors,\n",
    "                                        opt.conf_threshold,\n",
    "                                        opt.nms_threshold)\n",
    "    \n",
    "    if len(predictions_face) != 0:\n",
    "            num_preds = len(predictions_face)\n",
    "            num_face_per_pred = [len(pred) for pred in predictions_face]\n",
    "            image_c = image.permute(0,2,3,1).cpu()\n",
    "            face_crops, _ = crop_face_emotion(image_c, predictions_face, None, opt)\n",
    "            face_crops = face_crops.cuda(device).contiguous()\n",
    "            emo_logits_raw = model_emo(face_crops)\n",
    "\n",
    "            emo_logits, idx = [], 0\n",
    "            for pl in num_face_per_pred:\n",
    "                emo_logits.append(emo_logits_raw[idx:idx+pl])\n",
    "                idx = idx+pl\n",
    "\n",
    "    # object\n",
    "    if np.array(obj_label).size > 0 :\n",
    "        object_logits, _ = model_object(image)\n",
    "\n",
    "        predictions_object = post_processing(object_logits,\n",
    "                                             opt.image_size,\n",
    "                                             ObjectCLS,\n",
    "                                             model_object.detector.anchors,\n",
    "                                             opt.conf_threshold,\n",
    "                                             opt.nms_threshold)\n",
    "    else:\n",
    "        object_logits = None\n",
    "        predictions_object = None\n",
    "        \n",
    "    # relation\n",
    "    if np.array(obj_label).size > 0 and np.array(label).size > 0:\n",
    "        r_preds, r_obj_preds, relation_predictions = model_relation(image, label, obj_label)    \n",
    "    else:\n",
    "        r_preds = None\n",
    "        r_obj_preds = None\n",
    "        \n",
    "    print(\"===r_preds:{}\".format(r_preds))\n",
    "\n",
    "\n",
    "    # place\n",
    "    images_norm = []; info_place = []; preds_place = []\n",
    "    for idx in range(len(image)):\n",
    "        image_resize = image[idx]\n",
    "        images_norm.append(image_resize)\n",
    "        info_place.append(info[0][idx]['place'])\n",
    "        frame_place = frame_id.copy()\n",
    "    info_place = label_mapping(info_place)\n",
    "    buffer_images = place_buffer(images_norm, buffer_images)\n",
    "    pl_updated=False\n",
    "    buffer_idx = 10 - (len(images_norm) %10)\n",
    "    images_norm = buffer_images[-buffer_idx:] + images_norm\n",
    "    for plidx in range(len(images_norm)//10):\n",
    "        batch_images = torch.stack(images_norm[plidx*10:(plidx+1)*10]).cuda(device).unsqueeze(0)\n",
    "        output = model_place(batch_images)\n",
    "        output = torch.cat((output[:, :9], output[:, 10:]), 1) # None excluded. For None prediction, comment this line out.\n",
    "        preds = torch.argmax(output, -1).tolist() # (T, n_class) ->(T, )\n",
    "        for idx in range(len(preds)):\n",
    "            if preds[idx] >= 9: preds[idx] += 1\n",
    "        preds_place += preds;\n",
    "        pl_updated = True\n",
    "    buffer_images = images_norm[-10:]\n",
    "    preds_place = preds_place[buffer_idx:]\n",
    "    assert len(preds_place) == len(info_place)\n",
    "    preds_place_txt = label_remapping(preds_place)\n",
    "    target_place_txt = label_remapping(info_place)\n",
    "    \n",
    "    print(\"===preds_place_txt:{}\".format(preds_place_txt))\n",
    "    \n",
    "    for idx, frame in enumerate(frame_id):\n",
    "        \n",
    "        # ---------------(3) mkdir for evaluations----------------------\n",
    "        f_info = frame[0].split('/')\n",
    "        save_dir = '../results/drama-graph/{}/{}/{}/'.format(\n",
    "            f_info[4], f_info[5], f_info[6])\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        f_file = f_info[7]\n",
    "        mAP_file = \"{}_{}_{}_{}\".format(f_info[4],\n",
    "                                        f_info[5],\n",
    "                                        f_info[6],\n",
    "                                        f_info[7].replace(\"jpg\", \"txt\"))\n",
    "        if opt.display:\n",
    "            # AnotherMissOh07_002_0036_IMAGE_0000002672.txt\n",
    "            print(\"frame.__len__{}, mAP_file:{}\".format(len(frame_id), mAP_file))\n",
    "            \n",
    "        # --------------(5) visualization of inferences ----------\n",
    "        # out of try : pdb.set_trace = lambda : None\n",
    "        #**************************************\n",
    "        graph_json = {}\n",
    "        graph_json['persons'] = {}\n",
    "        graph_json['objects'] = {}\n",
    "        graph_json['relations'] = {}\n",
    "        graph_json['sound'] = 'none'\n",
    "        graph_json['place'] = 'none'\n",
    "        #**************************************\n",
    "        frm_name = \"episode_{:02d}_{}_{}_{}\".format(episode,\n",
    "                                                    f_info[5],\n",
    "                                                    f_info[6],\n",
    "                                                    f_info[7].replace(\".jpg\",\"\"))\n",
    "        save_file = save_dir + frm_name\n",
    "        \n",
    "        shot = int(f_info[6])\n",
    "        scene = int(f_info[5])\n",
    "        episode = episode\n",
    "        \n",
    "        try:\n",
    "            # for some empty video clips\n",
    "            img = image[idx]\n",
    "            # ToTensor function normalizes image pixel values into [0,1]\n",
    "            np_img = img.cpu().numpy()\n",
    "            np_img = np.transpose(np_img,(1,2,0)) * 255\n",
    "            output_image = cv2.cvtColor(np_img,cv2.COLOR_RGB2BGR)\n",
    "            output_image = cv2.resize(output_image, (width, height))\n",
    "            \n",
    "            # face and emotion\n",
    "            if len(predictions_face) != 0:\n",
    "                print(\"===== predictions_face: {}\".format(predictions_face))\n",
    "                prediction_face = predictions_face[idx]\n",
    "                prediction_emo  = emo_logits[idx]\n",
    "                for pi,pred in enumerate(prediction_face):\n",
    "                    xmin = int(max(float(pred[0]) / width_ratio, 0))\n",
    "                    ymin = int(max(float(pred[1]) / height_ratio, 0))\n",
    "                    xmax = int(min((float(pred[2])) / width_ratio, width))\n",
    "                    ymax = int(min((float(pred[3])) / height_ratio, height))\n",
    "                    color = colors[FaceCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "\n",
    "                    # save detection results\n",
    "                    pred_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "\n",
    "                    print(\"face_pred:{}\".format(cat_pred))\n",
    "                    print(\"detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "\n",
    "                    #**************************************************\n",
    "                    graph_json['persons'][pred_cls] = {}\n",
    "                    #**************************************************\n",
    "\n",
    "                    # update emotion model and the prediction\n",
    "                    emo_ij = F.softmax(prediction_emo[pi], dim=0).argmax().detach().cpu().numpy()\n",
    "                    emo_txt = EmoCLS[emo_ij]\n",
    "                    cv2.putText(output_image, emo_txt, (xmin, ymin),\n",
    "                                cv2.FONT_HERSHEY_PLAIN, 2, (0,255,255), 2,\n",
    "                                cv2.LINE_AA)\n",
    "                    #******************************************************\n",
    "                    graph_json['persons'][pred_cls]['emotion'] = emo_txt\n",
    "                    #******************************************************\n",
    "            else:\n",
    "                print(\"===== None-predictions_face: {}\".format(predictions_face))\n",
    "            \n",
    "\n",
    "            if len(predictions_p) != 0 :\n",
    "                print(\"===== predictions_p: {}\".format(predictions_p))\n",
    "                prediction = predictions_p[idx]\n",
    "                if True:\n",
    "                    b_logit = b_logits[idx]\n",
    "\n",
    "                # person and behavior\n",
    "                num_preds = len(prediction)\n",
    "                for jdx, pred in enumerate(prediction):  \n",
    "                    # person\n",
    "                    xmin = int(max(float(pred[0]) / width_ratio, 0))\n",
    "                    ymin = int(max(float(pred[1]) / height_ratio, 0))\n",
    "                    xmax = int(min((float(pred[2])) / width_ratio, width))\n",
    "                    ymax = int(min((float(pred[3])) / height_ratio, height))\n",
    "                    color = colors[PersonCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "                    \n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % float(pred[4]),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % float(pred[4]),\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "                        \n",
    "                    pred_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                    print(\"person_pred:{}\".format(cat_pred))\n",
    "                    \n",
    "                    #**************************************************\n",
    "                    if pred_cls not in graph_json['persons'].keys():\n",
    "                        graph_json['persons'][pred_cls] = {}\n",
    "                    #**************************************************\n",
    "                    \n",
    "                    # behavior\n",
    "                    if True:\n",
    "                        value, index = b_logit[jdx].max(0)\n",
    "\n",
    "                        b_idx = index.cpu().numpy()\n",
    "                        b_pred = PBeHavCLS[b_idx]\n",
    "                        \n",
    "                        cv2.putText(\n",
    "                            output_image, '+ behavior : ' + b_pred,\n",
    "                            (xmin, ymin + text_size[1] + 4 + 12),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "                        pred_beh_cls = b_pred.replace(' ', '_')\n",
    "                        pred_beh_cls = pred_beh_cls.replace('/', '_')\n",
    "                        \n",
    "                        #******************************************************\n",
    "                        graph_json['persons'][pred_cls]['behavior'] = pred_beh_cls\n",
    "                        #******************************************************\n",
    "                        \n",
    "                        cat_pred_beh = '%s %s %s %s %s %s\\n' % (\n",
    "                            pred_beh_cls,\n",
    "                            str(pred[4]),\n",
    "                            str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "\n",
    "                        print(\"behavior_pred:{}\".format(cat_pred_beh))\n",
    "            else:\n",
    "                print(\"===== None-predictions_p: {}\".format(predictions_p))\n",
    "\n",
    "            # object\n",
    "            if predictions_object is not None and len(predictions_object) > 0:\n",
    "                print(\"===== predictions_object: {}\".format(predictions_object))\n",
    "                prediction_object = predictions_object[0]\n",
    "                num_preds = len(prediction)\n",
    "                for jdx, pred in enumerate(prediction_object):\n",
    "                    \n",
    "                    # save detection results\n",
    "                    pred_obj_cls = pred[5]\n",
    "                    \n",
    "                    #if True:\n",
    "                    xmin = int(max(pred[0] / width_ratio, 0))\n",
    "                    ymin = int(max(pred[1] / height_ratio, 0))\n",
    "                    xmax = int(min((pred[2]) / width_ratio, width))\n",
    "                    ymax = int(min((pred[3]) / height_ratio, height))\n",
    "                    color = colors[ObjectCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_obj_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "\n",
    "                    print(\"object_pred:{}\".format(cat_pred))\n",
    "                    \n",
    "                    #**************************************************\n",
    "                    graph_json['objects'][pred_obj_cls] = {}\n",
    "                    #**************************************************\n",
    "                    \n",
    "            else:\n",
    "                print(\"===== None-predictions_object: {}\".format(predictions_object))\n",
    "                        \n",
    "            # relation\n",
    "            if r_preds is not None and len(r_preds):\n",
    "                r_pred = r_preds[idx]\n",
    "                r_obj_pred = r_obj_preds[idx]\n",
    "                relation_prediction = relation_predictions[idx]\n",
    "                num_preds = len(r_pred)\n",
    "                \n",
    "                print(\"===== r_preds: {}\".format(r_preds))\n",
    "                for jdx, pred in enumerate(r_pred):\n",
    "                    \n",
    "                    pred_per_cls = pred[5]\n",
    "                    #if False:\n",
    "                    xmin = int(max(float(pred[0]) / width_ratio, 0))\n",
    "                    ymin = int(max(float(pred[1]) / height_ratio, 0))\n",
    "                    xmax = int(min((float(pred[2])) / width_ratio, width))\n",
    "                    ymax = int(min((float(pred[3])) / height_ratio, height))\n",
    "                    color = colors[PersonCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred_per_cls + ' : %.2f' % float(pred[4]),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % float(pred[4]),\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "                    \n",
    "                    #*****************************************************\n",
    "                    graph_json['relations'][pred_per_cls] = {}\n",
    "                    #*****************************************************\n",
    "\n",
    "                    for kdx, obj_pred in enumerate(r_obj_pred):\n",
    "                        pred_obj_cls = obj_pred[5]\n",
    "                        \n",
    "                        #if False:\n",
    "                        xmin = int(max(float(obj_pred[0]) / width_ratio, 0))\n",
    "                        ymin = int(max(float(obj_pred[1]) / height_ratio, 0))\n",
    "                        xmax = int(min((float(obj_pred[2])) / width_ratio, width))\n",
    "                        ymax = int(min((float(obj_pred[3])) / height_ratio, height))\n",
    "\n",
    "                        color = colors[ObjectCLS.index(obj_pred[5])]\n",
    "                        cv2.rectangle(output_image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "\n",
    "                        text_size = cv2.getTextSize(\n",
    "                            pred_obj_cls + ' : %.2f' % float(obj_pred[4]),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                        cv2.rectangle(\n",
    "                            output_image,\n",
    "                            (xmin, ymin),\n",
    "                            (xmin + text_size[0] + 100,\n",
    "                             ymin + text_size[1] + 20), color, -1)\n",
    "                        cv2.putText(\n",
    "                            output_image, obj_pred[5] + ' : %.2f' % float(obj_pred[4]),\n",
    "                            (xmin, ymin + text_size[1] + 4),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "                        \n",
    "                        value, ind = relation_prediction[kdx].max(1)\n",
    "                        ind = int(ind.cpu().numpy())\n",
    "                        rel_ind = P2ORelCLS[ind]\n",
    "                        pred_pred_cls = rel_ind\n",
    "                        \n",
    "                        #if False:\n",
    "                        cv2.putText(\n",
    "                            output_image, '+ relation : ' + rel_ind,\n",
    "                            (xmin, ymin + text_size[1] + 4 + 12),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)                        \n",
    "\n",
    "                        cat_pred = '%s %s %s %s %s\\n' % (\n",
    "                            pred_cls, str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                        print(\"relation_pred:{}\".format(cat_pred))\n",
    "                        \n",
    "                        #*****************************************************\n",
    "                        graph_json['relations'][pred_per_cls][pred_obj_cls] = pred_pred_cls\n",
    "                        #*****************************************************\n",
    "            else:\n",
    "                print(\"===== None-r_preds: {}\".format(r_preds))\n",
    "                        \n",
    "            # place\n",
    "            if len(preds_place_txt) != 0:\n",
    "                print(\"===== place_pred: {}\".format(preds_place_txt))\n",
    "                cv2.putText(output_image, \"place : \" + preds_place_txt[idx],\n",
    "                    (30, 30),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "                \n",
    "                #*****************************************\n",
    "                graph_json['place'] = preds_place_txt[idx]\n",
    "                #*****************************************\n",
    "                print('place_pred :', preds_place_txt[idx])\n",
    "                \n",
    "            else:\n",
    "                print(\"===== None-place_pred: {}\".format(preds_place_txt))\n",
    "            \n",
    "            # save output image  \n",
    "            cv2.imwrite(save_dir + \"{}\".format(f_file), output_image)\n",
    "            # save images\n",
    "            plt_output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.imshow(plt_output_image.astype('uint8'))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            dot_to_json = json.dumps(graph_json)\n",
    "            with open('{}.json'.format(save_file), 'w') as f:\n",
    "                json.dump(dot_to_json, f)\n",
    "                print(graph_json)\n",
    "            graph_to_json(episode, scene, shot, graph_json, save_file)\n",
    "        except:\n",
    "            \n",
    "            # save output image  \n",
    "            cv2.imwrite(save_dir + \"{}\".format(f_file), output_image)\n",
    "            # save images\n",
    "            plt_output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(20,10))\n",
    "            plt.imshow(plt_output_image.astype('uint8'))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            dot_to_json = json.dumps(graph_json)\n",
    "            with open('{}.json'.format(save_file), 'w') as f:\n",
    "                json.dump(dot_to_json, f)\n",
    "                print(graph_json)\n",
    "            graph_to_json(episode, scene, shot, graph_json, save_file)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
