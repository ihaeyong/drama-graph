{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MissOh DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnotherMissOh Visual Structure\n",
    "- json_data['file_name'] : 'AnotherMissOh01.mp4'\n",
    "- json_data['visual_results']\n",
    "- json_data['visual_results'][0].keys() : dict_keys(['start_time', 'end_time', 'vid', 'image_info'])\n",
    "- {\n",
    "'start_time': '00:02:51;16', \n",
    "'end_time': '00:02:54;15', \n",
    "'vid': 'AnotherMissOh01_001_0078', \n",
    "'image_info': ...}\n",
    "- json_data['visual_results'][0]['image_info']\n",
    "- [{'frame_id': 'AnotherMissOh01_001_0078_IMAGE_0000004295', \n",
    "'place': 'none', \n",
    "'persons': [\n",
    "{'person_id': 'Haeyoung1', \n",
    "'person_info': {\n",
    "'face_rect': {'min_x': 515, 'min_y': 0, 'max_x': 845, 'max_y': 443}, \n",
    "'full_rect': {'min_x': 278, 'min_y': 2, 'max_x': 1025, 'max_y': 769}, \n",
    "'behavior': 'stand up', \n",
    "'predicate': 'none', \n",
    "'emotion': 'Neutral', \n",
    "'face_rect_score': '0.5', \n",
    "'full_rect_score': '0.9'}, \n",
    "'related_objects': []}], \n",
    "'objects': []}, \n",
    "- {'frame_id': 'AnotherMissOh01_001_0078_IMAGE_0000004311', \n",
    "'place': '', \n",
    "'persons': [{\n",
    "'person_id':'Haeyoung1',\n",
    "'person_info': {\n",
    "'face_rect': {'min_x': 515, 'min_y': 0, 'max_x': 831, 'max_y': 411}, \n",
    "'full_rect': {'min_x': 270, 'min_y': 0, 'max_x': 1025, 'max_y': 768}, \n",
    "'behavior': 'stand up', \n",
    "'predicate': 'none', \n",
    "'emotion': 'Neutral', \n",
    "'face_rect_score': '0.5', \n",
    "'full_rect_score': '0.9'}, \n",
    "'related_objects': []}],\n",
    "'objects': []},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install graphviz xdg-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-897117e53d12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import glob\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import json\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Yolo_v2_pytorch.src.utils import *\n",
    "from graphviz import Digraph, Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_blank(s):\n",
    "    return bool(s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\n",
      "(39, 129, 113)\n"
     ]
    }
   ],
   "source": [
    "MissOh_CLASSES = ['person']\n",
    "print(MissOh_CLASSES[0])\n",
    "global colors\n",
    "colors = pickle.load(open(\"../Yolo_v2_pytorch/src/pallete\", \"rb\"))\n",
    "print(colors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"../\") # go to parent dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1, conf_threshold=0.35, data_path_test='./Yolo_v2_pytorch/missoh_test/', display=False, emo_net_ch=64, image_size=448, img_path='./data/AnotherMissOh/AnotherMissOh_images_ver3.2/', json_path='./data/AnotherMissOh/AnotherMissOh_Visual_ver3.2/', model='baseline', nms_threshold=0.5, pre_trained_model_type='model', saved_path='./checkpoint/refined_models')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "from Yolo_v2_pytorch.src.utils import *\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from Yolo_v2_pytorch.src.yolo_net import Yolo\n",
    "from Yolo_v2_pytorch.src.anotherMissOh_dataset import AnotherMissOh, Splits, SortFullRect, PersonCLS,PBeHavCLS, FaceCLS, ObjectCLS, P2ORelCLS\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from lib.place_model import place_model, label_mapping, accuracy, label_remapping, place_buffer\n",
    "from lib.person_model import person_model\n",
    "from lib.behavior_model import behavior_model\n",
    "from lib.pytorch_misc import optimistic_restore, de_chunkize, clip_grad_norm, flatten\n",
    "from lib.focal_loss import FocalLossWithOneHot, FocalLossWithOutOneHot, CELossWithOutOneHot\n",
    "from lib.face_model import face_model\n",
    "from lib.object_model import object_model\n",
    "from lib.relation_model import relation_model\n",
    "from lib.emotion_model import emotion_model, crop_face_emotion, EmoCLS\n",
    "\n",
    "num_persons = len(PersonCLS)\n",
    "num_behaviors = len(PBeHavCLS)\n",
    "num_faces = len(FaceCLS)\n",
    "num_objects = len(ObjectCLS)\n",
    "num_relations = len(P2ORelCLS)\n",
    "num_emos = len(EmoCLS)\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        \"You Only Look Once: Unified, Real-Time Object Detection\")\n",
    "    parser.add_argument(\"--image_size\",\n",
    "                        type=int, default=448,\n",
    "                        help=\"The common width and height for all images\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=1,\n",
    "                        help=\"The number of images per batch\")\n",
    "    parser.add_argument(\"--conf_threshold\",\n",
    "                        type=float, default=0.35)\n",
    "    parser.add_argument(\"--nms_threshold\",\n",
    "                        type=float, default=0.5)\n",
    "    parser.add_argument(\"--pre_trained_model_type\",\n",
    "                        type=str, choices=[\"model\", \"params\"],\n",
    "                        default=\"model\")\n",
    "    parser.add_argument(\"--data_path_test\",\n",
    "                        type=str,\n",
    "                        default=\"./Yolo_v2_pytorch/missoh_test/\",\n",
    "                        help=\"the root folder of dataset\")\n",
    "\n",
    "    parser.add_argument(\"--saved_path\", type=str,\n",
    "                        default=\"./checkpoint/refined_models\")\n",
    "\n",
    "    parser.add_argument(\"--img_path\", type=str,\n",
    "                        default=\"./data/AnotherMissOh/AnotherMissOh_images_ver3.2/\")\n",
    "    parser.add_argument(\"--json_path\", type=str,\n",
    "                        default=\"./data/AnotherMissOh/AnotherMissOh_Visual_ver3.2/\")\n",
    "    parser.add_argument(\"-model\", dest='model', type=str, default=\"baseline\")\n",
    "    parser.add_argument(\"-display\", dest='display', action='store_true')\n",
    "    parser.add_argument(\"-emo_net_ch\", dest='emo_net_ch',type=int, default=64)\n",
    "    args = parser.parse_args([])\n",
    "    return args\n",
    "\n",
    "# get args.\n",
    "opt = get_args()\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import read_dot\n",
    "#from networkx.drawing.nx_agraph import read_dot\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.img_path = \"../data/AnotherMissOh/AnotherMissOh_images_ver3.2/\"\n",
    "opt.json_path = \"../data/AnotherMissOh/AnotherMissOh_Visual_ver3.2/\"\n",
    "opt.saved_path = \"../checkpoint/refined_models\"\n",
    "opt.display = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = [\n",
    "    Resize((448, 448)),  # should match to Yolo_V2\n",
    "    ToTensor(),\n",
    "    # Normalize(# should match to Yolo_V2\n",
    "    #mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]\n",
    "transf = Compose(tform)\n",
    "\n",
    "# splits the episodes int train, val, test\n",
    "train, val, test = Splits(num_episodes=18)\n",
    "\n",
    "# load datasets\n",
    "train_set = AnotherMissOh(train, opt.img_path, opt.json_path, False)\n",
    "val_set = AnotherMissOh(val, opt.img_path, opt.json_path, False)\n",
    "test_set = AnotherMissOh(test, opt.img_path, opt.json_path, False)\n",
    "\n",
    "episode = 7\n",
    "infer = [episode]\n",
    "infer_set = AnotherMissOh(infer, opt.img_path, opt.json_path, False)\n",
    "\n",
    "\n",
    "# model path\n",
    "model_path = \"{}/anotherMissOh_{}.pth\".format(\n",
    "    opt.saved_path,opt.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "loaded with person and behavior model ../checkpoint/behavior/anotherMissOh_voc_person_behavior_new.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_face.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_emotion_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_object_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_relation_integration.pth\n",
      "loaded with ../checkpoint/refined_models/anotherMissOh_only_params_place_integration.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "place_model(\n",
       "  (detector): YoloD(\n",
       "    (stage1_conv1): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv2): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv4): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv5): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv6): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv7): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv8): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stage1_conv9): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv10): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv11): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv12): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage1_conv13): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_maxpl): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (stage2_a_conv1): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv2): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv3): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv4): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv5): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv6): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_a_conv7): Sequential(\n",
       "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage2_b_conv): Sequential(\n",
       "      (0): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "    (stage3_conv1): Sequential(\n",
       "      (0): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    )\n",
       "  )\n",
       "  (place_conv): Sequential(\n",
       "    (0): Conv2d(1024, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.1, inplace)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (bert): BERT(\n",
       "    (embedding): BERTEmbedding(\n",
       "      (position): PositionalEmbedding()\n",
       "      (dropout): Dropout(p=0.0)\n",
       "    )\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (attention): MultiHeadedAttention(\n",
       "          (linear_layers): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (attention): Attention()\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (w_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "          (activation): ReLU()\n",
       "        )\n",
       "        (input_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (output_sublayer): SublayerConnection(\n",
       "          (norm): LayerNorm(torch.Size([128]), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=22, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(123)\n",
    "    device = torch.cuda.current_device()\n",
    "else:\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "# set test loader params\n",
    "test_params = {\"batch_size\": opt.batch_size,\n",
    "               \"shuffle\": False,\n",
    "               \"drop_last\": False,\n",
    "               \"collate_fn\": custom_collate_fn}\n",
    "\n",
    "# set test loader\n",
    "test_loader = DataLoader(infer_set, **test_params)\n",
    "\n",
    "# ---------------(1) load refined models --------------------\n",
    "# get the trained models from\n",
    "# https://drive.google.com/drive/folders/1WXzP8nfXU4l0cNOtSPX9O1qxYH2m6LIp\n",
    "# define person model\n",
    "if False:\n",
    "    # model path\n",
    "    if False:\n",
    "        model_path = \"../checkpoint/person/anotherMissOh_only_params_{}\".format(\n",
    "            'voc_person_group_1gpu_init_none.pth')\n",
    "    else:\n",
    "        model_path = \"../checkpoint/person/anotherMissOh_{}\".format(\n",
    "            'voc_person_group_1gpu_init_none.pth')\n",
    "        \n",
    "    model_p = person_model(num_persons, device)\n",
    "    ckpt = torch.load(model_path)\n",
    "    \n",
    "    # in case of multi-gpu training\n",
    "    if False:\n",
    "        from collections import OrderedDict\n",
    "        ckpt_state_dict = OrderedDict()\n",
    "        for k,v in ckpt.items():\n",
    "            name = k[7:] # remove 'module'\n",
    "            ckpt_state_dict[name] = v\n",
    "\n",
    "        print(\"--- loading {} model---\".format(model_path))\n",
    "        if optimistic_restore(model_p, ckpt_state_dict):\n",
    "            print(\"loaded with {}\".format(model_path))\n",
    "    else:\n",
    "        model_p = ckpt\n",
    "        print(\"loaded with {}\".format(model_path))\n",
    "        \n",
    "    model_p.to(device)\n",
    "    model_p.eval()\n",
    "\n",
    "if False :\n",
    "    print(\"-----------person---behavior-------model---------------\")\n",
    "    model1 = behavior_model(num_persons, num_behaviors, opt, device)\n",
    "    trained_persons = '../checkpoint/behavior' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_integration.pth')\n",
    "    if optimistic_restore(model1, torch.load(trained_persons)):\n",
    "        #model1.load_state_dict(torch.load(trained_persons))\n",
    "        print(\"loaded with {}\".format(trained_persons))\n",
    "\n",
    "else:\n",
    "    # pre-trained behavior model\n",
    "    # step 1: person trained on voc 50 epoch\n",
    "    # step 2: person feature based behavior sequence learning 100 epoch\n",
    "    model_p = behavior_model(num_persons, num_behaviors, opt, device)\n",
    "    if False:\n",
    "        trained_persons = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "            'anotherMissOh_only_params_integration.pth')\n",
    "        model_p.load_state_dict(torch.load(trained_persons))\n",
    "        print(\"loaded with person and behavior model {}\".format(trained_persons))\n",
    "    else:\n",
    "        trained_persons = '../checkpoint/behavior' + os.sep + \"{}\".format(\n",
    "            'anotherMissOh_voc_person_behavior_new.pth')\n",
    "        model_p = torch.load(trained_persons)\n",
    "        print(\"loaded with person and behavior model {}\".format(trained_persons))\n",
    "        \n",
    "model_p.cuda(device)\n",
    "model_p.eval()\n",
    "\n",
    "# face model\n",
    "if True:\n",
    "    model_face = face_model(num_persons, num_faces, device)\n",
    "    trained_face = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_face.pth')\n",
    "    model_face.load_state_dict(torch.load(trained_face))\n",
    "    print(\"loaded with {}\".format(trained_face))\n",
    "model_face.cuda(device)\n",
    "model_face.eval()\n",
    "\n",
    "# emotion model\n",
    "if True:\n",
    "    model_emo = emotion_model(opt.emo_net_ch, num_persons, device)\n",
    "    trained_emotion = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_emotion_integration.pth')\n",
    "    model_emo.load_state_dict(torch.load(trained_emotion))\n",
    "    print(\"loaded with {}\".format(trained_emotion))\n",
    "model_emo.cuda(device)\n",
    "model_emo.eval()\n",
    "\n",
    "# object model\n",
    "if True:\n",
    "    # add model\n",
    "    model_object = object_model(num_objects)\n",
    "    trained_object = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_object_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_object))\n",
    "    model_object.load_state_dict(torch.load(trained_object))\n",
    "\n",
    "model_object.cuda(device)\n",
    "model_object.eval()\n",
    "\n",
    "\n",
    "# relation model\n",
    "if True:\n",
    "    # add model\n",
    "    model_relation = relation_model(num_persons, num_objects, num_relations, opt, device)\n",
    "    trained_relation = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "    'anotherMissOh_only_params_relation_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_relation))\n",
    "    model_relation.load_state_dict(torch.load(trained_relation))\n",
    "model_relation.cuda(device)\n",
    "model_relation.eval()\n",
    "\n",
    "# place model\n",
    "if True:\n",
    "    model_place = place_model(num_persons, num_behaviors, device)\n",
    "    # add model\n",
    "    trained_place = '../checkpoint/refined_models' + os.sep + \"{}\".format(\n",
    "        'anotherMissOh_only_params_place_integration.pth')\n",
    "    # model load\n",
    "    print(\"loaded with {}\".format(trained_place))\n",
    "    model_place.load_state_dict(torch.load(trained_place)['model'])\n",
    "model_place.cuda(device)\n",
    "model_place.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the color map for detection results\n",
    "colors = pickle.load(open(\"../Yolo_v2_pytorch/src/pallete\", \"rb\"))\n",
    "\n",
    "width, height = (1024, 768)\n",
    "width_ratio = float(opt.image_size) / width\n",
    "height_ratio = float(opt.image_size) / height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_blank(s):\n",
    "    return bool(s and s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_json(episode, scene, frm, info, save_file=None):\n",
    "    \n",
    "    if save_file is None:\n",
    "        save_file = 'temp_graph'\n",
    "    import string\n",
    "    strseq = string.ascii_uppercase\n",
    "    \n",
    "    # define  graph\n",
    "    dot = Digraph('G',filename='{}.gv'.format(save_file),engine='fdp')\n",
    "    dot.attr('graph', rotate = '0', dpi='600',rankdir='TB', size='10,8')\n",
    "    dot.attr('node', height='0.1', fontsize='6')\n",
    "    dot.attr('edge', fontsize='6')\n",
    "\n",
    "    place = \"{}\".format(info['place'])\n",
    "    sound = \"{}\".format(info['sound'])\n",
    "\n",
    "    if not is_not_blank(place):\n",
    "        place = 'none'\n",
    "    if not is_not_blank(sound):\n",
    "        sound = 'none'\n",
    "\n",
    "    num_of_persons = len(info['persons'])\n",
    "    num_of_objects = len(info['objects'])\n",
    "\n",
    "    frm_graph = 'episode_{}_scene_{}_frame_{}'.format(\n",
    "        episode, scene, frm)\n",
    "\n",
    "    #dot.node(frm_graph, style='filled', color='lightgrey')\n",
    "    episode_node = \"episode_{:02d}\".format(episode)\n",
    "    scene_node = \"scene_{:03d}\".format(scene)\n",
    "    frame_node = \"frame_{:04d}\".format(frm)\n",
    "    dot.node(episode_node, style='filled', color='lightgrey')\n",
    "    dot.node(scene_node, style='filled', color='lightgrey')\n",
    "    dot.node(frame_node, style='filled', color='lightgrey')\n",
    "\n",
    "    # backgrounds--------------------------------------------\n",
    "    dot.node(place, style='filled', color='lightblue')\n",
    "    dot.node(sound, style='filled', color='lightblue')\n",
    "    \n",
    "    if is_not_blank(episode_node) and is_not_blank(scene_node):\n",
    "        dot.edge(episode_node, scene_node)\n",
    "\n",
    "    if is_not_blank(scene_node) and is_not_blank(frame_node):\n",
    "        dot.edge(scene_node, frame_node)\n",
    "\n",
    "    if is_not_blank(frame_node) and is_not_blank(place):\n",
    "        dot.edge(frame_node, place)\n",
    "\n",
    "    if is_not_blank(frame_node) and is_not_blank(sound):\n",
    "        dot.edge(frame_node, sound)\n",
    "    \n",
    "    # person ------------------------------------------------\n",
    "    for person_id in info['persons'].keys():\n",
    "\n",
    "        if is_not_blank(person_id):\n",
    "            dot.node(person_id)\n",
    "\n",
    "        # behavior---\n",
    "        if 'behavior' in info['persons'][person_id].keys():\n",
    "            behavior_id = info['persons'][person_id]['behavior']\n",
    "        else:\n",
    "            behavior_id = 'none'\n",
    "        if is_not_blank(behavior_id):\n",
    "            dot.node(behavior_id, style='filled', color='green')\n",
    "\n",
    "        # emotion---\n",
    "        if 'emotion' in info['persons'][person_id].keys():\n",
    "            emotion_id = info['persons'][person_id]['emotion']\n",
    "        else:\n",
    "            emotion_id = 'none'\n",
    "        if is_not_blank(emotion_id):\n",
    "            dot.node(emotion_id, style='filled', color='blue')\n",
    "\n",
    "        if is_not_blank(frame_node) and is_not_blank(person_id):\n",
    "            dot.edge(frame_node, person_id)\n",
    "\n",
    "        if is_not_blank(person_id) and is_not_blank(behavior_id):\n",
    "            dot.edge(person_id, behavior_id)\n",
    "\n",
    "        if is_not_blank(person_id) and is_not_blank(emotion_id):\n",
    "            dot.edge(person_id, emotion_id)\n",
    "    \n",
    "    # relation ---------------------------------------------\n",
    "    for object_id in info['objects'].keys():\n",
    "        if is_not_blank(object_id):\n",
    "            dot.node(object_id, style='filled', color='gold')\n",
    "\n",
    "    for person_id in info['relations'].keys():\n",
    "        if person_id not in info['persons'].keys():\n",
    "            dot.node(person_id)\n",
    "            dot.edge(frame_node, person_id)\n",
    "            \n",
    "        for object_id in info['relations'][person_id].keys() :\n",
    "            if object_id not in info['objects'].keys():\n",
    "                dot.node(object_id)\n",
    "                dot.edge(frame_node, object_id)\n",
    "            predicate = info['relations'][person_id][object_id]\n",
    "            dot.edge(person_id, object_id,label=predicate, color='red')\n",
    "\n",
    "    # convert dot graph to json\n",
    "    if False:\n",
    "        dot_to_json =json.dumps(json_graph.node_link_data(dot))\n",
    "    else:\n",
    "        dot_to_json = json.dumps(info)\n",
    "    \n",
    "    with open('{}.json'.format(save_file), 'w') as f:\n",
    "        json.dump(dot_to_json, f)\n",
    "        \n",
    "    # show in image\n",
    "    dot.format = 'png'\n",
    "    dot.render('{}.gv'.format(save_file), view=True) \n",
    "   \n",
    "    graph = cv2.imread('{}.gv.png'.format(save_file))\n",
    "    graph = cv2.resize(graph, dsize=(0, 0), fx=600.0/graph.shape[0], fy=600.0/graph.shape[0])\n",
    "     \n",
    "    if True:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(graph)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'persons': {'Haeyoung1': {'emotion': 'happy', 'behavior': 'talking'}, 'Deogi': {'emotion': 'happy', 'behavior': 'eating'}}, 'objects': {'spoon': {'Deogi': 'N_R'}}, 'relations': {'Deogi': {'spoon': 'holding'}}, 'place': 'kitchen', 'sound': 'talking'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "clip = 0\n",
    "frm = 0\n",
    "\n",
    "#---------------graph structure--------------------------\n",
    "graph_json = {}\n",
    "graph_json['persons'] = {}\n",
    "graph_json['objects'] = {}\n",
    "graph_json['relations'] = {}\n",
    "\n",
    "# ---------------persons---------------------------------\n",
    "graph_json['persons']['Haeyoung1'] = {}\n",
    "graph_json['persons']['Haeyoung1']['emotion'] = 'happy'\n",
    "graph_json['persons']['Haeyoung1']['behavior'] = 'talking'\n",
    "graph_json['persons']['Deogi'] = {}\n",
    "graph_json['persons']['Deogi']['emotion'] = 'happy'\n",
    "graph_json['persons']['Deogi']['behavior'] = 'eating'\n",
    "\n",
    "# ---------------objects---------------------------------\n",
    "graph_json['objects']['spoon'] = {}\n",
    "graph_json['objects']['spoon']['Deogi'] = 'N_R'\n",
    "\n",
    "# ---------------Relations-------------------------------\n",
    "graph_json['relations']['Deogi'] = {}\n",
    "graph_json['relations']['Deogi']['spoon'] = 'holding'\n",
    "\n",
    "# ---------------Backgrounds-----------------------------\n",
    "graph_json['place'] = 'kitchen'\n",
    "graph_json['sound'] = 'talking'\n",
    "\n",
    "info = graph_json\n",
    "print(info)\n",
    "\n",
    "graph_to_json(episode, clip, frm, graph_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/ipykernel_launcher.py:49: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/usr/local/envs/vtt_env/lib/python3.6/site-packages/ipykernel_launcher.py:60: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002446.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002454.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002462.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002470.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002478.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002486.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002494.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002502.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002510.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_001_0035_IMAGE_0000002518.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002576.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002584.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002592.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002600.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002608.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002616.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002680.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002672.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002664.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0036_IMAGE_0000002656.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002764.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002772.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002780.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002788.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002796.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002804.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002812.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002820.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002828.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0037_IMAGE_0000002836.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002882.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002890.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002898.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002906.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002914.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002922.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002930.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002938.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002946.txt\n",
      "frame.__len__10, mAP_file:AnotherMissOh07_002_0038_IMAGE_0000002954.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4c25f57194ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgraph_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load test clips\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/drama-graph/Yolo_v2_pytorch/src/utils.py\u001b[0m in \u001b[0;36mcustom_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcustom_collate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/vtt_env/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Sequence buffers\n",
    "buffer_images = []\n",
    "graph_info = {}\n",
    "# load test clips\n",
    "for iter, batch in enumerate(test_loader):\n",
    "    image, info = batch\n",
    "\n",
    "    scene = iter\n",
    "    episode = episode\n",
    "    \n",
    "    # sort label info on fullrect\n",
    "    image, label, behavior_label, obj_label, face_label, emo_label, frame_id = SortFullRect(\n",
    "        image, info, is_train=False)\n",
    "\n",
    "    try :\n",
    "        image = torch.cat(image,0).cuda(device)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # -----------------(2) inference -------------------------\n",
    "    # person and behavior predictions\n",
    "    # person\n",
    "    # logits : [1, 125, 14, 14]\n",
    "    if False:\n",
    "        p_logits, _ = model_p(image)\n",
    "        predictions_p = post_processing(p_logits,\n",
    "                                        opt.image_size,\n",
    "                                        PersonCLS,\n",
    "                                        model_p.detector.anchors,\n",
    "                                        opt.conf_threshold,\n",
    "                                        opt.nms_threshold)\n",
    "    \n",
    "    # logits : [1, 125, 14, 14]\n",
    "    # behavior_logits : [1, 135, 14, 14]\n",
    "    else :\n",
    "        predictions_p, b_logits = model_p(image, label, behavior_label)\n",
    "\n",
    "    # face\n",
    "    if np.array(face_label).size > 0 :\n",
    "        face_logits = model_face(image)\n",
    "        predictions_face = post_processing(face_logits,\n",
    "                                           opt.image_size,\n",
    "                                           FaceCLS,\n",
    "                                           model_face.detector.anchors,\n",
    "                                           opt.conf_threshold,\n",
    "                                           opt.nms_threshold)\n",
    "\n",
    "    # object\n",
    "    if np.array(obj_label).size > 0 :\n",
    "        object_logits, _ = model_object(image)\n",
    "\n",
    "        predictions_object = post_processing(object_logits,\n",
    "                                             opt.image_size,\n",
    "                                             ObjectCLS,\n",
    "                                             model_object.detector.anchors,\n",
    "                                             opt.conf_threshold,\n",
    "                                             opt.nms_threshold)\n",
    "        \n",
    "    # relation\n",
    "    if np.array(obj_label).size > 0 and np.array(label).size > 0:\n",
    "        r_preds, r_obj_preds, relation_predictions = model_relation(image, label, obj_label)\n",
    "\n",
    "\n",
    "    # place\n",
    "    images_norm = []; info_place = []; preds_place = []\n",
    "    for idx in range(len(image)):\n",
    "        image_resize = image[idx]\n",
    "        images_norm.append(image_resize)\n",
    "        info_place.append(info[0][idx]['place'])\n",
    "        frame_place = frame_id.copy()\n",
    "    info_place = label_mapping(info_place)\n",
    "    buffer_images = place_buffer(images_norm, buffer_images)\n",
    "    pl_updated=False\n",
    "    buffer_idx = 10 - (len(images_norm) %10)\n",
    "    images_norm = buffer_images[-buffer_idx:] + images_norm\n",
    "    for plidx in range(len(images_norm)//10):\n",
    "        batch_images = torch.stack(images_norm[plidx*10:(plidx+1)*10]).cuda(device).unsqueeze(0)\n",
    "        output = model_place(batch_images)\n",
    "        output = torch.cat((output[:, :9], output[:, 10:]), 1) # None excluded. For None prediction, comment this line out.\n",
    "        preds = torch.argmax(output, -1).tolist() # (T, n_class) ->(T, )\n",
    "        for idx in range(len(preds)):\n",
    "            if preds[idx] >= 9: preds[idx] += 1\n",
    "        preds_place += preds;\n",
    "        pl_updated = True\n",
    "    buffer_images = images_norm[-10:]\n",
    "    preds_place = preds_place[buffer_idx:]\n",
    "    assert len(preds_place) == len(info_place)\n",
    "    preds_place_txt = label_remapping(preds_place)\n",
    "    target_place_txt = label_remapping(info_place)\n",
    "    \n",
    "    for idx, frame in enumerate(frame_id):\n",
    "        \n",
    "        # ---------------(3) mkdir for evaluations----------------------\n",
    "        f_info = frame[0].split('/')\n",
    "        save_dir = '../results/drama-graph/{}/{}/{}/'.format(\n",
    "            f_info[4], f_info[5], f_info[6])\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        f_file = f_info[7]\n",
    "        mAP_file = \"{}_{}_{}_{}\".format(f_info[4],\n",
    "                                        f_info[5],\n",
    "                                        f_info[6],\n",
    "                                        f_info[7].replace(\"jpg\", \"txt\"))\n",
    "        if opt.display:\n",
    "            # AnotherMissOh07_002_0036_IMAGE_0000002672.txt\n",
    "            print(\"frame.__len__{}, mAP_file:{}\".format(len(frame_id), mAP_file))\n",
    "            \n",
    "        # --------------(5) visualization of inferences ----------\n",
    "        # out of try : pdb.set_trace = lambda : None\n",
    "        try:\n",
    "            # for some empty video clips\n",
    "            img = image[idx]\n",
    "            # ToTensor function normalizes image pixel values into [0,1]\n",
    "            np_img = img.cpu().numpy()\n",
    "            np_img = np.transpose(np_img,(1,2,0)) * 255\n",
    "            output_image = cv2.cvtColor(np_img,cv2.COLOR_RGB2BGR)\n",
    "            output_image = cv2.resize(output_image, (width, height))\n",
    "            \n",
    "            #**************************************\n",
    "            graph_json = {}\n",
    "            graph_json['persons'] = {}\n",
    "            graph_json['objects'] = {}\n",
    "            graph_json['relations'] = {}\n",
    "            graph_json['sound'] = 'none'\n",
    "            #**************************************\n",
    "            \n",
    "            # face\n",
    "            if len(predictions_face) != 0:\n",
    "                prediction_face = predictions_face[idx]\n",
    "                for pred in prediction_face:\n",
    "                    xmin = int(max(pred[0] / width_ratio, 0))\n",
    "                    ymin = int(max(pred[1] / height_ratio, 0))\n",
    "                    xmax = int(min((pred[2]) / width_ratio, width))\n",
    "                    ymax = int(min((pred[3]) / height_ratio, height))\n",
    "                    color = colors[FaceCLS.index(pred[5])]\n",
    "                    \n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "                    \n",
    "                    # save detection results\n",
    "                    pred_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                    \n",
    "                    print(\"face_pred:{}\".format(cat_pred))\n",
    "                    print(\"detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "                    \n",
    "                    #**************************************************\n",
    "                    graph_json['persons'][pred_cls] = {}\n",
    "                    #**************************************************\n",
    "                    \n",
    "                    # update emotion model and the prediction\n",
    "                    if False:\n",
    "                        fl = face_label[idx][jdx]\n",
    "                        face_x0, face_y0 = int(fl[0]/width_ratio), int(fl[1]/height_ratio)\n",
    "                        face_x1, face_y1 = int(fl[2]/width_ratio), int(fl[3]/height_ratio)\n",
    "                        \n",
    "                        \n",
    "                        # emotion\n",
    "                        if np.array(face_label).size > 0 and False:\n",
    "                            face_label = [fl for fl in face_label if len(fl) > 0]\n",
    "                            emo_label = [el for el in emo_label if len(el) > 0]\n",
    "                            image_c = image.permute(0,2,3,1).cpu()\n",
    "                            face_crops, emo_gt = crop_face_emotion(image_c, face_label, emo_label, opt)\n",
    "                            face_crops, emo_gt = face_crops.cuda(device).contiguous(), emo_gt.cuda(device)\n",
    "                            emo_logits = model_emo(face_crops)\n",
    "                            num_img, num_face = np.array(face_label).shape[0:2]\n",
    "                            emo_logits = emo_logits.view(num_img, num_face, 7)\n",
    "                        \n",
    "                        \n",
    "                        emo_ij = F.softmax(emo_logits[idx,jdx,:], dim=0).argmax().detach().cpu().numpy()\n",
    "                        emo_txt = EmoCLS[emo_ij]\n",
    "                        cv2.rectangle(output_image, (face_x0,face_y0),\n",
    "                                      (face_x1,face_y1), (255,255,0), 1)\n",
    "                        cv2.putText(output_image, emo_txt, (face_x0, face_y0-5),\n",
    "                                    cv2.FONT_HERSHEY_PLAIN, 1, (255,255,0), 1,\n",
    "                                    cv2.LINE_AA)\n",
    "                        \n",
    "                        #******************************************************\n",
    "                        graph_json['persons'][pred_cls]['emotion'] = emo_txt\n",
    "                        #******************************************************\n",
    "                    \n",
    "            else:\n",
    "                print(\"non-detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "            \n",
    "\n",
    "            if len(predictions_p) != 0 :\n",
    "                prediction = predictions_p[idx]\n",
    "                \n",
    "                if True:\n",
    "                    b_logit = b_logits[idx]\n",
    "\n",
    "                # person and behavior\n",
    "                num_preds = len(prediction)\n",
    "                                \n",
    "                for jdx, pred in enumerate(prediction):\n",
    "                    # person\n",
    "                    xmin = int(max(pred[0] / width_ratio, 0))\n",
    "                    ymin = int(max(pred[1] / height_ratio, 0))\n",
    "                    xmax = int(min((pred[2]) / width_ratio, width))\n",
    "                    ymax = int(min((pred[3]) / height_ratio, height))\n",
    "                    color = colors[PersonCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "                    \n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "                        \n",
    "                    pred_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                    print(\"person_pred:{}\".format(cat_pred))\n",
    "                    \n",
    "                    #**************************************************\n",
    "                    if pred_cls not in graph_json['persons'].keys():\n",
    "                        graph_json['persons'][pred_cls] = {}\n",
    "                    #**************************************************\n",
    "                    \n",
    "                    # behavior\n",
    "                    if True:\n",
    "                        value, index = b_logit[jdx].max(0)\n",
    "\n",
    "                        b_idx = index.cpu().numpy()\n",
    "                        b_pred = PBeHavCLS[b_idx]\n",
    "                        \n",
    "                        cv2.putText(\n",
    "                            output_image, '+ behavior : ' + b_pred,\n",
    "                            (xmin, ymin + text_size[1] + 4 + 12),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "                        pred_beh_cls = b_pred.replace(' ', '_')\n",
    "                        pred_beh_cls = pred_beh_cls.replace('/', '_')\n",
    "                        \n",
    "                        #******************************************************\n",
    "                        graph_json['persons'][pred_cls]['behavior'] = pred_beh_cls\n",
    "                        #******************************************************\n",
    "                        \n",
    "                        cat_pred_beh = '%s %s %s %s %s %s\\n' % (\n",
    "                            pred_beh_cls,\n",
    "                            str(pred[4]),\n",
    "                            str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "\n",
    "                        print(\"behavior_pred:{}\".format(cat_pred_beh))\n",
    "                    \n",
    "                    if opt.display:\n",
    "                        print(\"detected {}\".format(save_dir + \"{}\".format(f_file)))\n",
    "                else:\n",
    "                    if opt.display:\n",
    "                        print(\"non-detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "\n",
    "            # object\n",
    "            if len(predictions_object) != 0:\n",
    "                \n",
    "                prediction_object = predictions_object[0]\n",
    "                num_preds = len(prediction)\n",
    "                for jdx, pred in enumerate(prediction_object):\n",
    "                    xmin = int(max(pred[0] / width_ratio, 0))\n",
    "                    ymin = int(max(pred[1] / height_ratio, 0))\n",
    "                    xmax = int(min((pred[2]) / width_ratio, width))\n",
    "                    ymax = int(min((pred[3]) / height_ratio, height))\n",
    "                    color = colors[ObjectCLS.index(pred[5])]\n",
    "\n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred[5] + ' : %.2f' % pred[4],\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % pred[4],\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "\n",
    "                    # save detection results\n",
    "                    pred_obj_cls = pred[5]\n",
    "                    cat_pred = '%s %s %s %s %s %s\\n' % (\n",
    "                        pred_obj_cls,\n",
    "                        str(pred[4]),\n",
    "                        str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                    \n",
    "                    #**************************************************\n",
    "                    graph_json['objects'][pred_obj_cls] = {}\n",
    "                    #**************************************************\n",
    "                    print(\"object_pred:{}\".format(cat_pred))\n",
    "\n",
    "                    if opt.display:\n",
    "                        print(\"detected {}\".format(\n",
    "                            save_dir + \"{}\".format(f_file)))\n",
    "                else:\n",
    "                    if opt.display:\n",
    "                        print(\"non-detected {}\".format(\n",
    "                        save_dir + \"{}\".format(f_file)))\n",
    "                        \n",
    "            # relation\n",
    "            if len(r_preds) != 0:\n",
    "                r_pred = r_preds[idx]\n",
    "                r_obj_pred = r_obj_preds[idx]\n",
    "                relation_prediction = relation_predictions[idx]\n",
    "                num_preds = len(r_pred)\n",
    "                for jdx, pred in enumerate(r_pred):\n",
    "                    xmin = int(max(float(pred[0]) / width_ratio, 0))\n",
    "                    ymin = int(max(float(pred[1]) / height_ratio, 0))\n",
    "                    xmax = int(min((float(pred[2])) / width_ratio, width))\n",
    "                    ymax = int(min((float(pred[3])) / height_ratio, height))\n",
    "                    color = colors[PersonCLS.index(pred[5])]\n",
    "                    \n",
    "                    cv2.rectangle(output_image, (xmin, ymin),\n",
    "                                  (xmax, ymax), color, 2)\n",
    "                    \n",
    "                    pred_per_cls = pred[5]\n",
    "                    text_size = cv2.getTextSize(\n",
    "                        pred_per_cls + ' : %.2f' % float(pred[4]),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                    cv2.rectangle(\n",
    "                        output_image,\n",
    "                        (xmin, ymin),\n",
    "                        (xmin + text_size[0] + 100,\n",
    "                         ymin + text_size[1] + 20), color, -1)\n",
    "                    cv2.putText(\n",
    "                        output_image, pred[5] + ' : %.2f' % float(pred[4]),\n",
    "                        (xmin, ymin + text_size[1] + 4),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                        (255, 255, 255), 1)\n",
    "                    \n",
    "                    #*****************************************************\n",
    "                    graph_json['relations'][pred_per_cls] = {}\n",
    "                    #*****************************************************\n",
    "\n",
    "                    for kdx, obj_pred in enumerate(r_obj_pred):\n",
    "                        xmin = int(max(float(obj_pred[0]) / width_ratio, 0))\n",
    "                        ymin = int(max(float(obj_pred[1]) / height_ratio, 0))\n",
    "                        xmax = int(min((float(obj_pred[2])) / width_ratio, width))\n",
    "                        ymax = int(min((float(obj_pred[3])) / height_ratio, height))\n",
    "\n",
    "                        color = colors[ObjectCLS.index(obj_pred[5])]\n",
    "                        cv2.rectangle(output_image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "                        \n",
    "                        pred_obj_cls = obj_pred[5]\n",
    "                        text_size = cv2.getTextSize(\n",
    "                            pred_obj_cls + ' : %.2f' % float(obj_pred[4]),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\n",
    "                        cv2.rectangle(\n",
    "                            output_image,\n",
    "                            (xmin, ymin),\n",
    "                            (xmin + text_size[0] + 100,\n",
    "                             ymin + text_size[1] + 20), color, -1)\n",
    "                        cv2.putText(\n",
    "                            output_image, obj_pred[5] + ' : %.2f' % float(obj_pred[4]),\n",
    "                            (xmin, ymin + text_size[1] + 4),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "                        \n",
    "                        value, ind = relation_prediction[kdx].max(1)\n",
    "                        ind = int(ind.cpu().numpy())\n",
    "                        rel_ind = P2ORelCLS[ind]\n",
    "                        cv2.putText(\n",
    "                            output_image, '+ relation : ' + rel_ind,\n",
    "                            (xmin, ymin + text_size[1] + 4 + 12),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 1,\n",
    "                            (255, 255, 255), 1)\n",
    "\n",
    "                        pred_pred_cls = rel_ind\n",
    "                        cat_pred = '%s %s %s %s %s\\n' % (\n",
    "                            pred_cls, str(xmin), str(ymin), str(xmax), str(ymax))\n",
    "                        print(\"relation_pred:{}\".format(cat_pred))\n",
    "                        \n",
    "                        #*****************************************************\n",
    "                        graph_json['relations'][pred_per_cls][pred_obj_cls] = pred_pred_cls\n",
    "                        #*****************************************************\n",
    "                        \n",
    "            # place\n",
    "            if len(preds_place_txt) != 0:\n",
    "                cv2.putText(output_image, \"place : \" + preds_place_txt[idx],\n",
    "                    (30, 30),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 2, (255, 255, 255), 2)\n",
    "                \n",
    "                #*****************************************\n",
    "                graph_json['place'] = preds_place_txt[idx]\n",
    "                #*****************************************\n",
    "                \n",
    "                if opt.display:\n",
    "                    print('place_pred :', preds_place_txt[idx])\n",
    "                \n",
    "                \n",
    "            # save output image  \n",
    "            cv2.imwrite(save_dir + \"{}\".format(f_file), output_image)\n",
    "            # save images\n",
    "            plt_output_image = cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(8,8))\n",
    "            plt.imshow(plt_output_image.astype('uint8'))\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "            #*****************************************\n",
    "            frm_name = \"episode_{:02d}_scene_{:03d}_frame_{:04d}\".format(episode, scene, idx)\n",
    "            save_file = save_dir + frm_name\n",
    "            print(graph_json)\n",
    "            graph_to_json(episode, scene, idx, graph_json, save_file)\n",
    "            #*****************************************\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
